diff --git a/aclk/aclk.c b/aclk/aclk.c
index 399bc98..780890c 100644
--- a/aclk/aclk.c
+++ b/aclk/aclk.c
@@ -154,7 +154,7 @@ biofailed:
 
 static int wait_till_cloud_enabled()
 {
-    info("Waiting for Cloud to be enabled");
+    netdata_info("Waiting for Cloud to be enabled");
     while (!netdata_cloud_setting) {
         sleep_usec(USEC_PER_SEC * 1);
         if (!service_running(SERVICE_ACLK))
@@ -237,7 +237,7 @@ void aclk_mqtt_wss_log_cb(mqtt_wss_log_type_t log_type, const char* str)
             error_report("%s", str);
             return;
         case MQTT_WSS_LOG_INFO:
-            info("%s", str);
+            netdata_info("%s", str);
             return;
         case MQTT_WSS_LOG_DEBUG:
             debug(D_ACLK, "%s", str);
@@ -297,7 +297,7 @@ static void puback_callback(uint16_t packet_id)
 #endif
 
     if (aclk_shared_state.mqtt_shutdown_msg_id == (int)packet_id) {
-        info("Shutdown message has been acknowledged by the cloud. Exiting gracefully");
+        netdata_info("Shutdown message has been acknowledged by the cloud. Exiting gracefully");
         aclk_shared_state.mqtt_shutdown_msg_rcvd = 1;
     }
 }
@@ -335,7 +335,7 @@ static int handle_connection(mqtt_wss_client client)
         }
 
         if (disconnect_req || aclk_kill_link) {
-            info("Going to restart connection due to disconnect_req=%s (cloud req), aclk_kill_link=%s (reclaim)",
+            netdata_info("Going to restart connection due to disconnect_req=%s (cloud req), aclk_kill_link=%s (reclaim)",
                 disconnect_req ? "true" : "false",
                 aclk_kill_link ? "true" : "false");
             disconnect_req = 0;
@@ -390,7 +390,7 @@ static inline void mqtt_connected_actions(mqtt_wss_client client)
 
 void aclk_graceful_disconnect(mqtt_wss_client client)
 {
-    info("Preparing to gracefully shutdown ACLK connection");
+    netdata_info("Preparing to gracefully shutdown ACLK connection");
     aclk_queue_lock();
     aclk_queue_flush();
 
@@ -403,17 +403,17 @@ void aclk_graceful_disconnect(mqtt_wss_client client)
             break;
         }
         if (aclk_shared_state.mqtt_shutdown_msg_rcvd) {
-            info("MQTT App Layer `disconnect` message sent successfully");
+            netdata_info("MQTT App Layer `disconnect` message sent successfully");
             break;
         }
     }
-    info("ACLK link is down");
+    netdata_info("ACLK link is down");
     log_access("ACLK DISCONNECTED");
     aclk_stats_upd_online(0);
     last_disconnect_time = now_realtime_sec();
     aclk_connected = 0;
 
-    info("Attempting to gracefully shutdown the MQTT/WSS connection");
+    netdata_info("Attempting to gracefully shutdown the MQTT/WSS connection");
     mqtt_wss_disconnect(client, 1000);
 }
 
@@ -455,7 +455,7 @@ static int aclk_block_till_recon_allowed() {
     next_connection_attempt = now_realtime_sec() + (recon_delay / MSEC_PER_SEC);
     last_backoff_value = (float)recon_delay / MSEC_PER_SEC;
 
-    info("Wait before attempting to reconnect in %.3f seconds", recon_delay / (float)MSEC_PER_SEC);
+    netdata_info("Wait before attempting to reconnect in %.3f seconds", recon_delay / (float)MSEC_PER_SEC);
     // we want to wake up from time to time to check netdata_exit
     while (recon_delay)
     {
@@ -522,7 +522,7 @@ static int aclk_attempt_to_connect(mqtt_wss_client client)
         if (aclk_block_till_recon_allowed())
             return 1;
 
-        info("Attempting connection now");
+        netdata_info("Attempting connection now");
         memset(&base_url, 0, sizeof(url_t));
         if (url_parse(cloud_base_url, &base_url)) {
             error_report("ACLK base URL configuration key could not be parsed. Will retry in %d seconds.", CLOUD_BASE_URL_READ_RETRY);
@@ -572,7 +572,7 @@ static int aclk_attempt_to_connect(mqtt_wss_client client)
             error_report("Can't use encoding=proto without at least \"proto\" capability.");
             continue;
         }
-        info("New ACLK protobuf protocol negotiated successfully (/env response).");
+        netdata_info("New ACLK protobuf protocol negotiated successfully (/env response).");
 
         memset(&auth_url, 0, sizeof(url_t));
         if (url_parse(aclk_env->auth_endpoint, &auth_url)) {
@@ -637,7 +637,7 @@ static int aclk_attempt_to_connect(mqtt_wss_client client)
 
         if (!ret) {
             last_conn_time_mqtt = now_realtime_sec();
-            info("ACLK connection successfully established");
+            netdata_info("ACLK connection successfully established");
             log_access("ACLK CONNECTED");
             mqtt_connected_actions(client);
             return 0;
@@ -683,7 +683,7 @@ void *aclk_main(void *ptr)
     netdata_thread_disable_cancelability();
 
 #if defined( DISABLE_CLOUD ) || !defined( ENABLE_ACLK )
-    info("Killing ACLK thread -> cloud functionality has been disabled");
+    netdata_info("Killing ACLK thread -> cloud functionality has been disabled");
     static_thread->enabled = NETDATA_MAIN_THREAD_EXITED;
     return NULL;
 #endif
@@ -809,7 +809,7 @@ void aclk_host_state_update(RRDHOST *host, int cmd)
             rrdhost_aclk_state_unlock(localhost);
             create_query->data.bin_payload.topic = ACLK_TOPICID_CREATE_NODE;
             create_query->data.bin_payload.msg_name = "CreateNodeInstance";
-            info("Registering host=%s, hops=%u", host->machine_guid, host->system_info->hops);
+            netdata_info("Registering host=%s, hops=%u", host->machine_guid, host->system_info->hops);
             aclk_queue_query(create_query);
             return;
         }
@@ -832,7 +832,7 @@ void aclk_host_state_update(RRDHOST *host, int cmd)
     query->data.bin_payload.payload = generate_node_instance_connection(&query->data.bin_payload.size, &node_state_update);
     rrdhost_aclk_state_unlock(localhost);
 
-    info("Queuing status update for node=%s, live=%d, hops=%u",(char*)node_state_update.node_id, cmd,
+    netdata_info("Queuing status update for node=%s, live=%d, hops=%u",(char*)node_state_update.node_id, cmd,
          host->system_info->hops);
     freez((void*)node_state_update.node_id);
     query->data.bin_payload.msg_name = "UpdateNodeInstanceConnection";
@@ -875,7 +875,7 @@ void aclk_send_node_instances()
             node_state_update.claim_id = localhost->aclk_state.claimed_id;
             query->data.bin_payload.payload = generate_node_instance_connection(&query->data.bin_payload.size, &node_state_update);
             rrdhost_aclk_state_unlock(localhost);
-            info("Queuing status update for node=%s, live=%d, hops=%d",(char*)node_state_update.node_id,
+            netdata_info("Queuing status update for node=%s, live=%d, hops=%d",(char*)node_state_update.node_id,
                  list->live,
                  list->hops);
 
@@ -899,7 +899,7 @@ void aclk_send_node_instances()
             node_instance_creation.claim_id = localhost->aclk_state.claimed_id,
             create_query->data.bin_payload.payload = generate_node_instance_creation(&create_query->data.bin_payload.size, &node_instance_creation);
             rrdhost_aclk_state_unlock(localhost);
-            info("Queuing registration for host=%s, hops=%d",(char*)node_instance_creation.machine_guid,
+            netdata_info("Queuing registration for host=%s, hops=%d",(char*)node_instance_creation.machine_guid,
                  list->hops);
             freez((void *)node_instance_creation.machine_guid);
             aclk_queue_query(create_query);
diff --git a/aclk/aclk_otp.c b/aclk/aclk_otp.c
index 66d751b..02ab6de 100644
--- a/aclk/aclk_otp.c
+++ b/aclk/aclk_otp.c
@@ -335,7 +335,7 @@ int aclk_get_otp_challenge(url_t *target, const char *agent_id, unsigned char **
     }
     buffer_free(url);
 
-    info ("ACLK_OTP Got Challenge from Cloud");
+    netdata_info("ACLK_OTP Got Challenge from Cloud");
 
     json_object *json = json_tokener_parse(resp.payload);
     if (!json) {
@@ -414,7 +414,7 @@ int aclk_send_otp_response(const char *agent_id, const unsigned char *response,
             aclk_parse_otp_error(resp.payload);
         goto cleanup_response;
     }
-    info ("ACLK_OTP Got Password from Cloud");
+    netdata_info("ACLK_OTP Got Password from Cloud");
 
     if (parse_passwd_response(resp.payload, mqtt_auth)){
         error("Error parsing response of password endpoint");
@@ -871,7 +871,7 @@ int aclk_get_env(aclk_env_t *env, const char* aclk_hostname, int aclk_port) {
         return 1;
     }
 
-    info("Getting Cloud /env successful");
+    netdata_info("Getting Cloud /env successful");
 
     https_req_response_free(&resp);
     buffer_free(buf);
diff --git a/aclk/aclk_query.c b/aclk/aclk_query.c
index 0698c2d..5e41986 100644
--- a/aclk/aclk_query.c
+++ b/aclk/aclk_query.c
@@ -357,7 +357,7 @@ void *aclk_query_main_thread(void *ptr)
 #define TASK_LEN_MAX 22
 void aclk_query_threads_start(struct aclk_query_threads *query_threads, mqtt_wss_client client)
 {
-    info("Starting %d query threads.", query_threads->count);
+    netdata_info("Starting %d query threads.", query_threads->count);
 
     char thread_name[TASK_LEN_MAX];
     query_threads->thread_list = callocz(query_threads->count, sizeof(struct aclk_query_thread));
diff --git a/aclk/aclk_rx_msgs.c b/aclk/aclk_rx_msgs.c
index 60bff9b..abd44dc 100644
--- a/aclk/aclk_rx_msgs.c
+++ b/aclk/aclk_rx_msgs.c
@@ -399,10 +399,10 @@ int handle_disconnect_req(const char *msg, size_t msg_len)
         error("Cloud Banned This Agent!");
         aclk_disable_runtime = 1;
     }
-    info("Cloud requested disconnect (EC=%u, \"%s\")", (unsigned int)cmd->error_code, cmd->error_description);
+    netdata_info("Cloud requested disconnect (EC=%u, \"%s\")", (unsigned int)cmd->error_code, cmd->error_description);
     if (cmd->reconnect_after_s > 0) {
         aclk_block_until = now_monotonic_sec() + cmd->reconnect_after_s;
-        info(
+        netdata_info(
             "Cloud asks not to reconnect for %u seconds. We shall honor that request",
             (unsigned int)cmd->reconnect_after_s);
     }
diff --git a/aclk/https_client.c b/aclk/https_client.c
index 345cf65..882f93c 100644
--- a/aclk/https_client.c
+++ b/aclk/https_client.c
@@ -524,7 +524,7 @@ int https_request(https_req_t *request, https_req_response_t *response) {
             error("Proxy didn't return 200 OK (got %d)", ctx->parse_ctx.http_code);
             goto exit_sock;
         }
-        info("Proxy accepted CONNECT upgrade");
+        netdata_info("Proxy accepted CONNECT upgrade");
     }
     ctx->request = request;
 
@@ -584,7 +584,7 @@ int https_request(https_req_t *request, https_req_response_t *response) {
         // only exact data without affixed 0x00
         ((char*)response->payload)[response->payload_size] = 0; // mallocz(response->payload_size + 1);
     }
-    info("HTTPS \"%s\" request to \"%s\" finished with HTTP code: %d", http_req_type_to_str(ctx->request->request_type), ctx->request->host, response->http_code);
+    netdata_info("HTTPS \"%s\" request to \"%s\" finished with HTTP code: %d", http_req_type_to_str(ctx->request->request_type), ctx->request->host, response->http_code);
 
     rc = 0;
 
diff --git a/claim/claim.c b/claim/claim.c
index 9fe156d..212ee69 100644
--- a/claim/claim.c
+++ b/claim/claim.c
@@ -83,16 +83,16 @@ void claim_agent(char *claiming_arguments)
               cloud_base_url,
               claiming_arguments);
 
-    info("Executing agent claiming command 'netdata-claim.sh'");
+    netdata_info("Executing agent claiming command 'netdata-claim.sh'");
     fp_child_output = netdata_popen(command_buffer, &command_pid, &fp_child_input);
     if(!fp_child_output) {
         error("Cannot popen(\"%s\").", command_buffer);
         return;
     }
-    info("Waiting for claiming command to finish.");
+    netdata_info("Waiting for claiming command to finish.");
     while (fgets(command_buffer, CLAIMING_COMMAND_LENGTH, fp_child_output) != NULL) {;}
     exit_code = netdata_pclose(fp_child_input, fp_child_output, command_pid);
-    info("Agent claiming command returned with code %d", exit_code);
+    netdata_info("Agent claiming command returned with code %d", exit_code);
     if (0 == exit_code) {
         load_claiming_state();
         return;
@@ -148,7 +148,7 @@ void load_claiming_state(void)
     }
     if (aclk_connected)
     {
-        info("Agent was already connected to Cloud - forcing reconnection under new credentials");
+        netdata_info("Agent was already connected to Cloud - forcing reconnection under new credentials");
         aclk_kill_link = 1;
     }
     aclk_disable_runtime = 0;
@@ -174,13 +174,13 @@ void load_claiming_state(void)
     rrdhost_aclk_state_unlock(localhost);
 
     if (!claimed_id) {
-        info("Unable to load '%s', setting state to AGENT_UNCLAIMED", filename);
+        netdata_info("Unable to load '%s', setting state to AGENT_UNCLAIMED", filename);
         return;
     }
 
     freez(claimed_id);
 
-    info("File '%s' was found. Setting state to AGENT_CLAIMED.", filename);
+    netdata_info("File '%s' was found. Setting state to AGENT_CLAIMED.", filename);
     netdata_cloud_setting = appconfig_get_boolean(&cloud_config, CONFIG_SECTION_GLOBAL, "enabled", 1);
 #endif
 }
@@ -202,7 +202,7 @@ void load_cloud_conf(int silent)
 
     ret = appconfig_load(&cloud_config, filename, 1, NULL);
     if(!ret && !silent) {
-        info("CONFIG: cannot load cloud config '%s'. Running with internal defaults.", filename);
+        netdata_info("CONFIG: cannot load cloud config '%s'. Running with internal defaults.", filename);
     }
     freez(filename);
 }
diff --git a/collectors/apps.plugin/apps_plugin.c b/collectors/apps.plugin/apps_plugin.c
index 3132b22..ccc842f 100644
--- a/collectors/apps.plugin/apps_plugin.c
+++ b/collectors/apps.plugin/apps_plugin.c
@@ -1470,7 +1470,7 @@ static inline int read_proc_pid_stat(struct pid_stat *p, void *ptr) {
 
     if(enable_guest_charts) {
         enable_guest_charts = 0;
-        info("Guest charts aren't supported by FreeBSD");
+        netdata_info("Guest charts aren't supported by FreeBSD");
     }
 #else
     pid_incremental_rate(stat, p->minflt,  str2kernel_uint_t(procfile_lineword(ff, 0,  9)));
@@ -4184,17 +4184,17 @@ static void parse_args(int argc, char **argv)
     if(freq > 0) update_every = freq;
 
     if(read_apps_groups_conf(user_config_dir, "groups")) {
-        info("Cannot read process groups configuration file '%s/apps_groups.conf'. Will try '%s/apps_groups.conf'", user_config_dir, stock_config_dir);
+        netdata_info("Cannot read process groups configuration file '%s/apps_groups.conf'. Will try '%s/apps_groups.conf'", user_config_dir, stock_config_dir);
 
         if(read_apps_groups_conf(stock_config_dir, "groups")) {
             error("Cannot read process groups '%s/apps_groups.conf'. There are no internal defaults. Failing.", stock_config_dir);
             exit(1);
         }
         else
-            info("Loaded config file '%s/apps_groups.conf'", stock_config_dir);
+            netdata_info("Loaded config file '%s/apps_groups.conf'", stock_config_dir);
     }
     else
-        info("Loaded config file '%s/apps_groups.conf'", user_config_dir);
+        netdata_info("Loaded config file '%s/apps_groups.conf'", user_config_dir);
 }
 
 static int am_i_running_as_root() {
@@ -4217,7 +4217,7 @@ static int check_capabilities() {
         return 0;
     }
     else if(debug_enabled)
-        info("Received my capabilities from the system.");
+        netdata_info("Received my capabilities from the system.");
 
     int ret = 1;
 
@@ -4232,7 +4232,7 @@ static int check_capabilities() {
             ret = 0;
         }
         else if(debug_enabled)
-            info("apps.plugin runs with CAP_DAC_READ_SEARCH.");
+            netdata_info("apps.plugin runs with CAP_DAC_READ_SEARCH.");
     }
 
     cfv = CAP_CLEAR;
@@ -4246,7 +4246,7 @@ static int check_capabilities() {
             ret = 0;
         }
         else if(debug_enabled)
-            info("apps.plugin runs with CAP_SYS_PTRACE.");
+            netdata_info("apps.plugin runs with CAP_SYS_PTRACE.");
     }
 
     cap_free(caps);
@@ -5123,7 +5123,7 @@ int main(int argc, char **argv) {
     if(debug_flags != 0) {
         struct rlimit rl = { RLIM_INFINITY, RLIM_INFINITY };
         if(setrlimit(RLIMIT_CORE, &rl) != 0)
-            info("Cannot request unlimited core dumps for debugging... Proceeding anyway...");
+            netdata_info("Cannot request unlimited core dumps for debugging... Proceeding anyway...");
 #ifdef HAVE_SYS_PRCTL_H
         prctl(PR_SET_DUMPABLE, 1, 0, 0, 0);
 #endif
@@ -5163,7 +5163,7 @@ int main(int argc, char **argv) {
 #endif
     }
 
-    info("started on pid %d", getpid());
+    netdata_info("started on pid %d", getpid());
 
     snprintfz(all_user_ids.filename, FILENAME_MAX, "%s/etc/passwd", netdata_configured_host_prefix);
     debug_log("passwd file: '%s'", all_user_ids.filename);
diff --git a/collectors/cups.plugin/cups_plugin.c b/collectors/cups.plugin/cups_plugin.c
index ecadc4e..5213d75 100644
--- a/collectors/cups.plugin/cups_plugin.c
+++ b/collectors/cups.plugin/cups_plugin.c
@@ -436,5 +436,5 @@ int main(int argc, char **argv) {
     }
 
     httpClose(http);
-    info("CUPS process exiting");
+    netdata_info("CUPS process exiting");
 }
diff --git a/collectors/debugfs.plugin/debugfs_plugin.c b/collectors/debugfs.plugin/debugfs_plugin.c
index 9713be3..3cc7622 100644
--- a/collectors/debugfs.plugin/debugfs_plugin.c
+++ b/collectors/debugfs.plugin/debugfs_plugin.c
@@ -235,7 +235,7 @@ int main(int argc, char **argv)
                 enabled++;
         }
         if (!enabled) {
-            info("all modules are disabled, exiting...");
+            netdata_info("all modules are disabled, exiting...");
             return 1;
         }
     }
diff --git a/collectors/debugfs.plugin/debugfs_zswap.c b/collectors/debugfs.plugin/debugfs_zswap.c
index a2991b9..94b197b 100644
--- a/collectors/debugfs.plugin/debugfs_zswap.c
+++ b/collectors/debugfs.plugin/debugfs_zswap.c
@@ -383,7 +383,7 @@ int do_debugfs_zswap(int update_every, const char *name)
     static int check_if_enabled = 1;
 
     if (likely(check_if_enabled && debugfs_is_zswap_enabled())) {
-        info("Zswap is disabled");
+        netdata_info("Zswap is disabled");
         return 1;
     }
 
diff --git a/collectors/ebpf.plugin/ebpf.c b/collectors/ebpf.plugin/ebpf.c
index ffab37d..bf867d7 100644
--- a/collectors/ebpf.plugin/ebpf.c
+++ b/collectors/ebpf.plugin/ebpf.c
@@ -727,7 +727,7 @@ static void ebpf_stop_threads(int sig)
         if (ebpf_modules[i].enabled == NETDATA_THREAD_EBPF_RUNNING) {
             netdata_thread_cancel(*ebpf_modules[i].thread->thread);
 #ifdef NETDATA_DEV_MODE
-            info("Sending cancel for thread %s", ebpf_modules[i].thread_name);
+            netdata_info("Sending cancel for thread %s", ebpf_modules[i].thread_name);
 #endif
         }
     }
@@ -736,7 +736,7 @@ static void ebpf_stop_threads(int sig)
     pthread_mutex_lock(&mutex_cgroup_shm);
     netdata_thread_cancel(*cgroup_integration_thread.thread);
 #ifdef NETDATA_DEV_MODE
-    info("Sending cancel for thread %s", cgroup_integration_thread.name);
+    netdata_info("Sending cancel for thread %s", cgroup_integration_thread.name);
 #endif
     pthread_mutex_unlock(&mutex_cgroup_shm);
 
@@ -2135,11 +2135,11 @@ static void ebpf_parse_args(int argc, char **argv)
         freq = EBPF_DEFAULT_UPDATE_EVERY;
 
     if (load_collector_config(ebpf_user_config_dir, &disable_apps, &disable_cgroups, freq)) {
-        info(
+        netdata_info(
             "Does not have a configuration file inside `%s/ebpf.d.conf. It will try to load stock file.",
             ebpf_user_config_dir);
         if (load_collector_config(ebpf_stock_config_dir, &disable_apps, &disable_cgroups, freq)) {
-            info("Does not have a stock file. It is starting with default options.");
+            netdata_info("Does not have a stock file. It is starting with default options.");
         }
     }
 
@@ -2154,112 +2154,112 @@ static void ebpf_parse_args(int argc, char **argv)
             case EBPF_MODULE_PROCESS_IDX: {
                 select_threads |= 1<<EBPF_MODULE_PROCESS_IDX;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF enabling \"PROCESS\" charts, because it was started with the option \"[-]-process\".");
+                netdata_info("EBPF enabling \"PROCESS\" charts, because it was started with the option \"[-]-process\".");
 #endif
                 break;
             }
             case EBPF_MODULE_SOCKET_IDX: {
                 select_threads |= 1<<EBPF_MODULE_SOCKET_IDX;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF enabling \"NET\" charts, because it was started with the option \"[-]-net\".");
+                netdata_info("EBPF enabling \"NET\" charts, because it was started with the option \"[-]-net\".");
 #endif
                 break;
             }
             case EBPF_MODULE_CACHESTAT_IDX: {
                 select_threads |= 1<<EBPF_MODULE_CACHESTAT_IDX;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF enabling \"CACHESTAT\" charts, because it was started with the option \"[-]-cachestat\".");
+                netdata_info("EBPF enabling \"CACHESTAT\" charts, because it was started with the option \"[-]-cachestat\".");
 #endif
                 break;
             }
             case EBPF_MODULE_SYNC_IDX: {
                 select_threads |= 1<<EBPF_MODULE_SYNC_IDX;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF enabling \"SYNC\" chart, because it was started with the option \"[-]-sync\".");
+                netdata_info("EBPF enabling \"SYNC\" chart, because it was started with the option \"[-]-sync\".");
 #endif
                 break;
             }
             case EBPF_MODULE_DCSTAT_IDX: {
                 select_threads |= 1<<EBPF_MODULE_DCSTAT_IDX;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF enabling \"DCSTAT\" charts, because it was started with the option \"[-]-dcstat\".");
+                netdata_info("EBPF enabling \"DCSTAT\" charts, because it was started with the option \"[-]-dcstat\".");
 #endif
                 break;
             }
             case EBPF_MODULE_SWAP_IDX: {
                 select_threads |= 1<<EBPF_MODULE_SWAP_IDX;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF enabling \"SWAP\" chart, because it was started with the option \"[-]-swap\".");
+                netdata_info("EBPF enabling \"SWAP\" chart, because it was started with the option \"[-]-swap\".");
 #endif
                 break;
             }
             case EBPF_MODULE_VFS_IDX: {
                 select_threads |= 1<<EBPF_MODULE_VFS_IDX;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF enabling \"VFS\" chart, because it was started with the option \"[-]-vfs\".");
+                netdata_info("EBPF enabling \"VFS\" chart, because it was started with the option \"[-]-vfs\".");
 #endif
                 break;
             }
             case EBPF_MODULE_FILESYSTEM_IDX: {
                 select_threads |= 1<<EBPF_MODULE_FILESYSTEM_IDX;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF enabling \"FILESYSTEM\" chart, because it was started with the option \"[-]-filesystem\".");
+                netdata_info("EBPF enabling \"FILESYSTEM\" chart, because it was started with the option \"[-]-filesystem\".");
 #endif
                 break;
             }
             case EBPF_MODULE_DISK_IDX: {
                 select_threads |= 1<<EBPF_MODULE_DISK_IDX;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF enabling \"DISK\" chart, because it was started with the option \"[-]-disk\".");
+                netdata_info("EBPF enabling \"DISK\" chart, because it was started with the option \"[-]-disk\".");
 #endif
                 break;
             }
             case EBPF_MODULE_MOUNT_IDX: {
                 select_threads |= 1<<EBPF_MODULE_MOUNT_IDX;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF enabling \"MOUNT\" chart, because it was started with the option \"[-]-mount\".");
+                netdata_info("EBPF enabling \"MOUNT\" chart, because it was started with the option \"[-]-mount\".");
 #endif
                 break;
             }
             case EBPF_MODULE_FD_IDX: {
                 select_threads |= 1<<EBPF_MODULE_FD_IDX;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF enabling \"FILEDESCRIPTOR\" chart, because it was started with the option \"[-]-filedescriptor\".");
+                netdata_info("EBPF enabling \"FILEDESCRIPTOR\" chart, because it was started with the option \"[-]-filedescriptor\".");
 #endif
                 break;
             }
             case EBPF_MODULE_HARDIRQ_IDX: {
                 select_threads |= 1<<EBPF_MODULE_HARDIRQ_IDX;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF enabling \"HARDIRQ\" chart, because it was started with the option \"[-]-hardirq\".");
+                netdata_info("EBPF enabling \"HARDIRQ\" chart, because it was started with the option \"[-]-hardirq\".");
 #endif
                 break;
             }
             case EBPF_MODULE_SOFTIRQ_IDX: {
                 select_threads |= 1<<EBPF_MODULE_SOFTIRQ_IDX;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF enabling \"SOFTIRQ\" chart, because it was started with the option \"[-]-softirq\".");
+                netdata_info("EBPF enabling \"SOFTIRQ\" chart, because it was started with the option \"[-]-softirq\".");
 #endif
                 break;
             }
             case EBPF_MODULE_OOMKILL_IDX: {
                 select_threads |= 1<<EBPF_MODULE_OOMKILL_IDX;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF enabling \"OOMKILL\" chart, because it was started with the option \"[-]-oomkill\".");
+                netdata_info("EBPF enabling \"OOMKILL\" chart, because it was started with the option \"[-]-oomkill\".");
 #endif
                 break;
             }
             case EBPF_MODULE_SHM_IDX: {
                 select_threads |= 1<<EBPF_MODULE_SHM_IDX;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF enabling \"SHM\" chart, because it was started with the option \"[-]-shm\".");
+                netdata_info("EBPF enabling \"SHM\" chart, because it was started with the option \"[-]-shm\".");
 #endif
                 break;
             }
             case EBPF_MODULE_MDFLUSH_IDX: {
                 select_threads |= 1<<EBPF_MODULE_MDFLUSH_IDX;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF enabling \"MDFLUSH\" chart, because it was started with the option \"[-]-mdflush\".");
+                netdata_info("EBPF enabling \"MDFLUSH\" chart, because it was started with the option \"[-]-mdflush\".");
 #endif
                 break;
             }
@@ -2267,7 +2267,7 @@ static void ebpf_parse_args(int argc, char **argv)
                 disable_apps = 0;
                 disable_cgroups = 0;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF running with all chart groups, because it was started with the option \"[-]-all\".");
+                netdata_info("EBPF running with all chart groups, because it was started with the option \"[-]-all\".");
 #endif
                 break;
             }
@@ -2283,28 +2283,28 @@ static void ebpf_parse_args(int argc, char **argv)
                 disable_apps = 1;
                 disable_cgroups = 1;
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF running with global chart group, because it was started with the option  \"[-]-global\".");
+                netdata_info("EBPF running with global chart group, because it was started with the option  \"[-]-global\".");
 #endif
                 break;
             }
             case EBPF_OPTION_RETURN_MODE: {
                 ebpf_set_thread_mode(MODE_RETURN);
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF running in \"RETURN\" mode, because it was started with the option \"[-]-return\".");
+                netdata_info("EBPF running in \"RETURN\" mode, because it was started with the option \"[-]-return\".");
 #endif
                 break;
             }
             case EBPF_OPTION_LEGACY: {
                 ebpf_set_load_mode(EBPF_LOAD_LEGACY, EBPF_LOADED_FROM_USER);
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF running with \"LEGACY\" code, because it was started with the option \"[-]-legacy\".");
+                netdata_info("EBPF running with \"LEGACY\" code, because it was started with the option \"[-]-legacy\".");
 #endif
                 break;
             }
             case EBPF_OPTION_CORE: {
                 ebpf_set_load_mode(EBPF_LOAD_CORE, EBPF_LOADED_FROM_USER);
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("EBPF running with \"CO-RE\" code, because it was started with the option \"[-]-core\".");
+                netdata_info("EBPF running with \"CO-RE\" code, because it was started with the option \"[-]-core\".");
 #endif
                 break;
             }
@@ -2361,7 +2361,7 @@ unittest:
     // Load apps_groups.conf
     if (ebpf_read_apps_groups_conf(
             &apps_groups_default_target, &apps_groups_root_target, ebpf_user_config_dir, "groups")) {
-        info("Cannot read process groups configuration file '%s/apps_groups.conf'. Will try '%s/apps_groups.conf'",
+        netdata_info("Cannot read process groups configuration file '%s/apps_groups.conf'. Will try '%s/apps_groups.conf'",
              ebpf_user_config_dir, ebpf_stock_config_dir);
         if (ebpf_read_apps_groups_conf(
                 &apps_groups_default_target, &apps_groups_root_target, ebpf_stock_config_dir, "groups")) {
@@ -2370,7 +2370,7 @@ unittest:
             ebpf_exit();
         }
     } else
-        info("Loaded config file '%s/apps_groups.conf'", ebpf_user_config_dir);
+        netdata_info("Loaded config file '%s/apps_groups.conf'", ebpf_user_config_dir);
 }
 
 /*****************************************************************
diff --git a/collectors/ebpf.plugin/ebpf_apps.c b/collectors/ebpf.plugin/ebpf_apps.c
index 3826f8e..d57b2d2 100644
--- a/collectors/ebpf.plugin/ebpf_apps.c
+++ b/collectors/ebpf.plugin/ebpf_apps.c
@@ -44,7 +44,7 @@ void ebpf_aral_init(void)
     ebpf_aral_process_stat = ebpf_allocate_pid_aral(NETDATA_EBPF_PROC_ARAL_NAME, sizeof(ebpf_process_stat_t));
 
 #ifdef NETDATA_DEV_MODE
-    info("Plugin is using ARAL with values %d", NETDATA_EBPF_ALLOC_MAX_PID);
+    netdata_info("Plugin is using ARAL with values %d", NETDATA_EBPF_ALLOC_MAX_PID);
 #endif
 }
 
diff --git a/collectors/ebpf.plugin/ebpf_cgroup.c b/collectors/ebpf.plugin/ebpf_cgroup.c
index 6d7c555..0c44e76 100644
--- a/collectors/ebpf.plugin/ebpf_cgroup.c
+++ b/collectors/ebpf.plugin/ebpf_cgroup.c
@@ -303,7 +303,7 @@ void ebpf_parse_cgroup_shm_data()
     sem_post(shm_sem_ebpf_cgroup);
     pthread_mutex_unlock(&mutex_cgroup_shm);
 #ifdef NETDATA_DEV_MODE
-    info("Updating cgroup %d (Previous: %d, Current: %d)",
+    netdata_info("Updating cgroup %d (Previous: %d, Current: %d)",
          send_cgroup_chart, previous, shm_ebpf_cgroup.header->cgroup_root_count);
 #endif
 
diff --git a/collectors/ebpf.plugin/ebpf_dcstat.c b/collectors/ebpf.plugin/ebpf_dcstat.c
index 4157f0c..073ef3d 100644
--- a/collectors/ebpf.plugin/ebpf_dcstat.c
+++ b/collectors/ebpf.plugin/ebpf_dcstat.c
@@ -195,7 +195,7 @@ netdata_ebpf_program_loaded_t ebpf_dc_update_load(ebpf_module_t *em)
         return EBPF_LOAD_TRAMPOLINE;
 
     if (em->targets[NETDATA_DC_TARGET_LOOKUP_FAST].mode != EBPF_LOAD_RETPROBE)
-        info("When your kernel was compiled the symbol %s was modified, instead to use `trampoline`, the plugin will use `probes`.",
+        netdata_info("When your kernel was compiled the symbol %s was modified, instead to use `trampoline`, the plugin will use `probes`.",
              dc_optional_name[NETDATA_DC_TARGET_LOOKUP_FAST].function_to_attach);
 
     return EBPF_LOAD_RETPROBE;
diff --git a/collectors/ebpf.plugin/ebpf_disk.c b/collectors/ebpf.plugin/ebpf_disk.c
index 231186b..97a52d1 100644
--- a/collectors/ebpf.plugin/ebpf_disk.c
+++ b/collectors/ebpf.plugin/ebpf_disk.c
@@ -311,7 +311,7 @@ static void update_disk_table(char *name, int major, int minor, time_t current_t
         error("Internal error, cannot insert the AVL tree.");
 
 #ifdef NETDATA_INTERNAL_CHECKS
-    info("The Latency is monitoring the hard disk %s (Major = %d, Minor = %d, Device = %u)", name, major, minor,w->dev);
+    netdata_info("The Latency is monitoring the hard disk %s (Major = %d, Minor = %d, Device = %u)", name, major, minor,w->dev);
 #endif
 
     w->flags |= NETDATA_DISK_IS_HERE;
diff --git a/collectors/ebpf.plugin/ebpf_filesystem.c b/collectors/ebpf.plugin/ebpf_filesystem.c
index 63f592e..5542e6f 100644
--- a/collectors/ebpf.plugin/ebpf_filesystem.c
+++ b/collectors/ebpf.plugin/ebpf_filesystem.c
@@ -685,7 +685,7 @@ void *ebpf_filesystem_thread(void *ptr)
 
     if (ebpf_update_partitions(em)) {
         if (em->optional)
-            info("Netdata cannot monitor the filesystems used on this host.");
+            netdata_info("Netdata cannot monitor the filesystems used on this host.");
 
         goto endfilesystem;
     }
diff --git a/collectors/ebpf.plugin/ebpf_oomkill.c b/collectors/ebpf.plugin/ebpf_oomkill.c
index c80f448..f320207 100644
--- a/collectors/ebpf.plugin/ebpf_oomkill.c
+++ b/collectors/ebpf.plugin/ebpf_oomkill.c
@@ -379,14 +379,14 @@ void *ebpf_oomkill_thread(void *ptr)
         // we need to disable it.
         pthread_mutex_lock(&ebpf_exit_cleanup);
         if (em->enabled)
-            info("%s apps integration is completely disabled.", NETDATA_DEFAULT_OOM_DISABLED_MSG);
+            netdata_info("%s apps integration is completely disabled.", NETDATA_DEFAULT_OOM_DISABLED_MSG);
         pthread_mutex_unlock(&ebpf_exit_cleanup);
 
         goto endoomkill;
     } else if (running_on_kernel < NETDATA_EBPF_KERNEL_4_14) {
         pthread_mutex_lock(&ebpf_exit_cleanup);
         if (em->enabled)
-            info("%s kernel does not have necessary tracepoints.", NETDATA_DEFAULT_OOM_DISABLED_MSG);
+            netdata_info("%s kernel does not have necessary tracepoints.", NETDATA_DEFAULT_OOM_DISABLED_MSG);
         pthread_mutex_unlock(&ebpf_exit_cleanup);
 
         goto endoomkill;
diff --git a/collectors/ebpf.plugin/ebpf_socket.c b/collectors/ebpf.plugin/ebpf_socket.c
index b45dec7..d943b16 100644
--- a/collectors/ebpf.plugin/ebpf_socket.c
+++ b/collectors/ebpf.plugin/ebpf_socket.c
@@ -1844,7 +1844,7 @@ static void fill_last_nv_dimension(netdata_socket_plot_t *ptr, int is_outbound)
     fill_resolved_name(ptr, hostname,  10 + NETDATA_DOTS_PROTOCOL_COMBINED_LENGTH, service_name, is_outbound);
 
 #ifdef NETDATA_INTERNAL_CHECKS
-    info("Last %s dimension added: ID = %u, IP = OTHER, NAME = %s, DIM1 = %s, DIM2 = %s, DIM3 = %s",
+    netdata_info("Last %s dimension added: ID = %u, IP = OTHER, NAME = %s, DIM1 = %s, DIM2 = %s, DIM3 = %s",
          (is_outbound)?"outbound":"inbound", network_viewer_opt.max_dim - 1, ptr->resolved_name,
          ptr->dimension_recv, ptr->dimension_sent, ptr->dimension_retransmit);
 #endif
@@ -1932,7 +1932,7 @@ static void store_socket_inside_avl(netdata_vector_plot_t *out, netdata_socket_t
 #ifdef NETDATA_INTERNAL_CHECKS
         char iptext[INET6_ADDRSTRLEN];
         if (inet_ntop(family, &w->index.daddr.addr8, iptext, sizeof(iptext)))
-            info("New %s dimension added: ID = %u, IP = %s, NAME = %s, DIM1 = %s, DIM2 = %s, DIM3 = %s",
+            netdata_info("New %s dimension added: ID = %u, IP = %s, NAME = %s, DIM1 = %s, DIM2 = %s, DIM3 = %s",
                  (out == &inbound_vectors)?"inbound":"outbound", curr, iptext, w->resolved_name,
                  w->dimension_recv, w->dimension_sent, w->dimension_retransmit);
 #endif
@@ -2120,7 +2120,7 @@ void update_listen_table(uint16_t value, uint16_t proto, netdata_passive_connect
     fill_nv_port_list(w, value, proto, in);
 
 #ifdef NETDATA_INTERNAL_CHECKS
-    info("The network viewer is monitoring inbound connections for port %u", ntohs(value));
+    netdata_info("The network viewer is monitoring inbound connections for port %u", ntohs(value));
 #endif
 }
 
@@ -3044,14 +3044,14 @@ static inline void fill_port_list(ebpf_network_viewer_port_list_t **out, ebpf_ne
             uint16_t cmp_last = ntohs(move->last);
             if (cmp_first <= first && first <= cmp_last  &&
                 cmp_first <= last && last <= cmp_last ) {
-                info("The range/value (%u, %u) is inside the range/value (%u, %u) already inserted, it will be ignored.",
+                netdata_info("The range/value (%u, %u) is inside the range/value (%u, %u) already inserted, it will be ignored.",
                      first, last, cmp_first, cmp_last);
                 freez(in->value);
                 freez(in);
                 return;
             } else if (first <= cmp_first && cmp_first <= last  &&
                        first <= cmp_last && cmp_last <= last) {
-                info("The range (%u, %u) is bigger than previous range (%u, %u) already inserted, the previous will be ignored.",
+                netdata_info("The range (%u, %u) is bigger than previous range (%u, %u) already inserted, the previous will be ignored.",
                      first, last, cmp_first, cmp_last);
                 freez(move->value);
                 move->value = in->value;
@@ -3071,7 +3071,7 @@ static inline void fill_port_list(ebpf_network_viewer_port_list_t **out, ebpf_ne
     }
 
 #ifdef NETDATA_INTERNAL_CHECKS
-    info("Adding values %s( %u, %u) to %s port list used on network viewer",
+    netdata_info("Adding values %s( %u, %u) to %s port list used on network viewer",
          in->value, ntohs(in->first), ntohs(in->last),
          (*out == network_viewer_opt.included_port)?"included":"excluded");
 #endif
@@ -3091,7 +3091,7 @@ static void parse_service_list(void **out, char *service)
         serv = getservbyname((const char *)service, "udp");
 
     if (!serv) {
-        info("Cannot resolv the service '%s' with protocols TCP and UDP, it will be ignored", service);
+        netdata_info("Cannot resolv the service '%s' with protocols TCP and UDP, it will be ignored", service);
         return;
     }
 
@@ -3301,7 +3301,7 @@ void ebpf_fill_ip_list(ebpf_network_viewer_ip_list_t **out, ebpf_network_viewer_
         while (move) {
             if (in->ver == move->ver &&
                 ebpf_is_ip_inside_range(&move->first, &move->last, &in->first, &in->last, in->ver)) {
-                info("The range/value (%s) is inside the range/value (%s) already inserted, it will be ignored.",
+                netdata_info("The range/value (%s) is inside the range/value (%s) already inserted, it will be ignored.",
                      in->value, move->value);
                 freez(in->value);
                 freez(in);
@@ -3319,14 +3319,14 @@ void ebpf_fill_ip_list(ebpf_network_viewer_ip_list_t **out, ebpf_network_viewer_
 #ifdef NETDATA_INTERNAL_CHECKS
     char first[256], last[512];
     if (in->ver == AF_INET) {
-        info("Adding values %s: (%u - %u) to %s IP list \"%s\" used on network viewer",
+        netdata_info("Adding values %s: (%u - %u) to %s IP list \"%s\" used on network viewer",
              in->value, in->first.addr32[0], in->last.addr32[0],
              (*out == network_viewer_opt.included_ips)?"included":"excluded",
              table);
     } else {
         if (inet_ntop(AF_INET6, in->first.addr8, first, INET6_ADDRSTRLEN) &&
             inet_ntop(AF_INET6, in->last.addr8, last, INET6_ADDRSTRLEN))
-            info("Adding values %s - %s to %s IP list \"%s\" used on network viewer",
+            netdata_info("Adding values %s - %s to %s IP list \"%s\" used on network viewer",
                  first, last,
                  (*out == network_viewer_opt.included_ips)?"included":"excluded",
                  table);
@@ -3373,7 +3373,7 @@ static void ebpf_parse_ip_list(void **out, char *ip)
         select = (*end == '/') ? 0 : 1;
         *end++ = '\0';
         if (*end == '!') {
-            info("The exclusion cannot be in the second part of the range %s, it will be ignored.", ipdup);
+            netdata_info("The exclusion cannot be in the second part of the range %s, it will be ignored.", ipdup);
             goto cleanipdup;
         }
 
@@ -3384,7 +3384,7 @@ static void ebpf_parse_ip_list(void **out, char *ip)
 
             select = (int) str2i(end);
             if (select < NETDATA_MINIMUM_IPV4_CIDR || select > NETDATA_MAXIMUM_IPV4_CIDR) {
-                info("The specified CIDR %s is not valid, the IP %s will be ignored.", end, ip);
+                netdata_info("The specified CIDR %s is not valid, the IP %s will be ignored.", end, ip);
                 goto cleanipdup;
             }
 
@@ -3400,7 +3400,7 @@ static void ebpf_parse_ip_list(void **out, char *ip)
                 ipv4_convert.s_addr = ipv4_test;
                 char ipv4_msg[INET_ADDRSTRLEN];
                 if(inet_ntop(AF_INET, &ipv4_convert, ipv4_msg, INET_ADDRSTRLEN))
-                    info("The network value of CIDR %s was updated for %s .", ipdup, ipv4_msg);
+                    netdata_info("The network value of CIDR %s was updated for %s .", ipdup, ipv4_msg);
             }
         } else { // Range
             select = ip2nl(first.addr8, ip, AF_INET, ipdup);
@@ -3413,7 +3413,7 @@ static void ebpf_parse_ip_list(void **out, char *ip)
         }
 
         if (htonl(first.addr32[0]) > htonl(last.addr32[0])) {
-            info("The specified range %s is invalid, the second address is smallest than the first, it will be ignored.",
+            netdata_info("The specified range %s is invalid, the second address is smallest than the first, it will be ignored.",
                  ipdup);
             goto cleanipdup;
         }
@@ -3427,7 +3427,7 @@ static void ebpf_parse_ip_list(void **out, char *ip)
         } else if (*end == '-') {
             *end++ = 0x00;
             if (*end == '!') {
-                info("The exclusion cannot be in the second part of the range %s, it will be ignored.", ipdup);
+                netdata_info("The exclusion cannot be in the second part of the range %s, it will be ignored.", ipdup);
                 goto cleanipdup;
             }
 
@@ -3441,13 +3441,13 @@ static void ebpf_parse_ip_list(void **out, char *ip)
         } else { // CIDR
             *end++ = 0x00;
             if (*end == '!') {
-                info("The exclusion cannot be in the second part of the range %s, it will be ignored.", ipdup);
+                netdata_info("The exclusion cannot be in the second part of the range %s, it will be ignored.", ipdup);
                 goto cleanipdup;
             }
 
             select = str2i(end);
             if (select < 0 || select > 128) {
-                info("The CIDR %s is not valid, the address %s will be ignored.", end, ip);
+                netdata_info("The CIDR %s is not valid, the address %s will be ignored.", end, ip);
                 goto cleanipdup;
             }
 
@@ -3469,14 +3469,14 @@ static void ebpf_parse_ip_list(void **out, char *ip)
 
                 char ipv6_msg[INET6_ADDRSTRLEN];
                 if(inet_ntop(AF_INET6, &ipv6_convert, ipv6_msg, INET6_ADDRSTRLEN))
-                    info("The network value of CIDR %s was updated for %s .", ipdup, ipv6_msg);
+                    netdata_info("The network value of CIDR %s was updated for %s .", ipdup, ipv6_msg);
             }
         }
 
         if ((be64toh(*(uint64_t *)&first.addr32[2]) > be64toh(*(uint64_t *)&last.addr32[2]) &&
              !memcmp(first.addr32, last.addr32, 2*sizeof(uint32_t))) ||
             (be64toh(*(uint64_t *)&first.addr32) > be64toh(*(uint64_t *)&last.addr32)) ) {
-            info("The specified range %s is invalid, the second address is smallest than the first, it will be ignored.",
+            netdata_info("The specified range %s is invalid, the second address is smallest than the first, it will be ignored.",
                  ipdup);
             goto cleanipdup;
         }
@@ -3580,7 +3580,7 @@ static void parse_port_list(void **out, char *range)
     if (likely(*end)) {
         *end++ = '\0';
         if (*end == '!') {
-            info("The exclusion cannot be in the second part of the range, the range %s will be ignored.", copied);
+            netdata_info("The exclusion cannot be in the second part of the range, the range %s will be ignored.", copied);
             freez(copied);
             return;
         }
@@ -3591,7 +3591,7 @@ static void parse_port_list(void **out, char *range)
 
     first = str2i((const char *)range);
     if (first < NETDATA_MINIMUM_PORT_VALUE || first > NETDATA_MAXIMUM_PORT_VALUE) {
-        info("The first port %d of the range \"%s\" is invalid and it will be ignored!", first, copied);
+        netdata_info("The first port %d of the range \"%s\" is invalid and it will be ignored!", first, copied);
         freez(copied);
         return;
     }
@@ -3600,13 +3600,13 @@ static void parse_port_list(void **out, char *range)
         last = first;
 
     if (last < NETDATA_MINIMUM_PORT_VALUE || last > NETDATA_MAXIMUM_PORT_VALUE) {
-        info("The second port %d of the range \"%s\" is invalid and the whole range will be ignored!", last, copied);
+        netdata_info("The second port %d of the range \"%s\" is invalid and the whole range will be ignored!", last, copied);
         freez(copied);
         return;
     }
 
     if (first > last) {
-        info("The specified order %s is wrong, the smallest value is always the first, it will be ignored!", copied);
+        netdata_info("The specified order %s is wrong, the smallest value is always the first, it will be ignored!", copied);
         freez(copied);
         return;
     }
@@ -3646,7 +3646,7 @@ static void read_max_dimension(struct config *cfg)
 
     maxdim /= 2;
     if (!maxdim) {
-        info("The number of dimensions is too small (%u), we are setting it to minimum 2", network_viewer_opt.max_dim);
+        netdata_info("The number of dimensions is too small (%u), we are setting it to minimum 2", network_viewer_opt.max_dim);
         network_viewer_opt.max_dim = 1;
         return;
     }
@@ -3714,7 +3714,7 @@ static void link_hostname(ebpf_network_viewer_hostname_list_t **out, ebpf_networ
         ebpf_network_viewer_hostname_list_t *move = *out;
         for (; move->next ; move = move->next ) {
             if (move->hash == in->hash && !strcmp(move->value, in->value)) {
-                info("The hostname %s was already inserted, it will be ignored.", in->value);
+                netdata_info("The hostname %s was already inserted, it will be ignored.", in->value);
                 freez(in->value);
                 simple_pattern_free(in->value_pattern);
                 freez(in);
@@ -3727,7 +3727,7 @@ static void link_hostname(ebpf_network_viewer_hostname_list_t **out, ebpf_networ
         *out = in;
     }
 #ifdef NETDATA_INTERNAL_CHECKS
-    info("Adding value %s to %s hostname list used on network viewer",
+    netdata_info("Adding value %s to %s hostname list used on network viewer",
          in->value,
          (*out == network_viewer_opt.included_hostnames)?"included":"excluded");
 #endif
@@ -3806,7 +3806,7 @@ void parse_network_viewer_section(struct config *cfg)
         value = appconfig_get(cfg, EBPF_NETWORK_VIEWER_SECTION, EBPF_CONFIG_HOSTNAMES, NULL);
         link_hostnames(value);
     } else {
-        info("Name resolution is disabled, collector will not parser \"hostnames\" list.");
+        netdata_info("Name resolution is disabled, collector will not parser \"hostnames\" list.");
     }
 
     value = appconfig_get(cfg, EBPF_NETWORK_VIEWER_SECTION,
@@ -3845,7 +3845,7 @@ static void link_dimension_name(char *port, uint32_t hash, char *value)
     } else {
         for (; names->next; names = names->next) {
             if (names->port == w->port) {
-                info("Duplicated definition for a service, the name %s will be ignored. ", names->name);
+                netdata_info("Duplicated definition for a service, the name %s will be ignored. ", names->name);
                 freez(names->name);
                 names->name = w->name;
                 names->hash = w->hash;
@@ -3857,7 +3857,7 @@ static void link_dimension_name(char *port, uint32_t hash, char *value)
     }
 
 #ifdef NETDATA_INTERNAL_CHECKS
-    info("Adding values %s( %u) to dimension name list used on network viewer", w->name, htons(w->port));
+    netdata_info("Adding values %s( %u) to dimension name list used on network viewer", w->name, htons(w->port));
 #endif
 }
 
diff --git a/collectors/ebpf.plugin/ebpf_sync.c b/collectors/ebpf.plugin/ebpf_sync.c
index 9f1c015..dc98ef4 100644
--- a/collectors/ebpf.plugin/ebpf_sync.c
+++ b/collectors/ebpf.plugin/ebpf_sync.c
@@ -373,7 +373,7 @@ static int ebpf_sync_initialize_syscall(ebpf_module_t *em)
                         }
                     }
                 } else {
-                    info("Cannot find syscall %s we are not going to monitor it.", syscall);
+                    netdata_info("Cannot find syscall %s we are not going to monitor it.", syscall);
                     w->enabled = false;
                 }
 
diff --git a/collectors/plugins.d/plugins_d.c b/collectors/plugins.d/plugins_d.c
index da5226a..2f560cb 100644
--- a/collectors/plugins.d/plugins_d.c
+++ b/collectors/plugins.d/plugins_d.c
@@ -65,11 +65,11 @@ static void pluginsd_worker_thread_cleanup(void *arg)
 
     if (pid) {
         siginfo_t info;
-        info("PLUGINSD: 'host:%s', killing data collection child process with pid %d",
+        netdata_info("PLUGINSD: 'host:%s', killing data collection child process with pid %d",
              rrdhost_hostname(cd->host), pid);
 
         if (killpid(pid) != -1) {
-            info("PLUGINSD: 'host:%s', waiting for data collection child process pid %d to exit...",
+            netdata_info("PLUGINSD: 'host:%s', waiting for data collection child process pid %d to exit...",
                  rrdhost_hostname(cd->host), pid);
 
             netdata_waitid(P_PID, (id_t)pid, &info, WEXITED);
@@ -85,7 +85,7 @@ static void pluginsd_worker_thread_handle_success(struct plugind *cd) {
     }
 
     if (likely(cd->serial_failures <= SERIAL_FAILURES_THRESHOLD)) {
-        info("PLUGINSD: 'host:%s', '%s' (pid %d) does not generate useful output but it reports success (exits with 0). %s.",
+        netdata_info("PLUGINSD: 'host:%s', '%s' (pid %d) does not generate useful output but it reports success (exits with 0). %s.",
              rrdhost_hostname(cd->host), cd->fullfilename, cd->unsafe.pid,
              plugin_is_enabled(cd) ? "Waiting a bit before starting it again." : "Will not start it again - it is now disabled.");
 
@@ -105,7 +105,7 @@ static void pluginsd_worker_thread_handle_success(struct plugind *cd) {
 
 static void pluginsd_worker_thread_handle_error(struct plugind *cd, int worker_ret_code) {
     if (worker_ret_code == -1) {
-        info("PLUGINSD: 'host:%s', '%s' (pid %d) was killed with SIGTERM. Disabling it.",
+        netdata_info("PLUGINSD: 'host:%s', '%s' (pid %d) was killed with SIGTERM. Disabling it.",
              rrdhost_hostname(cd->host), cd->fullfilename, cd->unsafe.pid);
         plugin_set_disabled(cd);
         return;
@@ -157,12 +157,12 @@ static void *pluginsd_worker_thread(void *arg) {
             break;
         }
 
-        info("PLUGINSD: 'host:%s' connected to '%s' running on pid %d",
+        netdata_info("PLUGINSD: 'host:%s' connected to '%s' running on pid %d",
              rrdhost_hostname(cd->host), cd->fullfilename, cd->unsafe.pid);
 
         count = pluginsd_process(cd->host, cd, fp_child_input, fp_child_output, 0);
 
-        info("PLUGINSD: 'host:%s', '%s' (pid %d) disconnected after %zu successful data collections (ENDs).",
+        netdata_info("PLUGINSD: 'host:%s', '%s' (pid %d) disconnected after %zu successful data collections (ENDs).",
               rrdhost_hostname(cd->host), cd->fullfilename, cd->unsafe.pid, count);
 
         killpid(cd->unsafe.pid);
@@ -186,13 +186,13 @@ static void *pluginsd_worker_thread(void *arg) {
 static void pluginsd_main_cleanup(void *data) {
     struct netdata_static_thread *static_thread = (struct netdata_static_thread *)data;
     static_thread->enabled = NETDATA_MAIN_THREAD_EXITING;
-    info("PLUGINSD: cleaning up...");
+    netdata_info("PLUGINSD: cleaning up...");
 
     struct plugind *cd;
     for (cd = pluginsd_root; cd; cd = cd->next) {
         netdata_spinlock_lock(&cd->unsafe.spinlock);
         if (cd->unsafe.enabled && cd->unsafe.running && cd->unsafe.thread != 0) {
-            info("PLUGINSD: 'host:%s', stopping plugin thread: %s",
+            netdata_info("PLUGINSD: 'host:%s', stopping plugin thread: %s",
                  rrdhost_hostname(cd->host), cd->id);
 
             netdata_thread_cancel(cd->unsafe.thread);
@@ -200,7 +200,7 @@ static void pluginsd_main_cleanup(void *data) {
         netdata_spinlock_unlock(&cd->unsafe.spinlock);
     }
 
-    info("PLUGINSD: cleanup completed.");
+    netdata_info("PLUGINSD: cleanup completed.");
     static_thread->enabled = NETDATA_MAIN_THREAD_EXITED;
 
     worker_unregister();
diff --git a/collectors/plugins.d/pluginsd_parser.c b/collectors/plugins.d/pluginsd_parser.c
index 097e5ea..cdf4683 100644
--- a/collectors/plugins.d/pluginsd_parser.c
+++ b/collectors/plugins.d/pluginsd_parser.c
@@ -1030,7 +1030,7 @@ PARSER_RC pluginsd_flush(char **words __maybe_unused, size_t num_words __maybe_u
 
 PARSER_RC pluginsd_disable(char **words __maybe_unused, size_t num_words __maybe_unused, void *user __maybe_unused)
 {
-    info("PLUGINSD: plugin called DISABLE. Disabling it.");
+    netdata_info("PLUGINSD: plugin called DISABLE. Disabling it.");
     ((PARSER_USER_OBJECT *) user)->enabled = 0;
     return PARSER_RC_STOP;
 }
@@ -1911,7 +1911,7 @@ inline size_t pluginsd_process(RRDHOST *host, struct plugind *cd, FILE *fp_plugi
 
 PARSER_RC pluginsd_exit(char **words __maybe_unused, size_t num_words __maybe_unused, void *user __maybe_unused)
 {
-    info("PLUGINSD: plugin called EXIT.");
+    netdata_info("PLUGINSD: plugin called EXIT.");
     return PARSER_RC_STOP;
 }
 
@@ -2036,9 +2036,9 @@ int pluginsd_parser_unittest(void) {
 
     for(h = 0; hashers[h].name ;h++) {
         if(hashers[h].slots_needed > 1000)
-            info("PARSER: hash function '%s' cannot be used without collisions under %zu slots", hashers[h].name, slots_to_check);
+            netdata_info("PARSER: hash function '%s' cannot be used without collisions under %zu slots", hashers[h].name, slots_to_check);
         else
-            info("PARSER: hash function '%s' needs PARSER_KEYWORDS_HASHTABLE_SIZE (in parser.h) set to %zu", hashers[h].name, hashers[h].slots_needed);
+            netdata_info("PARSER: hash function '%s' needs PARSER_KEYWORDS_HASHTABLE_SIZE (in parser.h) set to %zu", hashers[h].name, hashers[h].slots_needed);
     }
 
     p = parser_init(NULL, NULL, NULL, -1, PARSER_INPUT_SPLIT, NULL);
diff --git a/collectors/timex.plugin/plugin_timex.c b/collectors/timex.plugin/plugin_timex.c
index 84147c8..864ec0e 100644
--- a/collectors/timex.plugin/plugin_timex.c
+++ b/collectors/timex.plugin/plugin_timex.c
@@ -37,7 +37,7 @@ static void timex_main_cleanup(void *ptr)
     struct netdata_static_thread *static_thread = (struct netdata_static_thread *)ptr;
     static_thread->enabled = NETDATA_MAIN_THREAD_EXITING;
 
-    info("cleaning up...");
+    netdata_info("cleaning up...");
 
     static_thread->enabled = NETDATA_MAIN_THREAD_EXITED;
 }
@@ -57,7 +57,7 @@ void *timex_main(void *ptr)
     int do_offset = config_get_boolean(CONFIG_SECTION_TIMEX, "time offset", CONFIG_BOOLEAN_YES);
 
     if (unlikely(do_sync == CONFIG_BOOLEAN_NO && do_offset == CONFIG_BOOLEAN_NO)) {
-        info("No charts to show");
+        netdata_info("No charts to show");
         goto exit;
     }
 
diff --git a/collectors/xenstat.plugin/xenstat_plugin.c b/collectors/xenstat.plugin/xenstat_plugin.c
index b0cfa0b..a4eb9ae 100644
--- a/collectors/xenstat.plugin/xenstat_plugin.c
+++ b/collectors/xenstat.plugin/xenstat_plugin.c
@@ -1066,7 +1066,7 @@ int main(int argc, char **argv) {
 
     libxl_ctx_free(ctx);
     xenstat_uninit(xhandle);
-    info("XENSTAT process exiting");
+    netdata_info("XENSTAT process exiting");
     
     return 0;
 }
diff --git a/daemon/analytics.c b/daemon/analytics.c
index 2689886..2173b44 100644
--- a/daemon/analytics.c
+++ b/daemon/analytics.c
@@ -314,7 +314,7 @@ void analytics_alarms_notifications(void)
         sizeof(char) * (strlen(netdata_configured_primary_plugins_dir) + strlen("alarm-notify.sh dump_methods") + 2));
     sprintf(script, "%s/%s", netdata_configured_primary_plugins_dir, "alarm-notify.sh");
     if (unlikely(access(script, R_OK) != 0)) {
-        info("Alarm notify script %s not found.", script);
+        netdata_info("Alarm notify script %s not found.", script);
         freez(script);
         return;
     }
@@ -698,13 +698,13 @@ void get_system_timezone(void)
     // use the TZ variable
     if (tz && *tz && *tz != ':') {
         timezone = tz;
-        info("TIMEZONE: using TZ variable '%s'", timezone);
+        netdata_info("TIMEZONE: using TZ variable '%s'", timezone);
     }
 
     // use the contents of /etc/timezone
     if (!timezone && !read_file("/etc/timezone", buffer, FILENAME_MAX)) {
         timezone = buffer;
-        info("TIMEZONE: using the contents of /etc/timezone");
+        netdata_info("TIMEZONE: using the contents of /etc/timezone");
     }
 
     // read the link /etc/localtime
@@ -720,7 +720,7 @@ void get_system_timezone(void)
             char *s = strstr(buffer, cmp);
             if (s && s[cmp_len]) {
                 timezone = &s[cmp_len];
-                info("TIMEZONE: using the link of /etc/localtime: '%s'", timezone);
+                netdata_info("TIMEZONE: using the link of /etc/localtime: '%s'", timezone);
             }
         } else
             buffer[0] = '\0';
@@ -740,7 +740,7 @@ void get_system_timezone(void)
             else {
                 buffer[FILENAME_MAX] = '\0';
                 timezone = buffer;
-                info("TIMEZONE: using strftime(): '%s'", timezone);
+                netdata_info("TIMEZONE: using strftime(): '%s'", timezone);
             }
         }
     }
@@ -763,7 +763,7 @@ void get_system_timezone(void)
         *d = '\0';
         strncpyz(buffer, tmp, len);
         timezone = buffer;
-        info("TIMEZONE: fixed as '%s'", timezone);
+        netdata_info("TIMEZONE: fixed as '%s'", timezone);
     }
 
     if (!timezone || !*timezone)
@@ -944,7 +944,7 @@ void send_statistics(const char *action, const char *action_result, const char *
             sprintf(as_script, "%s/%s", netdata_configured_primary_plugins_dir, "anonymous-statistics.sh");
             if (unlikely(access(as_script, R_OK) != 0)) {
                 netdata_anonymous_statistics_enabled = 0;
-                info("Anonymous statistics script %s not found.", as_script);
+                netdata_info("Anonymous statistics script %s not found.", as_script);
                 freez(as_script);
             } else {
                 netdata_anonymous_statistics_enabled = 1;
@@ -1015,7 +1015,7 @@ void send_statistics(const char *action, const char *action_result, const char *
         analytics_data.netdata_config_oom_score,
         analytics_data.netdata_prebuilt_distro);
 
-    info("%s '%s' '%s' '%s'", as_script, action, action_result, action_data);
+    netdata_info("%s '%s' '%s' '%s'", as_script, action, action_result, action_data);
 
     FILE *fp_child_input;
     FILE *fp_child_output = netdata_popen(command_to_run, &command_pid, &fp_child_input);
diff --git a/daemon/commands.c b/daemon/commands.c
index fcb75b7..3b88e07 100644
--- a/daemon/commands.c
+++ b/daemon/commands.c
@@ -143,7 +143,7 @@ static cmd_status_t cmd_reload_health_execute(char *args, char **message)
     (void)message;
 
     error_log_limit_unlimited();
-    info("COMMAND: Reloading HEALTH configuration.");
+    netdata_info("COMMAND: Reloading HEALTH configuration.");
     health_reload();
     error_log_limit_reset();
 
@@ -156,9 +156,9 @@ static cmd_status_t cmd_save_database_execute(char *args, char **message)
     (void)message;
 
     error_log_limit_unlimited();
-    info("COMMAND: Saving databases.");
+    netdata_info("COMMAND: Saving databases.");
     rrdhost_save_all();
-    info("COMMAND: Databases saved.");
+    netdata_info("COMMAND: Databases saved.");
     error_log_limit_reset();
 
     return CMD_STATUS_SUCCESS;
@@ -170,7 +170,7 @@ static cmd_status_t cmd_reopen_logs_execute(char *args, char **message)
     (void)message;
 
     error_log_limit_unlimited();
-    info("COMMAND: Reopening all log files.");
+    netdata_info("COMMAND: Reopening all log files.");
     reopen_all_log_files();
     error_log_limit_reset();
 
@@ -183,7 +183,7 @@ static cmd_status_t cmd_exit_execute(char *args, char **message)
     (void)message;
 
     error_log_limit_unlimited();
-    info("COMMAND: Cleaning up to exit.");
+    netdata_info("COMMAND: Cleaning up to exit.");
     netdata_cleanup_and_exit(0);
     exit(0);
 
@@ -205,12 +205,12 @@ static cmd_status_t cmd_reload_claiming_state_execute(char *args, char **message
     (void)args;
     (void)message;
 #if defined(DISABLE_CLOUD) || !defined(ENABLE_ACLK)
-    info("The claiming feature has been explicitly disabled");
+    netdata_info("The claiming feature has been explicitly disabled");
     *message = strdupz("This agent cannot be claimed, it was built without support for Cloud");
     return CMD_STATUS_FAILURE;
 #endif
     error_log_limit_unlimited();
-    info("COMMAND: Reloading Agent Claiming configuration.");
+    netdata_info("COMMAND: Reloading Agent Claiming configuration.");
     load_claiming_state();
     registry_update_cloud_base_url();
     rrdpush_claimed_id(localhost);
@@ -221,7 +221,7 @@ static cmd_status_t cmd_reload_claiming_state_execute(char *args, char **message
 static cmd_status_t cmd_reload_labels_execute(char *args, char **message)
 {
     (void)args;
-    info("COMMAND: reloading host labels.");
+    netdata_info("COMMAND: reloading host labels.");
     reload_host_labels();
 
     BUFFER *wb = buffer_create(10, NULL);
@@ -272,7 +272,7 @@ static cmd_status_t cmd_read_config_execute(char *args, char **message)
 static cmd_status_t cmd_write_config_execute(char *args, char **message)
 {
     UNUSED(message);
-    info("write-config %s", args);
+    netdata_info("write-config %s", args);
     size_t n = strlen(args);
     char *separator = strchr(args,'|');
     if (separator == NULL)
@@ -296,7 +296,7 @@ static cmd_status_t cmd_write_config_execute(char *args, char **message)
     struct config *tmp_config = strcmp(conf_file, "cloud") ? &netdata_config : &cloud_config;
 
     appconfig_set(tmp_config, temp + offset + 1, temp + offset2 + 1, temp + offset3 + 1);
-    info("write-config conf_file=%s section=%s key=%s value=%s",conf_file, temp + offset + 1, temp + offset2 + 1,
+    netdata_info("write-config conf_file=%s section=%s key=%s value=%s",conf_file, temp + offset + 1, temp + offset2 + 1,
          temp + offset3 + 1);
     freez(temp);
     return CMD_STATUS_SUCCESS;
@@ -313,7 +313,7 @@ static cmd_status_t cmd_ping_execute(char *args, char **message)
 
 static cmd_status_t cmd_aclk_state(char *args, char **message)
 {
-    info("COMMAND: Reopening aclk/cloud state.");
+    netdata_info("COMMAND: Reopening aclk/cloud state.");
     if (strstr(args, "json"))
         *message = aclk_state_json();
     else
@@ -409,7 +409,7 @@ static void pipe_write_cb(uv_write_t* req, int status)
     uv_close((uv_handle_t *)client, pipe_close_cb);
     --clients;
     buffer_free(client->data);
-    info("Command Clients = %u\n", clients);
+    netdata_info("Command Clients = %u\n", clients);
 }
 
 static inline void add_char_to_command_reply(BUFFER *reply_string, unsigned *reply_string_size, char character)
@@ -534,9 +534,9 @@ static void pipe_read_cb(uv_stream_t *client, ssize_t nread, const uv_buf_t *buf
     struct command_context *cmd_ctx = (struct command_context *)client;
 
     if (0 == nread) {
-        info("%s: Zero bytes read by command pipe.", __func__);
+        netdata_info("%s: Zero bytes read by command pipe.", __func__);
     } else if (UV_EOF == nread) {
-        info("EOF found in command pipe.");
+        netdata_info("EOF found in command pipe.");
         parse_commands(cmd_ctx);
     } else if (nread < 0) {
         error("%s: %s", __func__, uv_strerror(nread));
@@ -559,7 +559,7 @@ static void pipe_read_cb(uv_stream_t *client, ssize_t nread, const uv_buf_t *buf
     if (nread < 0 && UV_EOF != nread) {
         uv_close((uv_handle_t *)client, pipe_close_cb);
         --clients;
-        info("Command Clients = %u\n", clients);
+        netdata_info("Command Clients = %u\n", clients);
     }
 }
 
@@ -595,7 +595,7 @@ static void connection_cb(uv_stream_t *server, int status)
     }
 
     ++clients;
-    info("Command Clients = %u\n", clients);
+    netdata_info("Command Clients = %u\n", clients);
     /* Start parsing a new command */
     cmd_ctx->command_string_size = 0;
     cmd_ctx->command_string[0] = '\0';
@@ -605,7 +605,7 @@ static void connection_cb(uv_stream_t *server, int status)
         error("uv_read_start(): %s", uv_strerror(ret));
         uv_close((uv_handle_t *)client, pipe_close_cb);
         --clients;
-        info("Command Clients = %u\n", clients);
+        netdata_info("Command Clients = %u\n", clients);
         return;
     }
 }
@@ -655,7 +655,7 @@ static void command_thread(void *arg)
     ret = uv_listen((uv_stream_t *)&server_pipe, SOMAXCONN, connection_cb);
     if (ret) {
         /* Fallback to backlog of 1 */
-        info("uv_listen() failed with backlog = %d, falling back to backlog = 1.", SOMAXCONN);
+        netdata_info("uv_listen() failed with backlog = %d, falling back to backlog = 1.", SOMAXCONN);
         ret = uv_listen((uv_stream_t *)&server_pipe, 1, connection_cb);
     }
     if (ret) {
@@ -673,12 +673,12 @@ static void command_thread(void *arg)
         uv_run(loop, UV_RUN_DEFAULT);
     }
     /* cleanup operations of the event loop */
-    info("Shutting down command event loop.");
+    netdata_info("Shutting down command event loop.");
     uv_close((uv_handle_t *)&async, NULL);
     uv_close((uv_handle_t*)&server_pipe, NULL);
     uv_run(loop, UV_RUN_DEFAULT); /* flush all libuv handles */
 
-    info("Shutting down command loop complete.");
+    netdata_info("Shutting down command loop complete.");
     fatal_assert(0 == uv_loop_close(loop));
     freez(loop);
 
@@ -714,7 +714,7 @@ void commands_init(void)
     if (command_server_initialized)
         return;
 
-    info("Initializing command server.");
+    netdata_info("Initializing command server.");
     for (i = 0 ; i < CMD_TOTAL_COMMANDS ; ++i) {
         fatal_assert(0 == uv_mutex_init(&command_lock_array[i]));
     }
@@ -754,7 +754,7 @@ void commands_exit(void)
         return;
 
     command_thread_shutdown = 1;
-    info("Shutting down command server.");
+    netdata_info("Shutting down command server.");
     /* wake up event loop */
     fatal_assert(0 == uv_async_send(&async));
     fatal_assert(0 == uv_thread_join(&thread));
@@ -763,6 +763,6 @@ void commands_exit(void)
         uv_mutex_destroy(&command_lock_array[i]);
     }
     uv_rwlock_destroy(&exclusive_rwlock);
-    info("Command server has stopped.");
+    netdata_info("Command server has stopped.");
     command_server_initialized = 0;
 }
diff --git a/daemon/daemon.c b/daemon/daemon.c
index 2b8a655..26b6b40 100644
--- a/daemon/daemon.c
+++ b/daemon/daemon.c
@@ -202,11 +202,11 @@ static void oom_score_adj(void) {
     if(s && *s && (isdigit(*s) || *s == '-' || *s == '+'))
         wanted_score = atoll(s);
     else if(s && !strcmp(s, "keep")) {
-        info("Out-Of-Memory (OOM) kept as-is (running with %d)", (int) old_score);
+        netdata_info("Out-Of-Memory (OOM) kept as-is (running with %d)", (int) old_score);
         return;
     }
     else {
-        info("Out-Of-Memory (OOM) score not changed due to non-numeric setting: '%s' (running with %d)", s, (int)old_score);
+        netdata_info("Out-Of-Memory (OOM) score not changed due to non-numeric setting: '%s' (running with %d)", s, (int)old_score);
         return;
     }
 
@@ -221,7 +221,7 @@ static void oom_score_adj(void) {
     }
 
     if(old_score == wanted_score) {
-        info("Out-Of-Memory (OOM) score is already set to the wanted value %d", (int)old_score);
+        netdata_info("Out-Of-Memory (OOM) score is already set to the wanted value %d", (int)old_score);
         return;
     }
 
@@ -237,7 +237,7 @@ static void oom_score_adj(void) {
             if(read_single_signed_number_file("/proc/self/oom_score_adj", &final_score))
                 error("Adjusted my Out-Of-Memory (OOM) score to %d, but cannot verify it.", (int)wanted_score);
             else if(final_score == wanted_score)
-                info("Adjusted my Out-Of-Memory (OOM) score from %d to %d.", (int)old_score, (int)final_score);
+                netdata_info("Adjusted my Out-Of-Memory (OOM) score from %d to %d.", (int)old_score, (int)final_score);
             else
                 error("Adjusted my Out-Of-Memory (OOM) score from %d to %d, but it has been set to %d.", (int)old_score, (int)wanted_score, (int)final_score);
             analytics_report_oom_score(final_score);
@@ -323,19 +323,19 @@ static void sched_getscheduler_report(void) {
                         return;
                     }
                     else {
-                        info("Running with process scheduling policy '%s', priority %d", scheduler_defaults[i].name, param.sched_priority);
+                        netdata_info("Running with process scheduling policy '%s', priority %d", scheduler_defaults[i].name, param.sched_priority);
                     }
                 }
                 else if(scheduler_defaults[i].flags & SCHED_FLAG_USE_NICE) {
                     #ifdef HAVE_GETPRIORITY
                     int n = getpriority(PRIO_PROCESS, 0);
-                    info("Running with process scheduling policy '%s', nice level %d", scheduler_defaults[i].name, n);
+                    netdata_info("Running with process scheduling policy '%s', nice level %d", scheduler_defaults[i].name, n);
                     #else // !HAVE_GETPRIORITY
-                    info("Running with process scheduling policy '%s'", scheduler_defaults[i].name);
+                    netdata_info("Running with process scheduling policy '%s'", scheduler_defaults[i].name);
                     #endif // !HAVE_GETPRIORITY
                 }
                 else {
-                    info("Running with process scheduling policy '%s'", scheduler_defaults[i].name);
+                    netdata_info("Running with process scheduling policy '%s'", scheduler_defaults[i].name);
                 }
 
                 return;
@@ -404,7 +404,7 @@ static void sched_setscheduler_set(void) {
             error("Cannot adjust netdata scheduling policy to %s (%d), with priority %d. Falling back to nice.", name, policy, priority);
         }
         else {
-            info("Adjusted netdata scheduling policy to %s (%d), with priority %d.", name, policy, priority);
+            netdata_info("Adjusted netdata scheduling policy to %s (%d), with priority %d.", name, policy, priority);
             if(!(flags & SCHED_FLAG_USE_NICE))
                 goto report;
         }
diff --git a/daemon/global_statistics.c b/daemon/global_statistics.c
index ee68beb..6293777 100644
--- a/daemon/global_statistics.c
+++ b/daemon/global_statistics.c
@@ -4123,7 +4123,7 @@ static void global_statistics_cleanup(void *ptr)
     struct netdata_static_thread *static_thread = (struct netdata_static_thread *)ptr;
     static_thread->enabled = NETDATA_MAIN_THREAD_EXITING;
 
-    info("cleaning up...");
+    netdata_info("cleaning up...");
 
     static_thread->enabled = NETDATA_MAIN_THREAD_EXITED;
 }
@@ -4194,7 +4194,7 @@ static void global_statistics_workers_cleanup(void *ptr)
     struct netdata_static_thread *static_thread = (struct netdata_static_thread *)ptr;
     static_thread->enabled = NETDATA_MAIN_THREAD_EXITING;
 
-    info("cleaning up...");
+    netdata_info("cleaning up...");
 
     worker_utilization_finish();
 
@@ -4238,7 +4238,7 @@ static void global_statistics_sqlite3_cleanup(void *ptr)
     struct netdata_static_thread *static_thread = (struct netdata_static_thread *)ptr;
     static_thread->enabled = NETDATA_MAIN_THREAD_EXITING;
 
-    info("cleaning up...");
+    netdata_info("cleaning up...");
 
     static_thread->enabled = NETDATA_MAIN_THREAD_EXITED;
 }
diff --git a/daemon/main.c b/daemon/main.c
index cff6530..12fd61f 100644
--- a/daemon/main.c
+++ b/daemon/main.c
@@ -271,7 +271,7 @@ static bool service_wait_exit(SERVICE_TYPE service, usec_t timeout_ut) {
 
                 buffer_flush(service_list);
                 service_to_buffer(service_list, running_services);
-                info("SERVICE CONTROL: waiting for the following %zu services [ %s] to exit: %s",
+                netdata_info("SERVICE CONTROL: waiting for the following %zu services [ %s] to exit: %s",
                      running, buffer_tostring(service_list),
                      running <= 10 ? buffer_tostring(thread_list) : "");
             }
@@ -286,7 +286,7 @@ static bool service_wait_exit(SERVICE_TYPE service, usec_t timeout_ut) {
     if(running) {
         buffer_flush(service_list);
         service_to_buffer(service_list, running_services);
-        info("SERVICE CONTROL: "
+        netdata_info("SERVICE CONTROL: "
              "the following %zu service(s) [ %s] take too long to exit: %s; "
              "giving up on them...",
              running, buffer_tostring(service_list),
@@ -303,9 +303,9 @@ static bool service_wait_exit(SERVICE_TYPE service, usec_t timeout_ut) {
     {                                                   \
         usec_t now_ut = now_monotonic_usec();           \
         if(prev_msg)                                    \
-            info("NETDATA SHUTDOWN: in %7llu ms, %s%s - next: %s", (now_ut - last_ut) / USEC_PER_MS, (timeout)?"(TIMEOUT) ":"", prev_msg, msg); \
+            netdata_info("NETDATA SHUTDOWN: in %7llu ms, %s%s - next: %s", (now_ut - last_ut) / USEC_PER_MS, (timeout)?"(TIMEOUT) ":"", prev_msg, msg); \
         else                                            \
-            info("NETDATA SHUTDOWN: next: %s", msg);    \
+            netdata_info("NETDATA SHUTDOWN: next: %s", msg);    \
         last_ut = now_ut;                               \
         prev_msg = msg;                                 \
         timeout = false;                                \
@@ -320,7 +320,7 @@ void netdata_cleanup_and_exit(int ret) {
     bool timeout = false;
 
     error_log_limit_unlimited();
-    info("NETDATA SHUTDOWN: initializing shutdown with code %d...", ret);
+    netdata_info("NETDATA SHUTDOWN: initializing shutdown with code %d...", ret);
 
     send_statistics("EXIT", ret?"ERROR":"OK","-");
 
@@ -492,7 +492,7 @@ void netdata_cleanup_and_exit(int ret) {
     delta_shutdown_time("exit");
 
     usec_t ended_ut = now_monotonic_usec();
-    info("NETDATA SHUTDOWN: completed in %llu ms - netdata is now exiting - bye bye...", (ended_ut - started_ut) / USEC_PER_MS);
+    netdata_info("NETDATA SHUTDOWN: completed in %llu ms - netdata is now exiting - bye bye...", (ended_ut - started_ut) / USEC_PER_MS);
     exit(ret);
 }
 
@@ -639,7 +639,7 @@ static void set_nofile_limit(struct rlimit *rl) {
         return;
     }
 
-    info("resources control: allowed file descriptors: soft = %zu, max = %zu",
+    netdata_info("resources control: allowed file descriptors: soft = %zu, max = %zu",
          (size_t) rl->rlim_cur, (size_t) rl->rlim_max);
 
     // make the soft/hard limits equal
@@ -666,10 +666,10 @@ void cancel_main_threads() {
     for (i = 0; static_threads[i].name != NULL ; i++) {
         if (static_threads[i].enabled == NETDATA_MAIN_THREAD_RUNNING) {
             if (static_threads[i].thread) {
-                info("EXIT: Stopping main thread: %s", static_threads[i].name);
+                netdata_info("EXIT: Stopping main thread: %s", static_threads[i].name);
                 netdata_thread_cancel(*static_threads[i].thread);
             } else {
-                info("EXIT: No thread running (marking as EXITED): %s", static_threads[i].name);
+                netdata_info("EXIT: No thread running (marking as EXITED): %s", static_threads[i].name);
                 static_threads[i].enabled = NETDATA_MAIN_THREAD_EXITED;
             }
             found++;
@@ -680,7 +680,7 @@ void cancel_main_threads() {
 
     while(found && max > 0) {
         max -= step;
-        info("Waiting %d threads to finish...", found);
+        netdata_info("Waiting %d threads to finish...", found);
         sleep_usec(step);
         found = 0;
         for (i = 0; static_threads[i].name != NULL ; i++) {
@@ -696,7 +696,7 @@ void cancel_main_threads() {
         }
     }
     else
-        info("All threads finished.");
+        netdata_info("All threads finished.");
 
     for (i = 0; static_threads[i].name != NULL ; i++)
         freez(static_threads[i].thread);
@@ -1183,7 +1183,7 @@ static void get_netdata_configured_variables() {
     // https://github.com/netdata/netdata/pull/11222#issuecomment-868367920 for more information.
     if (rrdset_free_obsolete_time_s < 10) {
         rrdset_free_obsolete_time_s = 10;
-        info("The \"cleanup obsolete charts after seconds\" option was set to 10 seconds.");
+        netdata_info("The \"cleanup obsolete charts after seconds\" option was set to 10 seconds.");
         config_set_number(CONFIG_SECTION_DB, "cleanup obsolete charts after secs", rrdset_free_obsolete_time_s);
     }
 
@@ -1219,13 +1219,13 @@ int load_netdata_conf(char *filename, char overwrite_used) {
 
         ret = config_load(filename, overwrite_used, NULL);
         if(!ret) {
-            info("CONFIG: cannot load user config '%s'. Will try the stock version.", filename);
+            netdata_info("CONFIG: cannot load user config '%s'. Will try the stock version.", filename);
             freez(filename);
 
             filename = strdupz_path_subpath(netdata_configured_stock_config_dir, "netdata.conf");
             ret = config_load(filename, overwrite_used, NULL);
             if(!ret)
-                info("CONFIG: cannot load stock config '%s'. Running with internal defaults.", filename);
+                netdata_info("CONFIG: cannot load stock config '%s'. Running with internal defaults.", filename);
         }
 
         freez(filename);
@@ -1245,14 +1245,14 @@ int get_system_info(struct rrdhost_system_info *system_info) {
     script = mallocz(sizeof(char) * (strlen(netdata_configured_primary_plugins_dir) + strlen("system-info.sh") + 2));
     sprintf(script, "%s/%s", netdata_configured_primary_plugins_dir, "system-info.sh");
     if (unlikely(access(script, R_OK) != 0)) {
-        info("System info script %s not found.",script);
+        netdata_info("System info script %s not found.",script);
         freez(script);
         return 1;
     }
 
     pid_t command_pid;
 
-    info("Executing %s", script);
+    netdata_info("Executing %s", script);
 
     FILE *fp_child_input;
     FILE *fp_child_output = netdata_popen(script, &command_pid, &fp_child_input);
@@ -1273,10 +1273,10 @@ int get_system_info(struct rrdhost_system_info *system_info) {
                 coverity_remove_taint(value);
 
                 if(unlikely(rrdhost_set_system_info_variable(system_info, line, value))) {
-                    info("Unexpected environment variable %s=%s", line, value);
+                    netdata_info("Unexpected environment variable %s=%s", line, value);
                 }
                 else {
-                    info("%s=%s", line, value);
+                    netdata_info("%s=%s", line, value);
                     setenv(line, value, 1);
                 }
             }
@@ -1325,9 +1325,9 @@ void post_conf_load(char **user)
     {                                                   \
         usec_t now_ut = now_monotonic_usec();           \
         if(prev_msg)                                    \
-            info("NETDATA STARTUP: in %7llu ms, %s - next: %s", (now_ut - last_ut) / USEC_PER_MS, prev_msg, msg); \
+            netdata_info("NETDATA STARTUP: in %7llu ms, %s - next: %s", (now_ut - last_ut) / USEC_PER_MS, prev_msg, msg); \
         else                                            \
-            info("NETDATA STARTUP: next: %s", msg);    \
+            netdata_info("NETDATA STARTUP: next: %s", msg);    \
         last_ut = now_ut;                               \
         prev_msg = msg;                                 \
     }
@@ -2010,7 +2010,7 @@ int main(int argc, char **argv) {
     if(become_daemon(dont_fork, user) == -1)
         fatal("Cannot daemonize myself.");
 
-    info("netdata started on pid %d.", getpid());
+    netdata_info("netdata started on pid %d.", getpid());
 
     delta_startup_time("initialize threads after fork");
 
@@ -2116,7 +2116,7 @@ int main(int argc, char **argv) {
     delta_startup_time("ready");
 
     usec_t ready_ut = now_monotonic_usec();
-    info("NETDATA STARTUP: completed in %llu ms. Enjoy real-time performance monitoring!", (ready_ut - started_ut) / USEC_PER_MS);
+    netdata_info("NETDATA STARTUP: completed in %llu ms. Enjoy real-time performance monitoring!", (ready_ut - started_ut) / USEC_PER_MS);
     netdata_ready = 1;
 
     send_statistics("START", "-",  "-");
diff --git a/daemon/service.c b/daemon/service.c
index 57c7c7f..41ccb90 100644
--- a/daemon/service.c
+++ b/daemon/service.c
@@ -40,7 +40,7 @@ static void svc_rrddim_obsolete_to_archive(RRDDIM *rd) {
 
     const char *cache_filename = rrddim_cache_filename(rd);
     if(cache_filename) {
-        info("Deleting dimension file '%s'.", cache_filename);
+        netdata_info("Deleting dimension file '%s'.", cache_filename);
         if (unlikely(unlink(cache_filename) == -1))
             error("Cannot delete dimension file '%s'", cache_filename);
     }
@@ -91,7 +91,7 @@ static bool svc_rrdset_archive_obsolete_dimensions(RRDSET *st, bool all_dimensio
                     )) {
 
             if(dictionary_acquired_item_references(rd_dfe.item) == 1) {
-                info("Removing obsolete dimension '%s' (%s) of '%s' (%s).", rrddim_name(rd), rrddim_id(rd), rrdset_name(st), rrdset_id(st));
+                netdata_info("Removing obsolete dimension '%s' (%s) of '%s' (%s).", rrddim_name(rd), rrddim_id(rd), rrdset_name(st), rrdset_id(st));
                 svc_rrddim_obsolete_to_archive(rd);
             }
             else
@@ -227,7 +227,7 @@ restart_after_removal:
         if(!rrdhost_should_be_removed(host, protected_host, now))
             continue;
 
-        info("Host '%s' with machine guid '%s' is obsolete - cleaning up.", rrdhost_hostname(host), host->machine_guid);
+        netdata_info("Host '%s' with machine guid '%s' is obsolete - cleaning up.", rrdhost_hostname(host), host->machine_guid);
 
         if (rrdhost_option_check(host, RRDHOST_OPTION_DELETE_ORPHAN_HOST)
             /* don't delete multi-host DB host files */
diff --git a/daemon/signals.c b/daemon/signals.c
index 3699010..00c58cd 100644
--- a/daemon/signals.c
+++ b/daemon/signals.c
@@ -130,7 +130,7 @@ static void reap_child(pid_t pid) {
         if (errno != ECHILD)
             error("SIGNAL: waitid(%d): failed to wait for child", pid);
         else
-            info("SIGNAL: waitid(%d): failed - it seems the child is already reaped", pid);
+            netdata_info("SIGNAL: waitid(%d): failed - it seems the child is already reaped", pid);
         return;
     }
     else if (i.si_pid == 0) {
@@ -141,25 +141,25 @@ static void reap_child(pid_t pid) {
 
     switch (i.si_code) {
         case CLD_EXITED:
-            info("SIGNAL: reap_child(%d) exited with code: %d", pid, i.si_status);
+            netdata_info("SIGNAL: reap_child(%d) exited with code: %d", pid, i.si_status);
             break;
         case CLD_KILLED:
-            info("SIGNAL: reap_child(%d) killed by signal: %d", pid, i.si_status);
+            netdata_info("SIGNAL: reap_child(%d) killed by signal: %d", pid, i.si_status);
             break;
         case CLD_DUMPED:
-            info("SIGNAL: reap_child(%d) dumped core by signal: %d", pid, i.si_status);
+            netdata_info("SIGNAL: reap_child(%d) dumped core by signal: %d", pid, i.si_status);
             break;
         case CLD_STOPPED:
-            info("SIGNAL: reap_child(%d) stopped by signal: %d", pid, i.si_status);
+            netdata_info("SIGNAL: reap_child(%d) stopped by signal: %d", pid, i.si_status);
             break;
         case CLD_TRAPPED:
-            info("SIGNAL: reap_child(%d) trapped by signal: %d", pid, i.si_status);
+            netdata_info("SIGNAL: reap_child(%d) trapped by signal: %d", pid, i.si_status);
             break;
         case CLD_CONTINUED:
-            info("SIGNAL: reap_child(%d) continued by signal: %d", pid, i.si_status);
+            netdata_info("SIGNAL: reap_child(%d) continued by signal: %d", pid, i.si_status);
             break;
         default:
-            info("SIGNAL: reap_child(%d) gave us a SIGCHLD with code %d and status %d.", pid, i.si_code, i.si_status);
+            netdata_info("SIGNAL: reap_child(%d) gave us a SIGCHLD with code %d and status %d.", pid, i.si_code, i.si_status);
             break;
     }
 }
@@ -204,28 +204,28 @@ void signals_handle(void) {
                         switch (signals_waiting[i].action) {
                             case NETDATA_SIGNAL_RELOAD_HEALTH:
                                 error_log_limit_unlimited();
-                                info("SIGNAL: Received %s. Reloading HEALTH configuration...", name);
+                                netdata_info("SIGNAL: Received %s. Reloading HEALTH configuration...", name);
                                 error_log_limit_reset();
                                 execute_command(CMD_RELOAD_HEALTH, NULL, NULL);
                                 break;
 
                             case NETDATA_SIGNAL_SAVE_DATABASE:
                                 error_log_limit_unlimited();
-                                info("SIGNAL: Received %s. Saving databases...", name);
+                                netdata_info("SIGNAL: Received %s. Saving databases...", name);
                                 error_log_limit_reset();
                                 execute_command(CMD_SAVE_DATABASE, NULL, NULL);
                                 break;
 
                             case NETDATA_SIGNAL_REOPEN_LOGS:
                                 error_log_limit_unlimited();
-                                info("SIGNAL: Received %s. Reopening all log files...", name);
+                                netdata_info("SIGNAL: Received %s. Reopening all log files...", name);
                                 error_log_limit_reset();
                                 execute_command(CMD_REOPEN_LOGS, NULL, NULL);
                                 break;
 
                             case NETDATA_SIGNAL_EXIT_CLEANLY:
                                 error_log_limit_unlimited();
-                                info("SIGNAL: Received %s. Cleaning up to exit...", name);
+                                netdata_info("SIGNAL: Received %s. Cleaning up to exit...", name);
                                 commands_exit();
                                 netdata_cleanup_and_exit(0);
                                 exit(0);
@@ -240,7 +240,7 @@ void signals_handle(void) {
                                 break;
 
                             default:
-                                info("SIGNAL: Received %s. No signal handler configured. Ignoring it.", name);
+                                netdata_info("SIGNAL: Received %s. No signal handler configured. Ignoring it.", name);
                                 break;
                         }
                     }
diff --git a/database/contexts/rrdcontext.c b/database/contexts/rrdcontext.c
index 40a7e42..7d56cc7 100644
--- a/database/contexts/rrdcontext.c
+++ b/database/contexts/rrdcontext.c
@@ -241,7 +241,7 @@ void rrdcontext_hub_checkpoint_command(void *ptr) {
     }
 
     if(rrdhost_flag_check(host, RRDHOST_FLAG_ACLK_STREAM_CONTEXTS)) {
-        info("RRDCONTEXT: received checkpoint command for claim id '%s', node id '%s', while node '%s' has an active context streaming.",
+        netdata_info("RRDCONTEXT: received checkpoint command for claim id '%s', node id '%s', while node '%s' has an active context streaming.",
               cmd->claim_id, cmd->node_id, rrdhost_hostname(host));
 
         // disable it temporarily, so that our worker will not attempt to send messages in parallel
diff --git a/database/engine/cache.c b/database/engine/cache.c
index bc3ba6b..d18f809 100644
--- a/database/engine/cache.c
+++ b/database/engine/cache.c
@@ -2092,7 +2092,7 @@ void pgc_open_cache_to_journal_v2(PGC *cache, Word_t section, unsigned datafile_
 
     struct section_pages *sp = *section_pages_pptr;
     if(!netdata_spinlock_trylock(&sp->migration_to_v2_spinlock)) {
-        info("DBENGINE: migration to journal v2 for datafile %u is postponed, another jv2 indexer is already running for this section", datafile_fileno);
+        netdata_info("DBENGINE: migration to journal v2 for datafile %u is postponed, another jv2 indexer is already running for this section", datafile_fileno);
         pgc_ll_unlock(cache, &cache->hot);
         return;
     }
@@ -2625,7 +2625,7 @@ void unittest_stress_test(void) {
         if(stats.events_flush_critical > old_stats.events_flush_critical)
             flushing_status = "F";
 
-        info("PGS %5zuk +%4zuk/-%4zuk "
+        netdata_info("PGS %5zuk +%4zuk/-%4zuk "
              "| RF %5zuk "
              "| HOT %5zuk +%4zuk -%4zuk "
              "| DRT %s %5zuk +%4zuk -%4zuk "
@@ -2651,7 +2651,7 @@ void unittest_stress_test(void) {
 #endif
              );
     }
-    info("Waiting for threads to stop...");
+    netdata_info("Waiting for threads to stop...");
     __atomic_store_n(&pgc_uts.stop, true, __ATOMIC_RELAXED);
 
     netdata_thread_join(service_thread, NULL);
diff --git a/database/engine/datafile.c b/database/engine/datafile.c
index 8c413d8..cb31b8e 100644
--- a/database/engine/datafile.c
+++ b/database/engine/datafile.c
@@ -334,7 +334,7 @@ static int load_data_file(struct rrdengine_datafile *datafile)
         ctx_fs_error(ctx);
         return fd;
     }
-    info("DBENGINE: initializing data file \"%s\".", path);
+    netdata_info("DBENGINE: initializing data file \"%s\".", path);
 
     ret = check_file_properties(file, &file_size, sizeof(struct rrdeng_df_sb));
     if (ret)
@@ -350,7 +350,7 @@ static int load_data_file(struct rrdengine_datafile *datafile)
     datafile->file = file;
     datafile->pos = file_size;
 
-    info("DBENGINE: data file \"%s\" initialized (size:%"PRIu64").", path, file_size);
+    netdata_info("DBENGINE: data file \"%s\" initialized (size:%"PRIu64").", path, file_size);
     return 0;
 
     error:
@@ -394,7 +394,7 @@ static int scan_data_files(struct rrdengine_instance *ctx)
         ctx_fs_error(ctx);
         return ret;
     }
-    info("DBENGINE: found %d files in path %s", ret, ctx->config.dbfiles_path);
+    netdata_info("DBENGINE: found %d files in path %s", ret, ctx->config.dbfiles_path);
 
     datafiles = callocz(MIN(ret, MAX_DATAFILES), sizeof(*datafiles));
     for (matched_files = 0 ; UV_EOF != uv_fs_scandir_next(&req, &dent) && matched_files < MAX_DATAFILES ; ) {
@@ -439,12 +439,12 @@ static int scan_data_files(struct rrdengine_instance *ctx)
             ret = journalfile_unlink(journalfile);
             if (!ret) {
                 journalfile_v1_generate_path(datafile, path, sizeof(path));
-                info("DBENGINE: deleted journal file \"%s\".", path);
+                netdata_info("DBENGINE: deleted journal file \"%s\".", path);
             }
             ret = unlink_data_file(datafile);
             if (!ret) {
                 generate_datafilepath(datafile, path, sizeof(path));
-                info("DBENGINE: deleted data file \"%s\".", path);
+                netdata_info("DBENGINE: deleted data file \"%s\".", path);
             }
             freez(journalfile);
             freez(datafile);
@@ -472,14 +472,14 @@ int create_new_datafile_pair(struct rrdengine_instance *ctx)
     int ret;
     char path[RRDENG_PATH_MAX];
 
-    info("DBENGINE: creating new data and journal files in path %s", ctx->config.dbfiles_path);
+    netdata_info("DBENGINE: creating new data and journal files in path %s", ctx->config.dbfiles_path);
     datafile = datafile_alloc_and_init(ctx, 1, fileno);
     ret = create_data_file(datafile);
     if(ret)
         goto error_after_datafile;
 
     generate_datafilepath(datafile, path, sizeof(path));
-    info("DBENGINE: created data file \"%s\".", path);
+    netdata_info("DBENGINE: created data file \"%s\".", path);
 
     journalfile = journalfile_alloc_and_init(datafile);
     ret = journalfile_create(journalfile, datafile);
@@ -487,7 +487,7 @@ int create_new_datafile_pair(struct rrdengine_instance *ctx)
         goto error_after_journalfile;
 
     journalfile_v1_generate_path(datafile, path, sizeof(path));
-    info("DBENGINE: created journal file \"%s\".", path);
+    netdata_info("DBENGINE: created journal file \"%s\".", path);
 
     ctx_current_disk_space_increase(ctx, datafile->pos + journalfile->unsafe.pos);
     datafile_list_insert(ctx, datafile);
@@ -517,7 +517,7 @@ int init_data_files(struct rrdengine_instance *ctx)
         error("DBENGINE: failed to scan path \"%s\".", ctx->config.dbfiles_path);
         return ret;
     } else if (0 == ret) {
-        info("DBENGINE: data files not found, creating in path \"%s\".", ctx->config.dbfiles_path);
+        netdata_info("DBENGINE: data files not found, creating in path \"%s\".", ctx->config.dbfiles_path);
         ctx->atomic.last_fileno = 0;
         ret = create_new_datafile_pair(ctx);
         if (ret) {
@@ -545,7 +545,7 @@ void finalize_data_files(struct rrdengine_instance *ctx)
     logged = false;
     while(__atomic_load_n(&ctx->atomic.extents_currently_being_flushed, __ATOMIC_RELAXED)) {
         if(!logged) {
-            info("Waiting for inflight flush to finish on tier %d...", ctx->config.tier);
+            netdata_info("Waiting for inflight flush to finish on tier %d...", ctx->config.tier);
             logged = true;
         }
         sleep_usec(100 * USEC_PER_MS);
@@ -559,7 +559,7 @@ void finalize_data_files(struct rrdengine_instance *ctx)
         size_t iterations = 100;
         while(!datafile_acquire_for_deletion(datafile) && datafile != ctx->datafiles.first->prev && --iterations > 0) {
             if(!logged) {
-                info("Waiting to acquire data file %u of tier %d to close it...", datafile->fileno, ctx->config.tier);
+                netdata_info("Waiting to acquire data file %u of tier %d to close it...", datafile->fileno, ctx->config.tier);
                 logged = true;
             }
             sleep_usec(100 * USEC_PER_MS);
@@ -576,7 +576,7 @@ void finalize_data_files(struct rrdengine_instance *ctx)
                 netdata_spinlock_unlock(&datafile->writers.spinlock);
                 uv_rwlock_wrunlock(&ctx->datafiles.rwlock);
                 if(!logged) {
-                    info("Waiting for writers to data file %u of tier %d to finish...", datafile->fileno, ctx->config.tier);
+                    netdata_info("Waiting for writers to data file %u of tier %d to finish...", datafile->fileno, ctx->config.tier);
                     logged = true;
                 }
                 sleep_usec(100 * USEC_PER_MS);
diff --git a/database/engine/journalfile.c b/database/engine/journalfile.c
index 9998ee5..b547b64 100644
--- a/database/engine/journalfile.c
+++ b/database/engine/journalfile.c
@@ -849,7 +849,7 @@ static int journalfile_v2_validate(void *data_start, size_t journal_v2_file_size
     unsigned entries;
     unsigned total_pages = 0;
 
-    info("DBENGINE: checking %u metrics that exist in the journal", j2_header->metric_count);
+    netdata_info("DBENGINE: checking %u metrics that exist in the journal", j2_header->metric_count);
     for (entries = 0; entries < j2_header->metric_count; entries++) {
 
         char uuid_str[UUID_STR_LEN];
@@ -880,16 +880,16 @@ static int journalfile_v2_validate(void *data_start, size_t journal_v2_file_size
 
         metric++;
         if ((uint32_t)((uint8_t *) metric - (uint8_t *) data_start) > (uint32_t) journal_v2_file_size) {
-            info("DBENGINE: verification failed EOF reached -- total entries %u, verified %u", entries, verified);
+            netdata_info("DBENGINE: verification failed EOF reached -- total entries %u, verified %u", entries, verified);
             return 1;
         }
     }
 
     if (entries != verified) {
-        info("DBENGINE: verification failed -- total entries %u, verified %u", entries, verified);
+        netdata_info("DBENGINE: verification failed -- total entries %u, verified %u", entries, verified);
         return 1;
     }
-    info("DBENGINE: verification succeeded -- total entries %u, verified %u (%u total pages)", entries, verified, total_pages);
+    netdata_info("DBENGINE: verification succeeded -- total entries %u, verified %u (%u total pages)", entries, verified, total_pages);
 
     return 0;
 }
@@ -921,7 +921,7 @@ void journalfile_v2_populate_retention_to_mrg(struct rrdengine_instance *ctx, st
     journalfile_v2_data_release(journalfile);
     usec_t ended_ut = now_monotonic_usec();
 
-    info("DBENGINE: journal v2 of tier %d, datafile %u populated, size: %0.2f MiB, metrics: %0.2f k, %0.2f ms"
+    netdata_info("DBENGINE: journal v2 of tier %d, datafile %u populated, size: %0.2f MiB, metrics: %0.2f k, %0.2f ms"
         , ctx->config.tier, journalfile->datafile->fileno
         , (double)data_size / 1024 / 1024
         , (double)entries / 1000
@@ -975,7 +975,7 @@ int journalfile_v2_load(struct rrdengine_instance *ctx, struct rrdengine_journal
         return 1;
     }
 
-    info("DBENGINE: checking integrity of '%s'", path_v2);
+    netdata_info("DBENGINE: checking integrity of '%s'", path_v2);
     usec_t validation_start_ut = now_monotonic_usec();
     int rc = journalfile_v2_validate(data_start, journal_v2_file_size, journal_v1_file_size);
     if (unlikely(rc)) {
@@ -1006,7 +1006,7 @@ int journalfile_v2_load(struct rrdengine_instance *ctx, struct rrdengine_journal
 
     usec_t finished_ut = now_monotonic_usec();
 
-    info("DBENGINE: journal v2 '%s' loaded, size: %0.2f MiB, metrics: %0.2f k, "
+    netdata_info("DBENGINE: journal v2 '%s' loaded, size: %0.2f MiB, metrics: %0.2f k, "
          "mmap: %0.2f ms, validate: %0.2f ms"
          , path_v2
          , (double)journal_v2_file_size / 1024 / 1024
@@ -1179,7 +1179,7 @@ void journalfile_migrate_to_v2_callback(Word_t section, unsigned datafile_fileno
 
     journalfile_v2_generate_path(datafile, path, sizeof(path));
 
-    info("DBENGINE: indexing file '%s': extents %zu, metrics %zu, pages %zu",
+    netdata_info("DBENGINE: indexing file '%s': extents %zu, metrics %zu, pages %zu",
         path,
         number_of_extents,
         number_of_metrics,
@@ -1350,7 +1350,7 @@ void journalfile_migrate_to_v2_callback(Word_t section, unsigned datafile_fileno
 
         internal_error(true, "DBENGINE: FILE COMPLETED --------> %llu", (now_monotonic_usec() - start_loading) / USEC_PER_MS);
 
-        info("DBENGINE: migrated journal file '%s', file size %zu", path, total_file_size);
+        netdata_info("DBENGINE: migrated journal file '%s', file size %zu", path, total_file_size);
 
         // msync(data_start, total_file_size, MS_SYNC);
         journalfile_v2_data_set(journalfile, fd_v2, data_start, total_file_size);
@@ -1361,7 +1361,7 @@ void journalfile_migrate_to_v2_callback(Word_t section, unsigned datafile_fileno
         return;
     }
     else {
-        info("DBENGINE: failed to build index '%s', file will be skipped", path);
+        netdata_info("DBENGINE: failed to build index '%s', file will be skipped", path);
         j2_header.data = NULL;
         j2_header.magic = JOURVAL_V2_SKIP_MAGIC;
         memcpy(data_start, &j2_header, sizeof(j2_header));
@@ -1428,19 +1428,19 @@ int journalfile_load(struct rrdengine_instance *ctx, struct rrdengine_journalfil
 
     ret = journalfile_check_superblock(file);
     if (ret) {
-        info("DBENGINE: invalid journal file '%s' ; superblock check failed.", path);
+        netdata_info("DBENGINE: invalid journal file '%s' ; superblock check failed.", path);
         error = ret;
         goto cleanup;
     }
     ctx_io_read_op_bytes(ctx, sizeof(struct rrdeng_jf_sb));
 
-    info("DBENGINE: loading journal file '%s'", path);
+    netdata_info("DBENGINE: loading journal file '%s'", path);
 
     max_id = journalfile_iterate_transactions(ctx, journalfile);
 
     __atomic_store_n(&ctx->atomic.transaction_id, MAX(__atomic_load_n(&ctx->atomic.transaction_id, __ATOMIC_RELAXED), max_id + 1), __ATOMIC_RELAXED);
 
-    info("DBENGINE: journal file '%s' loaded (size:%"PRIu64").", path, file_size);
+    netdata_info("DBENGINE: journal file '%s' loaded (size:%"PRIu64").", path, file_size);
 
     bool is_last_file = (ctx_last_fileno_get(ctx) == journalfile->datafile->fileno);
     if (is_last_file && journalfile->datafile->pos <= rrdeng_target_data_file_size(ctx) / 3) {
diff --git a/database/engine/metric.c b/database/engine/metric.c
index 6b65df9..3fef3db 100644
--- a/database/engine/metric.c
+++ b/database/engine/metric.c
@@ -673,7 +673,7 @@ struct mrg_statistics mrg_get_statistics(MRG *mrg) {
 static void mrg_stress(MRG *mrg, size_t entries, size_t sections) {
     bool ret;
 
-    info("DBENGINE METRIC: stress testing %zu entries on %zu sections...", entries, sections);
+    netdata_info("DBENGINE METRIC: stress testing %zu entries on %zu sections...", entries, sections);
 
     METRIC *array[entries][sections];
     for(size_t i = 0; i < entries ; i++) {
@@ -882,7 +882,7 @@ int mrg_unittest(void) {
     netdata_thread_join(thread3, NULL);
     usec_t ended_ut = now_monotonic_usec();
 
-    info("DBENGINE METRIC: did %zu additions, %zu duplicate additions, "
+    netdata_info("DBENGINE METRIC: did %zu additions, %zu duplicate additions, "
          "%zu deletions, %zu wrong deletions, "
          "%zu successful searches, %zu wrong searches, "
          "%zu successful pointer validations, %zu wrong pointer validations "
@@ -897,7 +897,7 @@ int mrg_unittest(void) {
 
     mrg_destroy(mrg);
 
-    info("DBENGINE METRIC: all tests passed!");
+    netdata_info("DBENGINE METRIC: all tests passed!");
 
     return 0;
 }
diff --git a/database/engine/rrdengine.c b/database/engine/rrdengine.c
index 7811a5e..2a29bc6 100644
--- a/database/engine/rrdengine.c
+++ b/database/engine/rrdengine.c
@@ -1174,7 +1174,7 @@ static void update_metrics_first_time_s(struct rrdengine_instance *ctx, struct r
         added++;
     }
 
-    info("DBENGINE: recalculating tier %d retention for %zu metrics starting with datafile %u",
+    netdata_info("DBENGINE: recalculating tier %d retention for %zu metrics starting with datafile %u",
          ctx->config.tier, count, first_datafile_remaining->fileno);
 
     journalfile_v2_data_release(journalfile);
@@ -1189,7 +1189,7 @@ static void update_metrics_first_time_s(struct rrdengine_instance *ctx, struct r
     if(worker)
         worker_is_busy(UV_EVENT_DBENGINE_POPULATE_MRG);
 
-    info("DBENGINE: updating tier %d metrics registry retention for %zu metrics",
+    netdata_info("DBENGINE: updating tier %d metrics registry retention for %zu metrics",
          ctx->config.tier, added);
 
     size_t deleted_metrics = 0, zero_retention_referenced = 0, zero_disk_retention = 0, zero_disk_but_live = 0;
@@ -1243,7 +1243,7 @@ void datafile_delete(struct rrdengine_instance *ctx, struct rrdengine_datafile *
         datafile_got_for_deletion = datafile_acquire_for_deletion(datafile);
 
         if (!datafile_got_for_deletion) {
-            info("DBENGINE: waiting for data file '%s/"
+            netdata_info("DBENGINE: waiting for data file '%s/"
                          DATAFILE_PREFIX RRDENG_FILE_NUMBER_PRINT_TMPL DATAFILE_EXTENSION
                          "' to be available for deletion, "
                          "it is in use currently by %u users.",
@@ -1255,7 +1255,7 @@ void datafile_delete(struct rrdengine_instance *ctx, struct rrdengine_datafile *
     }
 
     __atomic_add_fetch(&rrdeng_cache_efficiency_stats.datafile_deletion_started, 1, __ATOMIC_RELAXED);
-    info("DBENGINE: deleting data file '%s/"
+    netdata_info("DBENGINE: deleting data file '%s/"
          DATAFILE_PREFIX RRDENG_FILE_NUMBER_PRINT_TMPL DATAFILE_EXTENSION
          "'.",
          ctx->config.dbfiles_path, ctx->datafiles.first->tier, ctx->datafiles.first->fileno);
@@ -1277,26 +1277,26 @@ void datafile_delete(struct rrdengine_instance *ctx, struct rrdengine_datafile *
     journal_file_bytes = journalfile_current_size(journal_file);
     deleted_bytes = journalfile_v2_data_size_get(journal_file);
 
-    info("DBENGINE: deleting data and journal files to maintain disk quota");
+    netdata_info("DBENGINE: deleting data and journal files to maintain disk quota");
     ret = journalfile_destroy_unsafe(journal_file, datafile);
     if (!ret) {
         journalfile_v1_generate_path(datafile, path, sizeof(path));
-        info("DBENGINE: deleted journal file \"%s\".", path);
+        netdata_info("DBENGINE: deleted journal file \"%s\".", path);
         journalfile_v2_generate_path(datafile, path, sizeof(path));
-        info("DBENGINE: deleted journal file \"%s\".", path);
+        netdata_info("DBENGINE: deleted journal file \"%s\".", path);
         deleted_bytes += journal_file_bytes;
     }
     ret = destroy_data_file_unsafe(datafile);
     if (!ret) {
         generate_datafilepath(datafile, path, sizeof(path));
-        info("DBENGINE: deleted data file \"%s\".", path);
+        netdata_info("DBENGINE: deleted data file \"%s\".", path);
         deleted_bytes += datafile_bytes;
     }
     freez(journal_file);
     freez(datafile);
 
     ctx_current_disk_space_decrease(ctx, deleted_bytes);
-    info("DBENGINE: reclaimed %u bytes of disk space.", deleted_bytes);
+    netdata_info("DBENGINE: reclaimed %u bytes of disk space.", deleted_bytes);
 }
 
 static void *database_rotate_tp_worker(struct rrdengine_instance *ctx __maybe_unused, void *data __maybe_unused, struct completion *completion __maybe_unused, uv_work_t *uv_work_req __maybe_unused) {
@@ -1376,7 +1376,7 @@ static void *ctx_shutdown_tp_worker(struct rrdengine_instance *ctx __maybe_unuse
             __atomic_load_n(&ctx->atomic.inflight_queries, __ATOMIC_RELAXED)) {
         if(!logged) {
             logged = true;
-            info("DBENGINE: waiting for %zu inflight queries to finish to shutdown tier %d...",
+            netdata_info("DBENGINE: waiting for %zu inflight queries to finish to shutdown tier %d...",
                  __atomic_load_n(&ctx->atomic.inflight_queries, __ATOMIC_RELAXED),
                  (ctx->config.legacy) ? -1 : ctx->config.tier);
         }
@@ -1501,12 +1501,12 @@ static void *journal_v2_indexing_tp_worker(struct rrdengine_instance *ctx __mayb
         netdata_spinlock_unlock(&datafile->writers.spinlock);
 
         if(!available) {
-            info("DBENGINE: journal file %u needs to be indexed, but it has writers working on it - skipping it for now", datafile->fileno);
+            netdata_info("DBENGINE: journal file %u needs to be indexed, but it has writers working on it - skipping it for now", datafile->fileno);
             datafile = datafile->next;
             continue;
         }
 
-        info("DBENGINE: journal file %u is ready to be indexed", datafile->fileno);
+        netdata_info("DBENGINE: journal file %u is ready to be indexed", datafile->fileno);
         pgc_open_cache_to_journal_v2(open_cache, (Word_t) ctx, (int) datafile->fileno, ctx->config.page_type,
                                      journalfile_migrate_to_v2_callback, (void *) datafile->journalfile);
 
@@ -1860,7 +1860,7 @@ void dbengine_event_loop(void* arg) {
     }
 
     /* cleanup operations of the event loop */
-    info("DBENGINE: shutting down dbengine thread");
+    netdata_info("DBENGINE: shutting down dbengine thread");
 
     /*
      * uv_async_send after uv_close does not seem to crash in linux at the moment,
diff --git a/database/engine/rrdengineapi.c b/database/engine/rrdengineapi.c
index ddc306e..6b4df79 100755
--- a/database/engine/rrdengineapi.c
+++ b/database/engine/rrdengineapi.c
@@ -1075,7 +1075,7 @@ static void rrdeng_populate_mrg(struct rrdengine_instance *ctx) {
     if(cpus > MRG_PARTITIONS)
         cpus = MRG_PARTITIONS;
 
-    info("DBENGINE: populating retention to MRG from %zu journal files of tier %d, using %zu threads...", datafiles, ctx->config.tier, cpus);
+    netdata_info("DBENGINE: populating retention to MRG from %zu journal files of tier %d, using %zu threads...", datafiles, ctx->config.tier, cpus);
 
     if(datafiles > 2) {
         struct rrdengine_datafile *datafile;
@@ -1116,7 +1116,7 @@ void rrdeng_readiness_wait(struct rrdengine_instance *ctx) {
     ctx->loading.populate_mrg.array = NULL;
     ctx->loading.populate_mrg.size = 0;
 
-    info("DBENGINE: tier %d is ready for data collection and queries", ctx->config.tier);
+    netdata_info("DBENGINE: tier %d is ready for data collection and queries", ctx->config.tier);
 }
 
 bool rrdeng_is_legacy(STORAGE_INSTANCE *db_instance) {
@@ -1208,16 +1208,16 @@ int rrdeng_exit(struct rrdengine_instance *ctx) {
     bool logged = false;
     while(__atomic_load_n(&ctx->atomic.collectors_running, __ATOMIC_RELAXED) && !unittest_running) {
         if(!logged) {
-            info("DBENGINE: waiting for collectors to finish on tier %d...", (ctx->config.legacy) ? -1 : ctx->config.tier);
+            netdata_info("DBENGINE: waiting for collectors to finish on tier %d...", (ctx->config.legacy) ? -1 : ctx->config.tier);
             logged = true;
         }
         sleep_usec(100 * USEC_PER_MS);
     }
 
-    info("DBENGINE: flushing main cache for tier %d", (ctx->config.legacy) ? -1 : ctx->config.tier);
+    netdata_info("DBENGINE: flushing main cache for tier %d", (ctx->config.legacy) ? -1 : ctx->config.tier);
     pgc_flush_all_hot_and_dirty_pages(main_cache, (Word_t)ctx);
 
-    info("DBENGINE: shutting down tier %d", (ctx->config.legacy) ? -1 : ctx->config.tier);
+    netdata_info("DBENGINE: shutting down tier %d", (ctx->config.legacy) ? -1 : ctx->config.tier);
     struct completion completion = {};
     completion_init(&completion);
     rrdeng_enq_cmd(ctx, RRDENG_OPCODE_CTX_SHUTDOWN, NULL, &completion, STORAGE_PRIORITY_BEST_EFFORT, NULL, NULL);
diff --git a/database/engine/rrdenginelib.c b/database/engine/rrdenginelib.c
index 984a591..ed7af39 100644
--- a/database/engine/rrdenginelib.c
+++ b/database/engine/rrdenginelib.c
@@ -65,7 +65,7 @@ int open_file_for_io(char *path, int flags, uv_file *file, int direct)
             fatal_assert(req.result >= 0);
             *file = req.result;
 #ifdef __APPLE__
-            info("Disabling OS X caching for file \"%s\".", path);
+            netdata_info("Disabling OS X caching for file \"%s\".", path);
             fcntl(fd, F_NOCACHE, 1);
 #endif
             --direct; /* break the loop */
@@ -143,12 +143,12 @@ int compute_multidb_diskspace()
         int rc = count_legacy_children(netdata_configured_cache_dir);
         if (likely(rc >= 0)) {
             computed_multidb_disk_quota_mb = (rc + 1) * default_rrdeng_disk_quota_mb;
-            info("Found %d legacy dbengines, setting multidb diskspace to %dMB", rc, computed_multidb_disk_quota_mb);
+            netdata_info("Found %d legacy dbengines, setting multidb diskspace to %dMB", rc, computed_multidb_disk_quota_mb);
 
             fp = fopen(multidb_disk_space_file, "w");
             if (likely(fp)) {
                 fprintf(fp, "%d", computed_multidb_disk_quota_mb);
-                info("Created file '%s' to store the computed value", multidb_disk_space_file);
+                netdata_info("Created file '%s' to store the computed value", multidb_disk_space_file);
                 fclose(fp);
             } else
                 error("Failed to store the default multidb disk quota size on '%s'", multidb_disk_space_file);
diff --git a/database/rrdcalctemplate.c b/database/rrdcalctemplate.c
index 53630f9..50532b9 100644
--- a/database/rrdcalctemplate.c
+++ b/database/rrdcalctemplate.c
@@ -246,7 +246,7 @@ void rrdcalctemplate_add_from_config(RRDHOST *host, RRDCALCTEMPLATE *rt) {
     if(added)
         freez(rt);
     else {
-        info("Health configuration template '%s' already exists for host '%s'.", rrdcalctemplate_name(rt), rrdhost_hostname(host));
+        netdata_info("Health configuration template '%s' already exists for host '%s'.", rrdcalctemplate_name(rt), rrdhost_hostname(host));
         rrdcalctemplate_free_unused_rrdcalctemplate_loaded_from_config(rt);
     }
 }
diff --git a/database/rrddim.c b/database/rrddim.c
index 496fdc6..662be4f 100644
--- a/database/rrddim.c
+++ b/database/rrddim.c
@@ -55,7 +55,7 @@ static void rrddim_insert_callback(const DICTIONARY_ITEM *item __maybe_unused, v
 
     if(ctr->memory_mode == RRD_MEMORY_MODE_MAP || ctr->memory_mode == RRD_MEMORY_MODE_SAVE) {
         if(!rrddim_memory_load_or_create_map_save(st, rd, ctr->memory_mode)) {
-            info("Failed to use memory mode %s for chart '%s', dimension '%s', falling back to ram", (ctr->memory_mode == RRD_MEMORY_MODE_MAP)?"map":"save", rrdset_name(st), rrddim_name(rd));
+            netdata_info("Failed to use memory mode %s for chart '%s', dimension '%s', falling back to ram", (ctr->memory_mode == RRD_MEMORY_MODE_MAP)?"map":"save", rrdset_name(st), rrddim_name(rd));
             ctr->memory_mode = RRD_MEMORY_MODE_RAM;
         }
     }
@@ -66,7 +66,7 @@ static void rrddim_insert_callback(const DICTIONARY_ITEM *item __maybe_unused, v
 
         rd->db = netdata_mmap(NULL, entries * sizeof(storage_number), MAP_PRIVATE, 1, false, NULL);
         if(!rd->db) {
-            info("Failed to use memory mode ram for chart '%s', dimension '%s', falling back to alloc", rrdset_name(st), rrddim_name(rd));
+            netdata_info("Failed to use memory mode ram for chart '%s', dimension '%s', falling back to alloc", rrdset_name(st), rrddim_name(rd));
             ctr->memory_mode = RRD_MEMORY_MODE_ALLOC;
         }
         else {
@@ -135,7 +135,7 @@ static void rrddim_insert_callback(const DICTIONARY_ITEM *item __maybe_unused, v
         if(td && (td->algorithm != rd->algorithm || ABS(td->multiplier) != ABS(rd->multiplier) || ABS(td->divisor) != ABS(rd->divisor))) {
             if(!rrdset_flag_check(st, RRDSET_FLAG_HETEROGENEOUS)) {
 #ifdef NETDATA_INTERNAL_CHECKS
-                info("Dimension '%s' added on chart '%s' of host '%s' is not homogeneous to other dimensions already present (algorithm is '%s' vs '%s', multiplier is " COLLECTED_NUMBER_FORMAT " vs " COLLECTED_NUMBER_FORMAT ", divisor is " COLLECTED_NUMBER_FORMAT " vs " COLLECTED_NUMBER_FORMAT ").",
+                netdata_info("Dimension '%s' added on chart '%s' of host '%s' is not homogeneous to other dimensions already present (algorithm is '%s' vs '%s', multiplier is " COLLECTED_NUMBER_FORMAT " vs " COLLECTED_NUMBER_FORMAT ", divisor is " COLLECTED_NUMBER_FORMAT " vs " COLLECTED_NUMBER_FORMAT ").",
                      rrddim_name(rd),
                      rrdset_name(st),
                      rrdhost_hostname(host),
@@ -530,7 +530,7 @@ inline void rrddim_is_obsolete(RRDSET *st, RRDDIM *rd) {
     debug(D_RRD_CALLS, "rrddim_is_obsolete() for chart %s, dimension %s", rrdset_name(st), rrddim_name(rd));
 
     if(unlikely(rrddim_flag_check(rd, RRDDIM_FLAG_ARCHIVED))) {
-        info("Cannot obsolete already archived dimension %s from chart %s", rrddim_name(rd), rrdset_name(st));
+        netdata_info("Cannot obsolete already archived dimension %s from chart %s", rrddim_name(rd), rrdset_name(st));
         return;
     }
     rrddim_flag_set(rd, RRDDIM_FLAG_OBSOLETE);
@@ -700,7 +700,7 @@ bool rrddim_memory_load_or_create_map_save(RRDSET *st, RRDDIM *rd, RRD_MEMORY_MO
     int reset = 0;
     rd_on_file->magic[sizeof(RRDDIMENSION_MAGIC_V019)] = '\0';
     if(strcmp(rd_on_file->magic, RRDDIMENSION_MAGIC_V019) != 0) {
-        info("Initializing file %s.", fullfilename);
+        netdata_info("Initializing file %s.", fullfilename);
         memset(rd_on_file, 0, size);
         reset = 1;
     }
@@ -715,7 +715,7 @@ bool rrddim_memory_load_or_create_map_save(RRDSET *st, RRDDIM *rd, RRD_MEMORY_MO
         reset = 1;
     }
     else if(dt_usec(&now, &rd_on_file->last_collected_time) > (rd_on_file->entries * rd_on_file->update_every * USEC_PER_SEC)) {
-        info("File %s is too old (last collected %llu seconds ago, but the database is %ld seconds). Clearing it.", fullfilename, dt_usec(&now, &rd_on_file->last_collected_time) / USEC_PER_SEC, rd_on_file->entries * rd_on_file->update_every);
+        netdata_info("File %s is too old (last collected %llu seconds ago, but the database is %ld seconds). Clearing it.", fullfilename, dt_usec(&now, &rd_on_file->last_collected_time) / USEC_PER_SEC, rd_on_file->entries * rd_on_file->update_every);
         memset(rd_on_file, 0, size);
         reset = 1;
     }
@@ -724,14 +724,14 @@ bool rrddim_memory_load_or_create_map_save(RRDSET *st, RRDDIM *rd, RRD_MEMORY_MO
         rd->last_collected_value = rd_on_file->last_collected_value;
 
         if(rd_on_file->algorithm != rd->algorithm)
-            info("File %s does not have the expected algorithm (expected %u '%s', found %u '%s'). Previous values may be wrong.",
+            netdata_info("File %s does not have the expected algorithm (expected %u '%s', found %u '%s'). Previous values may be wrong.",
                  fullfilename, rd->algorithm, rrd_algorithm_name(rd->algorithm), rd_on_file->algorithm, rrd_algorithm_name(rd_on_file->algorithm));
 
         if(rd_on_file->multiplier != rd->multiplier)
-            info("File %s does not have the expected multiplier (expected " COLLECTED_NUMBER_FORMAT ", found " COLLECTED_NUMBER_FORMAT "). Previous values may be wrong.", fullfilename, rd->multiplier, rd_on_file->multiplier);
+            netdata_info("File %s does not have the expected multiplier (expected " COLLECTED_NUMBER_FORMAT ", found " COLLECTED_NUMBER_FORMAT "). Previous values may be wrong.", fullfilename, rd->multiplier, rd_on_file->multiplier);
 
         if(rd_on_file->divisor != rd->divisor)
-            info("File %s does not have the expected divisor (expected " COLLECTED_NUMBER_FORMAT ", found " COLLECTED_NUMBER_FORMAT "). Previous values may be wrong.", fullfilename, rd->divisor, rd_on_file->divisor);
+            netdata_info("File %s does not have the expected divisor (expected " COLLECTED_NUMBER_FORMAT ", found " COLLECTED_NUMBER_FORMAT "). Previous values may be wrong.", fullfilename, rd->divisor, rd_on_file->divisor);
     }
 
     // zero the entire header
diff --git a/database/rrdhost.c b/database/rrdhost.c
index 69e4bea..dd69cb3 100644
--- a/database/rrdhost.c
+++ b/database/rrdhost.c
@@ -520,7 +520,7 @@ int is_legacy = 1;
 
     // ------------------------------------------------------------------------
 
-    info("Host '%s' (at registry as '%s') with guid '%s' initialized"
+    netdata_info("Host '%s' (at registry as '%s') with guid '%s' initialized"
                  ", os '%s'"
                  ", timezone '%s'"
                  ", tags '%s'"
@@ -611,21 +611,21 @@ static void rrdhost_update(RRDHOST *host
     host->registry_hostname = string_strdupz((registry_hostname && *registry_hostname)?registry_hostname:hostname);
 
     if(strcmp(rrdhost_hostname(host), hostname) != 0) {
-        info("Host '%s' has been renamed to '%s'. If this is not intentional it may mean multiple hosts are using the same machine_guid.", rrdhost_hostname(host), hostname);
+        netdata_info("Host '%s' has been renamed to '%s'. If this is not intentional it may mean multiple hosts are using the same machine_guid.", rrdhost_hostname(host), hostname);
         rrdhost_init_hostname(host, hostname, true);
     } else {
         rrdhost_index_add_hostname(host);
     }
 
     if(strcmp(rrdhost_program_name(host), program_name) != 0) {
-        info("Host '%s' switched program name from '%s' to '%s'", rrdhost_hostname(host), rrdhost_program_name(host), program_name);
+        netdata_info("Host '%s' switched program name from '%s' to '%s'", rrdhost_hostname(host), rrdhost_program_name(host), program_name);
         STRING *t = host->program_name;
         host->program_name = string_strdupz(program_name);
         string_freez(t);
     }
 
     if(strcmp(rrdhost_program_version(host), program_version) != 0) {
-        info("Host '%s' switched program version from '%s' to '%s'", rrdhost_hostname(host), rrdhost_program_version(host), program_version);
+        netdata_info("Host '%s' switched program version from '%s' to '%s'", rrdhost_hostname(host), rrdhost_program_version(host), program_version);
         STRING *t = host->program_version;
         host->program_version = string_strdupz(program_version);
         string_freez(t);
@@ -678,7 +678,7 @@ static void rrdhost_update(RRDHOST *host
         ml_host_new(host);
         
         rrdhost_load_rrdcontext_data(host);
-        info("Host %s is not in archived mode anymore", rrdhost_hostname(host));
+        netdata_info("Host %s is not in archived mode anymore", rrdhost_hostname(host));
     }
 
     netdata_spinlock_unlock(&host->rrdhost_update_lock);
@@ -963,7 +963,7 @@ int rrd_init(char *hostname, struct rrdhost_system_info *system_info, bool unitt
             set_late_global_environment(system_info);
             fatal("Failed to initialize SQLite");
         }
-        info("Skipping SQLITE metadata initialization since memory mode is not dbengine");
+        netdata_info("Skipping SQLITE metadata initialization since memory mode is not dbengine");
     }
 
     if (unlikely(sql_init_context_database(system_info ? 0 : 1))) {
@@ -978,11 +978,11 @@ int rrd_init(char *hostname, struct rrdhost_system_info *system_info, bool unitt
         rrdpush_init();
 
         if (default_rrd_memory_mode == RRD_MEMORY_MODE_DBENGINE || rrdpush_receiver_needs_dbengine()) {
-            info("DBENGINE: Initializing ...");
+            netdata_info("DBENGINE: Initializing ...");
             dbengine_init(hostname);
         }
         else {
-            info("DBENGINE: Not initializing ...");
+            netdata_info("DBENGINE: Not initializing ...");
             storage_tiers = 1;
         }
 
@@ -1139,7 +1139,7 @@ void rrdhost_free___while_having_rrd_wrlock(RRDHOST *host, bool force) {
     if(!host) return;
 
     if (netdata_exit || force) {
-        info("RRD: 'host:%s' freeing memory...", rrdhost_hostname(host));
+        netdata_info("RRD: 'host:%s' freeing memory...", rrdhost_hostname(host));
 
         // ------------------------------------------------------------------------
         // first remove it from the indexes, so that it will not be discoverable
@@ -1199,7 +1199,7 @@ void rrdhost_free___while_having_rrd_wrlock(RRDHOST *host, bool force) {
 #endif
 
     if (!netdata_exit && !force) {
-        info("RRD: 'host:%s' is now in archive mode...", rrdhost_hostname(host));
+        netdata_info("RRD: 'host:%s' is now in archive mode...", rrdhost_hostname(host));
         rrdhost_flag_set(host, RRDHOST_FLAG_ARCHIVED | RRDHOST_FLAG_ORPHAN);
         return;
     }
@@ -1269,7 +1269,7 @@ void rrd_finalize_collection_for_all_hosts(void) {
 void rrdhost_save_charts(RRDHOST *host) {
     if(!host) return;
 
-    info("RRD: 'host:%s' saving / closing database...", rrdhost_hostname(host));
+    netdata_info("RRD: 'host:%s' saving / closing database...", rrdhost_hostname(host));
 
     RRDSET *st;
 
@@ -1455,7 +1455,7 @@ void reload_host_labels(void) {
 }
 
 void rrdhost_finalize_collection(RRDHOST *host) {
-    info("RRD: 'host:%s' stopping data collection...", rrdhost_hostname(host));
+    netdata_info("RRD: 'host:%s' stopping data collection...", rrdhost_hostname(host));
 
     RRDSET *st;
     rrdset_foreach_read(st, host)
@@ -1469,7 +1469,7 @@ void rrdhost_finalize_collection(RRDHOST *host) {
 void rrdhost_delete_charts(RRDHOST *host) {
     if(!host) return;
 
-    info("RRD: 'host:%s' deleting disk files...", rrdhost_hostname(host));
+    netdata_info("RRD: 'host:%s' deleting disk files...", rrdhost_hostname(host));
 
     RRDSET *st;
 
@@ -1491,7 +1491,7 @@ void rrdhost_delete_charts(RRDHOST *host) {
 void rrdhost_cleanup_charts(RRDHOST *host) {
     if(!host) return;
 
-    info("RRD: 'host:%s' cleaning up disk files...", rrdhost_hostname(host));
+    netdata_info("RRD: 'host:%s' cleaning up disk files...", rrdhost_hostname(host));
 
     RRDSET *st;
     uint32_t rrdhost_delete_obsolete_charts = rrdhost_option_check(host, RRDHOST_OPTION_DELETE_OBSOLETE_CHARTS);
@@ -1518,7 +1518,7 @@ void rrdhost_cleanup_charts(RRDHOST *host) {
 // RRDHOST - save all hosts to disk
 
 void rrdhost_save_all(void) {
-    info("RRD: saving databases [%zu hosts(s)]...", rrdhost_hosts_available());
+    netdata_info("RRD: saving databases [%zu hosts(s)]...", rrdhost_hosts_available());
 
     rrd_rdlock();
 
@@ -1533,7 +1533,7 @@ void rrdhost_save_all(void) {
 // RRDHOST - save or delete all hosts from disk
 
 void rrdhost_cleanup_all(void) {
-    info("RRD: cleaning up database [%zu hosts(s)]...", rrdhost_hosts_available());
+    netdata_info("RRD: cleaning up database [%zu hosts(s)]...", rrdhost_hosts_available());
 
     rrd_rdlock();
 
diff --git a/database/rrdset.c b/database/rrdset.c
index 3177f43..fbd3770 100644
--- a/database/rrdset.c
+++ b/database/rrdset.c
@@ -64,7 +64,7 @@ static STRING *rrdset_fix_name(RRDHOST *host, const char *chart_full_id, const c
                 i++;
             } while (rrdset_index_find_name(host, new_name));
 
-            info("RRDSET: using name '%s' for chart '%s' on host '%s'.", new_name, full_name, rrdhost_hostname(host));
+            netdata_info("RRDSET: using name '%s' for chart '%s' on host '%s'.", new_name, full_name, rrdhost_hostname(host));
         }
         else
             return NULL;
@@ -147,7 +147,7 @@ static void rrdset_insert_callback(const DICTIONARY_ITEM *item __maybe_unused, v
 
     if(st->rrd_memory_mode == RRD_MEMORY_MODE_SAVE || st->rrd_memory_mode == RRD_MEMORY_MODE_MAP) {
         if(!rrdset_memory_load_or_create_map_save(st, st->rrd_memory_mode)) {
-            info("Failed to use db mode %s for chart '%s', falling back to ram mode.", (st->rrd_memory_mode == RRD_MEMORY_MODE_MAP)?"map":"save", rrdset_name(st));
+            netdata_info("Failed to use db mode %s for chart '%s', falling back to ram mode.", (st->rrd_memory_mode == RRD_MEMORY_MODE_MAP)?"map":"save", rrdset_name(st));
             st->rrd_memory_mode = RRD_MEMORY_MODE_RAM;
         }
     }
@@ -660,7 +660,7 @@ void rrdset_get_retention_of_tier_for_collected_chart(RRDSET *st, time_t *first_
 
 inline void rrdset_is_obsolete(RRDSET *st) {
     if(unlikely(rrdset_flag_check(st, RRDSET_FLAG_ARCHIVED))) {
-        info("Cannot obsolete already archived chart %s", rrdset_name(st));
+        netdata_info("Cannot obsolete already archived chart %s", rrdset_name(st));
         return;
     }
 
@@ -717,7 +717,7 @@ inline void rrdset_update_heterogeneous_flag(RRDSET *st) {
         if(algorithm != rd->algorithm || multiplier != ABS(rd->multiplier) || divisor != ABS(rd->divisor)) {
             if(!rrdset_flag_check(st, RRDSET_FLAG_HETEROGENEOUS)) {
                 #ifdef NETDATA_INTERNAL_CHECKS
-                info("Dimension '%s' added on chart '%s' of host '%s' is not homogeneous to other dimensions already present (algorithm is '%s' vs '%s', multiplier is " COLLECTED_NUMBER_FORMAT " vs " COLLECTED_NUMBER_FORMAT ", divisor is " COLLECTED_NUMBER_FORMAT " vs " COLLECTED_NUMBER_FORMAT ").",
+                netdata_info("Dimension '%s' added on chart '%s' of host '%s' is not homogeneous to other dimensions already present (algorithm is '%s' vs '%s', multiplier is " COLLECTED_NUMBER_FORMAT " vs " COLLECTED_NUMBER_FORMAT ", divisor is " COLLECTED_NUMBER_FORMAT " vs " COLLECTED_NUMBER_FORMAT ").",
                      rrddim_name(rd),
                      rrdset_name(st),
                      rrdhost_hostname(host),
@@ -833,12 +833,12 @@ void rrdset_save(RRDSET *st) {
 void rrdset_delete_files(RRDSET *st) {
     RRDDIM *rd;
 
-    info("Deleting chart '%s' ('%s') from disk...", rrdset_id(st), rrdset_name(st));
+    netdata_info("Deleting chart '%s' ('%s') from disk...", rrdset_id(st), rrdset_name(st));
 
     if(st->rrd_memory_mode == RRD_MEMORY_MODE_SAVE || st->rrd_memory_mode == RRD_MEMORY_MODE_MAP) {
         const char *cache_filename = rrdset_cache_filename(st);
         if(cache_filename) {
-            info("Deleting chart header file '%s'.", cache_filename);
+            netdata_info("Deleting chart header file '%s'.", cache_filename);
             if (unlikely(unlink(cache_filename) == -1))
                 error("Cannot delete chart header file '%s'", cache_filename);
         }
@@ -850,7 +850,7 @@ void rrdset_delete_files(RRDSET *st) {
         const char *cache_filename = rrddim_cache_filename(rd);
         if(!cache_filename) continue;
 
-        info("Deleting dimension file '%s'.", cache_filename);
+        netdata_info("Deleting dimension file '%s'.", cache_filename);
         if(unlikely(unlink(cache_filename) == -1))
             error("Cannot delete dimension file '%s'", cache_filename);
     }
@@ -863,13 +863,13 @@ void rrdset_delete_files(RRDSET *st) {
 void rrdset_delete_obsolete_dimensions(RRDSET *st) {
     RRDDIM *rd;
 
-    info("Deleting dimensions of chart '%s' ('%s') from disk...", rrdset_id(st), rrdset_name(st));
+    netdata_info("Deleting dimensions of chart '%s' ('%s') from disk...", rrdset_id(st), rrdset_name(st));
 
     rrddim_foreach_read(rd, st) {
         if(rrddim_flag_check(rd, RRDDIM_FLAG_OBSOLETE)) {
             const char *cache_filename = rrddim_cache_filename(rd);
             if(!cache_filename) continue;
-            info("Deleting dimension file '%s'.", cache_filename);
+            netdata_info("Deleting dimension file '%s'.", cache_filename);
             if(unlikely(unlink(cache_filename) == -1))
                 error("Cannot delete dimension file '%s'", cache_filename);
         }
@@ -999,7 +999,7 @@ void rrdset_timed_next(RRDSET *st, struct timeval now, usec_t duration_since_las
         if(unlikely(since_last_usec < 0)) {
             // oops! the database is in the future
             #ifdef NETDATA_INTERNAL_CHECKS
-            info("RRD database for chart '%s' on host '%s' is %0.5" NETDATA_DOUBLE_MODIFIER
+            netdata_info("RRD database for chart '%s' on host '%s' is %0.5" NETDATA_DOUBLE_MODIFIER
                 " secs in the future (counter #%zu, update #%zu). Adjusting it to current time."
                 , rrdset_id(st)
                 , rrdhost_hostname(st->rrdhost)
@@ -1018,7 +1018,7 @@ void rrdset_timed_next(RRDSET *st, struct timeval now, usec_t duration_since_las
         else if(unlikely((usec_t)since_last_usec > (usec_t)(st->update_every * 5 * USEC_PER_SEC))) {
             // oops! the database is too far behind
             #ifdef NETDATA_INTERNAL_CHECKS
-            info("RRD database for chart '%s' on host '%s' is %0.5" NETDATA_DOUBLE_MODIFIER
+            netdata_info("RRD database for chart '%s' on host '%s' is %0.5" NETDATA_DOUBLE_MODIFIER
                 " secs in the past (counter #%zu, update #%zu). Adjusting it to current time.", rrdset_id(st), rrdhost_hostname(st->rrdhost), (NETDATA_DOUBLE)since_last_usec / USEC_PER_SEC, st->counter, st->counter_done);
             #endif
 
@@ -1044,7 +1044,7 @@ void rrdset_timed_next(RRDSET *st, struct timeval now, usec_t duration_since_las
                 last_time_s = now.tv_sec;
 
                 if(min_delta > permanent_min_delta) {
-                    info("MINIMUM MICROSECONDS DELTA of thread %d increased from %lld to %lld (+%lld)", gettid(), permanent_min_delta, min_delta, min_delta - permanent_min_delta);
+                    netdata_info("MINIMUM MICROSECONDS DELTA of thread %d increased from %lld to %lld (+%lld)", gettid(), permanent_min_delta, min_delta, min_delta - permanent_min_delta);
                     permanent_min_delta = min_delta;
                 }
 
@@ -1540,7 +1540,7 @@ void rrdset_timed_done(RRDSET *st, struct timeval now, bool pending_rrdset_next)
 
     // check if the chart has a long time to be updated
     if(unlikely(st->usec_since_last_update > MAX(st->entries, 60) * update_every_ut)) {
-        info("host '%s', chart '%s': took too long to be updated (counter #%zu, update #%zu, %0.3" NETDATA_DOUBLE_MODIFIER
+        netdata_info("host '%s', chart '%s': took too long to be updated (counter #%zu, update #%zu, %0.3" NETDATA_DOUBLE_MODIFIER
             " secs). Resetting it.", rrdhost_hostname(st->rrdhost), rrdset_id(st), st->counter, st->counter_done, (NETDATA_DOUBLE)st->usec_since_last_update / USEC_PER_SEC);
         rrdset_reset(st);
         st->usec_since_last_update = update_every_ut;
@@ -1581,7 +1581,7 @@ void rrdset_timed_done(RRDSET *st, struct timeval now, bool pending_rrdset_next)
     // check if we will re-write the entire data set
     if(unlikely(dt_usec(&st->last_collected_time, &st->last_updated) > st->entries * update_every_ut &&
                 st->rrd_memory_mode != RRD_MEMORY_MODE_DBENGINE)) {
-        info(
+        netdata_info(
             "'%s': too old data (last updated at %"PRId64".%"PRId64", last collected at %"PRId64".%"PRId64"). "
             "Resetting it. Will not store the next entry.",
             rrdset_id(st),
@@ -2159,7 +2159,7 @@ bool rrdset_memory_load_or_create_map_save(RRDSET *st, RRD_MEMORY_MODE memory_mo
 
     st_on_file->magic[sizeof(RRDSET_MAGIC_V019)] = '\0';
     if(strcmp(st_on_file->magic, RRDSET_MAGIC_V019) != 0) {
-        info("Initializing file '%s'.", fullfilename);
+        netdata_info("Initializing file '%s'.", fullfilename);
         memset(st_on_file, 0, size);
     }
     else if(strncmp(st_on_file->id, rrdset_id(st), RRD_ID_LENGTH_MAX_V019) != 0) {
@@ -2175,7 +2175,7 @@ bool rrdset_memory_load_or_create_map_save(RRDSET *st, RRD_MEMORY_MODE memory_mo
         memset(st_on_file, 0, size);
     }
     else if((now_s - st_on_file->last_updated.tv_sec) > st->update_every * st->entries) {
-        info("File '%s' is too old. Clearing it.", fullfilename);
+        netdata_info("File '%s' is too old. Clearing it.", fullfilename);
         memset(st_on_file, 0, size);
     }
     else if(st_on_file->last_updated.tv_sec > now_s + st->update_every) {
diff --git a/database/sqlite/sqlite_aclk.c b/database/sqlite/sqlite_aclk.c
index a33e09f..bd2bfc4 100644
--- a/database/sqlite/sqlite_aclk.c
+++ b/database/sqlite/sqlite_aclk.c
@@ -385,7 +385,7 @@ static void aclk_synchronization(void *arg __maybe_unused)
     config->timer_req.data = config;
     fatal_assert(0 == uv_timer_start(&config->timer_req, timer_cb, TIMER_PERIOD_MS, TIMER_PERIOD_MS));
 
-    info("Starting ACLK synchronization thread");
+    netdata_info("Starting ACLK synchronization thread");
 
     config->cleanup_after = now_realtime_sec() + ACLK_DATABASE_CLEANUP_FIRST;
     config->initialized = true;
@@ -462,7 +462,7 @@ static void aclk_synchronization(void *arg __maybe_unused)
 
     worker_unregister();
     service_exits();
-    info("ACLK SYNC: Shutting down ACLK synchronization event loop");
+    netdata_info("ACLK SYNC: Shutting down ACLK synchronization event loop");
 }
 
 static void aclk_synchronization_init(void)
@@ -543,7 +543,7 @@ void sql_aclk_sync_init(void)
         return;
     }
 
-    info("Creating archived hosts");
+    netdata_info("Creating archived hosts");
     int number_of_children = 0;
     rc = sqlite3_exec_monitored(db_meta, SQL_FETCH_ALL_HOSTS, create_host_callback, &number_of_children, &err_msg);
 
@@ -552,7 +552,7 @@ void sql_aclk_sync_init(void)
         sqlite3_free(err_msg);
     }
 
-    info("Created %d archived hosts", number_of_children);
+    netdata_info("Created %d archived hosts", number_of_children);
     // Trigger host context load for hosts that have been created
     metadata_queue_load_host_context(NULL);
 
@@ -568,7 +568,7 @@ void sql_aclk_sync_init(void)
     }
     aclk_synchronization_init();
 
-    info("ACLK sync initialization completed");
+    netdata_info("ACLK sync initialization completed");
 #endif
 }
 
diff --git a/database/sqlite/sqlite_aclk_node.c b/database/sqlite/sqlite_aclk_node.c
index 3817296..35ad9db 100644
--- a/database/sqlite/sqlite_aclk_node.c
+++ b/database/sqlite/sqlite_aclk_node.c
@@ -172,7 +172,7 @@ void aclk_check_node_info_and_collectors(void)
     dfe_done(host);
 
     if(pending)
-        info("ACLK: %zu nodes are pending for contexts to load, skipped sending node info for them", pending);
+        netdata_info("ACLK: %zu nodes are pending for contexts to load, skipped sending node info for them", pending);
 }
 
 #endif
diff --git a/database/sqlite/sqlite_context.c b/database/sqlite/sqlite_context.c
index b72726d..8b36116 100644
--- a/database/sqlite/sqlite_context.c
+++ b/database/sqlite/sqlite_context.c
@@ -43,7 +43,7 @@ int sql_init_context_database(int memory)
         return 1;
     }
 
-    info("SQLite database %s initialization", sqlite_database);
+    netdata_info("SQLite database %s initialization", sqlite_database);
 
     char buf[1024 + 1] = "";
     const char *list[2] = { buf, NULL };
@@ -112,7 +112,7 @@ void sql_close_context_database(void)
     if (unlikely(!db_context_meta))
         return;
 
-    info("Closing context SQLite database");
+    netdata_info("Closing context SQLite database");
 
     rc = sqlite3_close_v2(db_context_meta);
     if (unlikely(rc != SQLITE_OK))
@@ -431,7 +431,7 @@ int ctx_delete_context(uuid_t *host_uuid, VERSIONED_CONTEXT_DATA *context_data)
     else {
         char host_uuid_str[UUID_STR_LEN];
         uuid_unparse_lower(*host_uuid, host_uuid_str);
-        info("%s: Deleted context %s under host %s", __FUNCTION__, context_data->id, host_uuid_str);
+        netdata_info("%s: Deleted context %s under host %s", __FUNCTION__, context_data->id, host_uuid_str);
     }
 #endif
 
@@ -463,7 +463,7 @@ int sql_context_cache_stats(int op)
 static void dict_ctx_get_context_list_cb(VERSIONED_CONTEXT_DATA *context_data, void *data)
 {
     (void)data;
-    info("   Context id = %s "
+    netdata_info("   Context id = %s "
          "version = %"PRIu64" "
          "title = %s "
          "chart_type = %s "
@@ -512,48 +512,48 @@ int ctx_unittest(void)
     context_data.version  = now_realtime_usec();
 
     if (likely(!ctx_store_context(&host_uuid, &context_data)))
-        info("Entry %s inserted", context_data.id);
+        netdata_info("Entry %s inserted", context_data.id);
     else
-        info("Entry %s not inserted", context_data.id);
+        netdata_info("Entry %s not inserted", context_data.id);
 
     if (likely(!ctx_store_context(&host_uuid, &context_data)))
-        info("Entry %s inserted", context_data.id);
+        netdata_info("Entry %s inserted", context_data.id);
     else
-        info("Entry %s not inserted", context_data.id);
+        netdata_info("Entry %s not inserted", context_data.id);
 
     // This will change end time
     context_data.first_time_s = 1657781000;
     context_data.last_time_s  = 1657782001;
     if (likely(!ctx_update_context(&host_uuid, &context_data)))
-        info("Entry %s updated", context_data.id);
+        netdata_info("Entry %s updated", context_data.id);
     else
-        info("Entry %s not updated", context_data.id);
-    info("List context start after insert");
+        netdata_info("Entry %s not updated", context_data.id);
+    netdata_info("List context start after insert");
     ctx_get_context_list(&host_uuid, dict_ctx_get_context_list_cb, NULL);
-    info("List context end after insert");
+    netdata_info("List context end after insert");
 
     // This will change start time
     context_data.first_time_s = 1657782000;
     context_data.last_time_s  = 1657782001;
     if (likely(!ctx_update_context(&host_uuid, &context_data)))
-        info("Entry %s updated", context_data.id);
+        netdata_info("Entry %s updated", context_data.id);
     else
-        info("Entry %s not updated", context_data.id);
+        netdata_info("Entry %s not updated", context_data.id);
 
     // This will list one entry
-    info("List context start after insert");
+    netdata_info("List context start after insert");
     ctx_get_context_list(&host_uuid, dict_ctx_get_context_list_cb, NULL);
-    info("List context end after insert");
+    netdata_info("List context end after insert");
 
-    info("List context start after insert");
+    netdata_info("List context start after insert");
     ctx_get_context_list(&host_uuid, dict_ctx_get_context_list_cb, NULL);
-    info("List context end after insert");
+    netdata_info("List context end after insert");
 
     // This will delete the entry
     if (likely(!ctx_delete_context(&host_uuid, &context_data)))
-        info("Entry %s deleted", context_data.id);
+        netdata_info("Entry %s deleted", context_data.id);
     else
-        info("Entry %s not deleted", context_data.id);
+        netdata_info("Entry %s not deleted", context_data.id);
 
     freez((void *)context_data.id);
     freez((void *)context_data.title);
@@ -562,9 +562,9 @@ int ctx_unittest(void)
     freez((void *)context_data.units);
 
     // The list should be empty
-    info("List context start after delete");
+    netdata_info("List context start after delete");
     ctx_get_context_list(&host_uuid, dict_ctx_get_context_list_cb, NULL);
-    info("List context end after delete");
+    netdata_info("List context end after delete");
 
     sql_close_context_database();
 
diff --git a/database/sqlite/sqlite_db_migration.c b/database/sqlite/sqlite_db_migration.c
index 9c7235f..dd99d22 100644
--- a/database/sqlite/sqlite_db_migration.c
+++ b/database/sqlite/sqlite_db_migration.c
@@ -23,7 +23,7 @@ int table_exists_in_database(const char *table)
 
     int rc = sqlite3_exec_monitored(db_meta, sql, return_int_cb, (void *) &exists, &err_msg);
     if (rc != SQLITE_OK) {
-        info("Error checking table existence; %s", err_msg);
+        netdata_info("Error checking table existence; %s", err_msg);
         sqlite3_free(err_msg);
     }
 
@@ -41,7 +41,7 @@ static int column_exists_in_table(const char *table, const char *column)
 
     int rc = sqlite3_exec_monitored(db_meta, sql, return_int_cb, (void *) &exists, &err_msg);
     if (rc != SQLITE_OK) {
-        info("Error checking column existence; %s", err_msg);
+        netdata_info("Error checking column existence; %s", err_msg);
         sqlite3_free(err_msg);
     }
 
@@ -83,7 +83,7 @@ const char *database_migrate_v5_v6[] = {
 static int do_migration_v1_v2(sqlite3 *database, const char *name)
 {
     UNUSED(name);
-    info("Running \"%s\" database migration", name);
+    netdata_info("Running \"%s\" database migration", name);
 
     if (table_exists_in_database("host") && !column_exists_in_table("host", "hops"))
         return init_database_batch(database, DB_CHECK_NONE, 0, &database_migrate_v1_v2[0]);
@@ -93,7 +93,7 @@ static int do_migration_v1_v2(sqlite3 *database, const char *name)
 static int do_migration_v2_v3(sqlite3 *database, const char *name)
 {
     UNUSED(name);
-    info("Running \"%s\" database migration", name);
+    netdata_info("Running \"%s\" database migration", name);
 
     if (table_exists_in_database("host") && !column_exists_in_table("host", "memory_mode"))
         return init_database_batch(database, DB_CHECK_NONE, 0, &database_migrate_v2_v3[0]);
@@ -103,7 +103,7 @@ static int do_migration_v2_v3(sqlite3 *database, const char *name)
 static int do_migration_v3_v4(sqlite3 *database, const char *name)
 {
     UNUSED(name);
-    info("Running database migration %s", name);
+    netdata_info("Running database migration %s", name);
 
     char sql[256];
 
@@ -135,7 +135,7 @@ static int do_migration_v3_v4(sqlite3 *database, const char *name)
 static int do_migration_v4_v5(sqlite3 *database, const char *name)
 {
     UNUSED(name);
-    info("Running \"%s\" database migration", name);
+    netdata_info("Running \"%s\" database migration", name);
 
     return init_database_batch(database, DB_CHECK_NONE, 0, &database_migrate_v4_v5[0]);
 }
@@ -143,7 +143,7 @@ static int do_migration_v4_v5(sqlite3 *database, const char *name)
 static int do_migration_v5_v6(sqlite3 *database, const char *name)
 {
     UNUSED(name);
-    info("Running \"%s\" database migration", name);
+    netdata_info("Running \"%s\" database migration", name);
 
     return init_database_batch(database, DB_CHECK_NONE, 0, &database_migrate_v5_v6[0]);
 }
@@ -151,7 +151,7 @@ static int do_migration_v5_v6(sqlite3 *database, const char *name)
 static int do_migration_v6_v7(sqlite3 *database, const char *name)
 {
     UNUSED(name);
-    info("Running \"%s\" database migration", name);
+    netdata_info("Running \"%s\" database migration", name);
 
     char sql[256];
 
@@ -185,7 +185,7 @@ static int do_migration_v6_v7(sqlite3 *database, const char *name)
 static int do_migration_v7_v8(sqlite3 *database, const char *name)
 {
     UNUSED(name);
-    info("Running database migration %s", name);
+    netdata_info("Running database migration %s", name);
 
     char sql[256];
 
@@ -219,7 +219,7 @@ static int do_migration_noop(sqlite3 *database, const char *name)
 {
     UNUSED(database);
     UNUSED(name);
-    info("Running database migration %s", name);
+    netdata_info("Running database migration %s", name);
     return 0;
 }
 
@@ -236,16 +236,16 @@ static int migrate_database(sqlite3 *database, int target_version, char *db_name
 
     int rc = sqlite3_exec_monitored(database, "PRAGMA user_version;", return_int_cb, (void *) &user_version, &err_msg);
     if (rc != SQLITE_OK) {
-        info("Error checking the %s database version; %s", db_name, err_msg);
+        netdata_info("Error checking the %s database version; %s", db_name, err_msg);
         sqlite3_free(err_msg);
     }
 
     if (likely(user_version == target_version)) {
-        info("%s database version is %d (no migration needed)", db_name, target_version);
+        netdata_info("%s database version is %d (no migration needed)", db_name, target_version);
         return target_version;
     }
 
-    info("Database version is %d, current version is %d. Running migration for %s ...", user_version, target_version, db_name);
+    netdata_info("Database version is %d, current version is %d. Running migration for %s ...", user_version, target_version, db_name);
     for (int i = user_version; i < target_version && migration_list[i].func; i++) {
         rc = (migration_list[i].func)(database, migration_list[i].name);
         if (unlikely(rc)) {
diff --git a/database/sqlite/sqlite_functions.c b/database/sqlite/sqlite_functions.c
index 555db10..c9360f0 100644
--- a/database/sqlite/sqlite_functions.c
+++ b/database/sqlite/sqlite_functions.c
@@ -128,9 +128,9 @@ static void add_stmt_to_list(sqlite3_stmt *res)
 
     if (unlikely(!res)) {
         if (idx)
-            info("Finilizing %d statements", idx);
+            netdata_info("Finilizing %d statements", idx);
         else
-            info("No statements pending to finalize");
+            netdata_info("No statements pending to finalize");
         while (idx > 0) {
             int rc;
             rc = sqlite3_finalize(statements[--idx]);
@@ -148,7 +148,7 @@ static void release_statement(void *statement)
 {
     int rc;
 #ifdef NETDATA_DEV_MODE
-    info("Thread %d: Cleaning prepared statement on %p", gettid(), statement);
+    netdata_info("Thread %d: Cleaning prepared statement on %p", gettid(), statement);
 #endif
     if (unlikely(rc = sqlite3_finalize((sqlite3_stmt *) statement) != SQLITE_OK))
         error_report("Failed to finalize statement, rc = %d", rc);
@@ -175,7 +175,7 @@ int prepare_statement(sqlite3 *database, const char *query, sqlite3_stmt **state
         if (likely(key)) {
             ret = pthread_setspecific(*key, *statement);
 #ifdef NETDATA_DEV_MODE
-            info("Thread %d: Using key %u on statement %p", gettid(), keys_used, *statement);
+            netdata_info("Thread %d: Using key %u on statement %p", gettid(), keys_used, *statement);
 #endif
         }
         if (ret)
@@ -189,7 +189,7 @@ static int check_table_integrity_cb(void *data, int argc, char **argv, char **co
     int *status = data;
     UNUSED(argc);
     UNUSED(column);
-    info("---> %s", argv[0]);
+    netdata_info("---> %s", argv[0]);
     *status = (strcmp(argv[0], "ok") != 0);
     return 0;
 }
@@ -202,11 +202,11 @@ static int check_table_integrity(char *table)
     char wstr[255];
 
     if (table) {
-        info("Checking table %s", table);
+        netdata_info("Checking table %s", table);
         snprintfz(wstr, 254, "PRAGMA integrity_check(%s);", table);
     }
     else {
-        info("Checking entire database");
+        netdata_info("Checking entire database");
         strcpy(wstr,"PRAGMA integrity_check;");
     }
 
@@ -240,9 +240,9 @@ static void rebuild_chart()
 {
     int rc;
     char *err_msg = NULL;
-    info("Rebuilding chart table");
+    netdata_info("Rebuilding chart table");
     for (int i = 0; rebuild_chart_commands[i]; i++) {
-        info("Executing %s", rebuild_chart_commands[i]);
+        netdata_info("Executing %s", rebuild_chart_commands[i]);
         rc = sqlite3_exec_monitored(db_meta, rebuild_chart_commands[i], 0, 0, &err_msg);
         if (rc != SQLITE_OK) {
             error_report("SQLite error during database setup, rc = %d (%s)", rc, err_msg);
@@ -272,9 +272,9 @@ void rebuild_dimension()
     int rc;
     char *err_msg = NULL;
 
-    info("Rebuilding dimension table");
+    netdata_info("Rebuilding dimension table");
     for (int i = 0; rebuild_dimension_commands[i]; i++) {
-        info("Executing %s", rebuild_dimension_commands[i]);
+        netdata_info("Executing %s", rebuild_dimension_commands[i]);
         rc = sqlite3_exec_monitored(db_meta, rebuild_dimension_commands[i], 0, 0, &err_msg);
         if (rc != SQLITE_OK) {
             error_report("SQLite error during database setup, rc = %d (%s)", rc, err_msg);
@@ -286,11 +286,11 @@ void rebuild_dimension()
 
 static int attempt_database_fix()
 {
-    info("Closing database and attempting to fix it");
+    netdata_info("Closing database and attempting to fix it");
     int rc = sqlite3_close(db_meta);
     if (rc != SQLITE_OK)
         error_report("Failed to close database, rc = %d", rc);
-    info("Attempting to fix database");
+    netdata_info("Attempting to fix database");
     db_meta = NULL;
     return sql_init_database(DB_CHECK_FIX_DB | DB_CHECK_CONT, 0);
 }
@@ -363,7 +363,7 @@ int sql_init_database(db_check_action_type_t rebuild, int memory)
     if (rebuild & (DB_CHECK_INTEGRITY | DB_CHECK_FIX_DB)) {
         int errors_detected = 0;
         if (!(rebuild & DB_CHECK_CONT))
-            info("Running database check on %s", sqlite_database);
+            netdata_info("Running database check on %s", sqlite_database);
 
         if (check_table_integrity("chart")) {
             errors_detected++;
@@ -389,7 +389,7 @@ int sql_init_database(db_check_action_type_t rebuild, int memory)
 
     if (rebuild & DB_CHECK_RECLAIM_SPACE) {
         if (!(rebuild & DB_CHECK_CONT))
-            info("Reclaiming space of %s", sqlite_database);
+            netdata_info("Reclaiming space of %s", sqlite_database);
         rc = sqlite3_exec_monitored(db_meta, "VACUUM;", 0, 0, &err_msg);
         if (rc != SQLITE_OK) {
             error_report("Failed to execute VACUUM rc = %d (%s)", rc, err_msg);
@@ -400,7 +400,7 @@ int sql_init_database(db_check_action_type_t rebuild, int memory)
     if (rebuild && !(rebuild & DB_CHECK_CONT))
         return 1;
 
-    info("SQLite database %s initialization", sqlite_database);
+    netdata_info("SQLite database %s initialization", sqlite_database);
 
     char buf[1024 + 1] = "";
     const char *list[2] = { buf, NULL };
@@ -450,7 +450,7 @@ int sql_init_database(db_check_action_type_t rebuild, int memory)
     if (init_database_batch(db_meta, rebuild, 0, &database_cleanup[0]))
         return 1;
 
-    info("SQLite database initialization completed");
+    netdata_info("SQLite database initialization completed");
 
     initialize_thread_key_pool();
 
@@ -470,7 +470,7 @@ void sql_close_database(void)
     if (unlikely(!db_meta))
         return;
 
-    info("Closing SQLite database");
+    netdata_info("Closing SQLite database");
 
     add_stmt_to_list(NULL);
 
@@ -771,7 +771,7 @@ struct node_instance_list *get_node_list(void)
             uuid_unparse_lower(*host_id, host_guid);
             RRDHOST *host = rrdhost_find_by_guid(host_guid);
             if (rrdhost_flag_check(host, RRDHOST_FLAG_PENDING_CONTEXT_LOAD)) {
-                info("ACLK: 'host:%s' skipping get node list because context is initializing", rrdhost_hostname(host));
+                netdata_info("ACLK: 'host:%s' skipping get node list because context is initializing", rrdhost_hostname(host));
                 continue;
             }
             uuid_copy(node_list[row].host_id, *host_id);
diff --git a/database/sqlite/sqlite_health.c b/database/sqlite/sqlite_health.c
index 5c4cdbb..435bfbb 100644
--- a/database/sqlite/sqlite_health.c
+++ b/database/sqlite/sqlite_health.c
@@ -404,7 +404,7 @@ void sql_health_alarm_log_count(RRDHOST *host) {
     if (unlikely(rc != SQLITE_OK))
         error_report("Failed to finalize the prepared statement to count health log entries from db");
 
-    info("HEALTH [%s]: Table health_log_%s, contains %lu entries.", rrdhost_hostname(host), uuid_str, (unsigned long int) host->health.health_log_entries_written);
+    netdata_info("HEALTH [%s]: Table health_log_%s, contains %lu entries.", rrdhost_hostname(host), uuid_str, (unsigned long int) host->health.health_log_entries_written);
 }
 
 /* Health related SQL queries
diff --git a/database/sqlite/sqlite_metadata.c b/database/sqlite/sqlite_metadata.c
index 607d789..61c993a 100644
--- a/database/sqlite/sqlite_metadata.c
+++ b/database/sqlite/sqlite_metadata.c
@@ -665,7 +665,7 @@ static void check_dimension_metadata(struct metadata_wc *wc)
     uint32_t total_deleted= 0;
     uint64_t last_row_id = wc->row_id;
 
-    info("METADATA: Checking dimensions starting after row %"PRIu64, wc->row_id);
+    netdata_info("METADATA: Checking dimensions starting after row %"PRIu64, wc->row_id);
 
     while (sqlite3_step_monitored(res) == SQLITE_ROW && total_deleted < MAX_METADATA_CLEANUP) {
         if (unlikely(metadata_flag_check(wc, METADATA_FLAG_SHUTDOWN)))
@@ -685,7 +685,7 @@ static void check_dimension_metadata(struct metadata_wc *wc)
         wc->check_metadata_after = now + METADATA_MAINTENANCE_RETRY;
     } else
         wc->row_id = 0;
-    info("METADATA: Checked %u, deleted %u -- will resume after row %"PRIu64" in %lld seconds", total_checked, total_deleted, wc->row_id,
+    netdata_info("METADATA: Checked %u, deleted %u -- will resume after row %"PRIu64" in %lld seconds", total_checked, total_deleted, wc->row_id,
          (long long)(wc->check_metadata_after - now));
 
 skip_run:
@@ -1244,7 +1244,7 @@ static void metadata_event_loop(void *arg)
     wc->timer_req.data = wc;
     fatal_assert(0 == uv_timer_start(&wc->timer_req, timer_cb, TIMER_INITIAL_PERIOD_MS, TIMER_REPEAT_PERIOD_MS));
 
-    info("Starting metadata sync thread with %d entries command queue", METADATA_CMD_Q_MAX_SIZE);
+    netdata_info("Starting metadata sync thread with %d entries command queue", METADATA_CMD_Q_MAX_SIZE);
 
     struct metadata_cmd cmd;
     memset(&cmd, 0, sizeof(cmd));
@@ -1394,7 +1394,7 @@ static void metadata_event_loop(void *arg)
     freez(loop);
     worker_unregister();
 
-    info("METADATA: Shutting down event loop");
+    netdata_info("METADATA: Shutting down event loop");
     completion_mark_complete(&wc->init_complete);
     return;
 
@@ -1415,15 +1415,15 @@ void metadata_sync_shutdown(void)
 
     struct metadata_cmd cmd;
     memset(&cmd, 0, sizeof(cmd));
-    info("METADATA: Sending a shutdown command");
+    netdata_info("METADATA: Sending a shutdown command");
     cmd.opcode = METADATA_SYNC_SHUTDOWN;
     metadata_enq_cmd(&metasync_worker, &cmd);
 
     /* wait for metadata thread to shut down */
-    info("METADATA: Waiting for shutdown ACK");
+    netdata_info("METADATA: Waiting for shutdown ACK");
     completion_wait_for(&metasync_worker.init_complete);
     completion_destroy(&metasync_worker.init_complete);
-    info("METADATA: Shutdown complete");
+    netdata_info("METADATA: Shutdown complete");
 }
 
 void metadata_sync_shutdown_prepare(void)
@@ -1437,11 +1437,11 @@ void metadata_sync_shutdown_prepare(void)
     struct completion compl;
     completion_init(&compl);
 
-    info("METADATA: Sending a scan host command");
+    netdata_info("METADATA: Sending a scan host command");
     uint32_t max_wait_iterations = 2000;
     while (unlikely(metadata_flag_check(&metasync_worker, METADATA_FLAG_SCANNING_HOSTS)) && max_wait_iterations--) {
         if (max_wait_iterations == 1999)
-            info("METADATA: Current worker is running; waiting to finish");
+            netdata_info("METADATA: Current worker is running; waiting to finish");
         sleep_usec(1000);
     }
 
@@ -1449,10 +1449,10 @@ void metadata_sync_shutdown_prepare(void)
     cmd.completion = &compl;
     metadata_enq_cmd(&metasync_worker, &cmd);
 
-    info("METADATA: Waiting for host scan completion");
+    netdata_info("METADATA: Waiting for host scan completion");
     completion_wait_for(&compl);
     completion_destroy(&compl);
-    info("METADATA: Host scan complete; can continue with shutdown");
+    netdata_info("METADATA: Host scan complete; can continue with shutdown");
 }
 
 // -------------------------------------------------------------
@@ -1471,7 +1471,7 @@ void metadata_sync_init(void)
     completion_wait_for(&wc->init_complete);
     completion_destroy(&wc->init_complete);
 
-    info("SQLite metadata sync initialization complete");
+    netdata_info("SQLite metadata sync initialization complete");
 }
 
 
diff --git a/exporting/aws_kinesis/aws_kinesis.c b/exporting/aws_kinesis/aws_kinesis.c
index c7d7a9d..03d3a42 100644
--- a/exporting/aws_kinesis/aws_kinesis.c
+++ b/exporting/aws_kinesis/aws_kinesis.c
@@ -7,7 +7,7 @@
  */
 void aws_kinesis_cleanup(struct instance *instance)
 {
-    info("EXPORTING: cleaning up instance %s ...", instance->config.name);
+    netdata_info("EXPORTING: cleaning up instance %s ...", instance->config.name);
     kinesis_shutdown(instance->connector_specific_data);
 
     freez(instance->connector_specific_data);
@@ -21,7 +21,7 @@ void aws_kinesis_cleanup(struct instance *instance)
         freez(connector_specific_config);
     }
 
-    info("EXPORTING: instance %s exited", instance->config.name);
+    netdata_info("EXPORTING: instance %s exited", instance->config.name);
     instance->exited = 1;
 }
 
diff --git a/exporting/check_filters.c b/exporting/check_filters.c
index 9b573f0..b982209 100644
--- a/exporting/check_filters.c
+++ b/exporting/check_filters.c
@@ -29,10 +29,10 @@ int rrdhost_is_exportable(struct instance *instance, RRDHOST *host)
 
         if (!instance->config.hosts_pattern || simple_pattern_matches(instance->config.hosts_pattern, host_name)) {
             *flags |= RRDHOST_FLAG_EXPORTING_SEND;
-            info("enabled exporting of host '%s' for instance '%s'", host_name, instance->config.name);
+            netdata_info("enabled exporting of host '%s' for instance '%s'", host_name, instance->config.name);
         } else {
             *flags |= RRDHOST_FLAG_EXPORTING_DONT_SEND;
-            info("disabled exporting of host '%s' for instance '%s'", host_name, instance->config.name);
+            netdata_info("disabled exporting of host '%s' for instance '%s'", host_name, instance->config.name);
         }
     }
 
diff --git a/exporting/clean_connectors.c b/exporting/clean_connectors.c
index ab1fb5d..e990daa 100644
--- a/exporting/clean_connectors.c
+++ b/exporting/clean_connectors.c
@@ -46,7 +46,7 @@ void clean_instance(struct instance *instance)
  */
 void simple_connector_cleanup(struct instance *instance)
 {
-    info("EXPORTING: cleaning up instance %s ...", instance->config.name);
+    netdata_info("EXPORTING: cleaning up instance %s ...", instance->config.name);
 
     struct simple_connector_data *simple_connector_data =
         (struct simple_connector_data *)instance->connector_specific_data;
@@ -77,6 +77,6 @@ void simple_connector_cleanup(struct instance *instance)
         (struct simple_connector_config *)instance->config.connector_specific_config;
     freez(simple_connector_config);
 
-    info("EXPORTING: instance %s exited", instance->config.name);
+    netdata_info("EXPORTING: instance %s exited", instance->config.name);
     instance->exited = 1;
 }
diff --git a/exporting/exporting_engine.c b/exporting/exporting_engine.c
index 8f957c7..89ba682 100644
--- a/exporting/exporting_engine.c
+++ b/exporting/exporting_engine.c
@@ -124,7 +124,7 @@ static void exporting_main_cleanup(void *ptr)
     struct netdata_static_thread *static_thread = (struct netdata_static_thread *)ptr;
     static_thread->enabled = NETDATA_MAIN_THREAD_EXITING;
 
-    info("cleaning up...");
+    netdata_info("cleaning up...");
 
     if (!engine) {
         static_thread->enabled = NETDATA_MAIN_THREAD_EXITED;
@@ -139,17 +139,17 @@ static void exporting_main_cleanup(void *ptr)
     for (struct instance *instance = engine->instance_root; instance; instance = instance->next) {
         if (!instance->exited) {
             found++;
-            info("stopping worker for instance %s", instance->config.name);
+            netdata_info("stopping worker for instance %s", instance->config.name);
             uv_mutex_unlock(&instance->mutex);
             instance->data_is_ready = 1;
             uv_cond_signal(&instance->cond_var);
         } else
-            info("found stopped worker for instance %s", instance->config.name);
+            netdata_info("found stopped worker for instance %s", instance->config.name);
     }
 
     while (found && max > 0) {
         max -= step;
-        info("Waiting %d exporting connectors to finish...", found);
+        netdata_info("Waiting %d exporting connectors to finish...", found);
         sleep_usec(step);
         found = 0;
 
@@ -178,7 +178,7 @@ void *exporting_main(void *ptr)
 
     engine = read_exporting_config();
     if (!engine) {
-        info("EXPORTING: no exporting connectors configured");
+        netdata_info("EXPORTING: no exporting connectors configured");
         goto cleanup;
     }
 
diff --git a/exporting/mongodb/mongodb.c b/exporting/mongodb/mongodb.c
index 186a7dc..0372bce 100644
--- a/exporting/mongodb/mongodb.c
+++ b/exporting/mongodb/mongodb.c
@@ -229,7 +229,7 @@ int format_batch_mongodb(struct instance *instance)
  */
 void mongodb_cleanup(struct instance *instance)
 {
-    info("EXPORTING: cleaning up instance %s ...", instance->config.name);
+    netdata_info("EXPORTING: cleaning up instance %s ...", instance->config.name);
 
     struct mongodb_specific_data *connector_specific_data =
         (struct mongodb_specific_data *)instance->connector_specific_data;
@@ -261,7 +261,7 @@ void mongodb_cleanup(struct instance *instance)
     freez(connector_specific_config->collection);
     freez(connector_specific_config);
 
-    info("EXPORTING: instance %s exited", instance->config.name);
+    netdata_info("EXPORTING: instance %s exited", instance->config.name);
     instance->exited = 1;
 
     return;
diff --git a/exporting/pubsub/pubsub.c b/exporting/pubsub/pubsub.c
index d65fc2c..b293bdb 100644
--- a/exporting/pubsub/pubsub.c
+++ b/exporting/pubsub/pubsub.c
@@ -64,7 +64,7 @@ int init_pubsub_instance(struct instance *instance)
  */
 void clean_pubsub_instance(struct instance *instance)
 {
-    info("EXPORTING: cleaning up instance %s ...", instance->config.name);
+    netdata_info("EXPORTING: cleaning up instance %s ...", instance->config.name);
 
     struct pubsub_specific_data *connector_specific_data =
         (struct pubsub_specific_data *)instance->connector_specific_data;
@@ -80,7 +80,7 @@ void clean_pubsub_instance(struct instance *instance)
     freez(connector_specific_config->topic_id);
     freez(connector_specific_config);
 
-    info("EXPORTING: instance %s exited", instance->config.name);
+    netdata_info("EXPORTING: instance %s exited", instance->config.name);
     instance->exited = 1;
 
     return;
diff --git a/exporting/read_config.c b/exporting/read_config.c
index eab2cdf..6505b0a 100644
--- a/exporting/read_config.c
+++ b/exporting/read_config.c
@@ -211,13 +211,13 @@ struct engine *read_exporting_config()
 
     exporting_config_exists = appconfig_load(&exporting_config, filename, 0, NULL);
     if (!exporting_config_exists) {
-        info("CONFIG: cannot load user exporting config '%s'. Will try the stock version.", filename);
+        netdata_info("CONFIG: cannot load user exporting config '%s'. Will try the stock version.", filename);
         freez(filename);
 
         filename = strdupz_path_subpath(netdata_configured_stock_config_dir, EXPORTING_CONF);
         exporting_config_exists = appconfig_load(&exporting_config, filename, 0, NULL);
         if (!exporting_config_exists)
-            info("CONFIG: cannot load stock exporting config '%s'. Running with internal defaults.", filename);
+            netdata_info("CONFIG: cannot load stock exporting config '%s'. Running with internal defaults.", filename);
     }
 
     freez(filename);
@@ -276,10 +276,10 @@ struct engine *read_exporting_config()
     }
 
     while (get_connector_instance(&local_ci)) {
-        info("Processing connector instance (%s)", local_ci.instance_name);
+        netdata_info("Processing connector instance (%s)", local_ci.instance_name);
 
         if (exporter_get_boolean(local_ci.instance_name, "enabled", 0)) {
-            info(
+            netdata_info(
                 "Instance (%s) on connector (%s) is enabled and scheduled for activation",
                 local_ci.instance_name, local_ci.connector_name);
 
@@ -290,11 +290,11 @@ struct engine *read_exporting_config()
             tmp_ci_list_prev = tmp_ci_list;
             instances_to_activate++;
         } else
-            info("Instance (%s) on connector (%s) is not enabled", local_ci.instance_name, local_ci.connector_name);
+            netdata_info("Instance (%s) on connector (%s) is not enabled", local_ci.instance_name, local_ci.connector_name);
     }
 
     if (unlikely(!instances_to_activate)) {
-        info("No connector instances to activate");
+        netdata_info("No connector instances to activate");
         return NULL;
     }
 
@@ -313,7 +313,7 @@ struct engine *read_exporting_config()
         char *instance_name;
         char *default_destination = "localhost";
 
-        info("Instance %s on %s", tmp_ci_list->local_ci.instance_name, tmp_ci_list->local_ci.connector_name);
+        netdata_info("Instance %s on %s", tmp_ci_list->local_ci.instance_name, tmp_ci_list->local_ci.connector_name);
 
         if (tmp_ci_list->exporting_type == EXPORTING_CONNECTOR_TYPE_UNKNOWN) {
             error("Unknown exporting connector type");
@@ -381,7 +381,7 @@ struct engine *read_exporting_config()
         tmp_instance->config.options = exporting_parse_data_source(data_source, tmp_instance->config.options);
         if (EXPORTING_OPTIONS_DATA_SOURCE(tmp_instance->config.options) != EXPORTING_SOURCE_DATA_AS_COLLECTED &&
             tmp_instance->config.update_every % localhost->rrd_update_every)
-            info(
+            netdata_info(
                 "The update interval %d for instance %s is not a multiple of the database update interval %d. "
                 "Metric values will deviate at different points in time.",
                 tmp_instance->config.update_every, tmp_instance->config.name, localhost->rrd_update_every);
@@ -488,7 +488,7 @@ struct engine *read_exporting_config()
 #endif
 
 #ifdef NETDATA_INTERNAL_CHECKS
-        info(
+        netdata_info(
             "     Dest=[%s], upd=[%d], buffer=[%d] timeout=[%ld] options=[%u]",
             tmp_instance->config.destination,
             tmp_instance->config.update_every,
diff --git a/exporting/send_data.c b/exporting/send_data.c
index d91fc50..7177e2e 100644
--- a/exporting/send_data.c
+++ b/exporting/send_data.c
@@ -303,7 +303,7 @@ void simple_connector_worker(void *instance_p)
 
                     if(netdata_ssl_open(&connector_specific_data->ssl, netdata_ssl_exporting_ctx, sock)) {
                         if(netdata_ssl_connect(&connector_specific_data->ssl)) {
-                            info("Exporting established a SSL connection.");
+                            netdata_info("Exporting established a SSL connection.");
 
                             struct timeval tv;
                             tv.tv_sec = timeout.tv_sec / 4;
diff --git a/health/health.c b/health/health.c
index e04debb..073c946 100644
--- a/health/health.c
+++ b/health/health.c
@@ -257,7 +257,7 @@ static void health_silencers_init(void) {
                 if (copied == (length* sizeof(char))) {
                     str[length] = 0x00;
                     json_parse(str, NULL, health_silencers_json_read_callback);
-                    info("Parsed health silencers file %s", silencers_filename);
+                    netdata_info("Parsed health silencers file %s", silencers_filename);
                 } else {
                     error("Cannot read the data from health silencers file %s", silencers_filename);
                 }
@@ -272,7 +272,7 @@ static void health_silencers_init(void) {
         }
         fclose(fd);
     } else {
-        info("Cannot open the file %s, so Netdata will work with the default health configuration.",silencers_filename);
+        netdata_info("Cannot open the file %s, so Netdata will work with the default health configuration.",silencers_filename);
     }
 }
 
@@ -747,7 +747,7 @@ static void health_main_cleanup(void *ptr) {
 
     struct netdata_static_thread *static_thread = (struct netdata_static_thread *)ptr;
     static_thread->enabled = NETDATA_MAIN_THREAD_EXITING;
-    info("cleaning up...");
+    netdata_info("cleaning up...");
     static_thread->enabled = NETDATA_MAIN_THREAD_EXITED;
 
     log_health("Health thread ended.");
@@ -888,7 +888,7 @@ static int update_disabled_silenced(RRDHOST *host, RRDCALC *rc) {
     }
 
     if (rrdcalc_flags_old != rc->run_flags) {
-        info("Alarm silencing changed for host '%s' alarm '%s': Disabled %s->%s Silenced %s->%s",
+        netdata_info("Alarm silencing changed for host '%s' alarm '%s': Disabled %s->%s Silenced %s->%s",
              rrdhost_hostname(host),
              rrdcalc_name(rc),
              (rrdcalc_flags_old & RRDCALC_FLAG_DISABLED)?"true":"false",
diff --git a/httpd/http_server.c b/httpd/http_server.c
index 24b168d..774bf99 100644
--- a/httpd/http_server.c
+++ b/httpd/http_server.c
@@ -88,7 +88,7 @@ static int ssl_init()
 
     h2o_ssl_register_alpn_protocols(accept_ctx.ssl_ctx, h2o_http2_alpn_protocols);
 
-    info("SSL support enabled");
+    netdata_info("SSL support enabled");
 
     return 0;
 }
diff --git a/libnetdata/adaptive_resortable_list/adaptive_resortable_list.c b/libnetdata/adaptive_resortable_list/adaptive_resortable_list.c
index 6332fa1..d27a508 100644
--- a/libnetdata/adaptive_resortable_list/adaptive_resortable_list.c
+++ b/libnetdata/adaptive_resortable_list/adaptive_resortable_list.c
@@ -78,16 +78,16 @@ void arl_begin(ARL_BASE *base) {
         // do these checks after the ARL has been sorted
 
         if(unlikely(base->relinkings > (base->expected + base->allocated)))
-            info("ARL '%s' has %zu relinkings with %zu expected and %zu allocated entries. Is the source changing so fast?"
+            netdata_info("ARL '%s' has %zu relinkings with %zu expected and %zu allocated entries. Is the source changing so fast?"
                  , base->name, base->relinkings, base->expected, base->allocated);
 
         if(unlikely(base->slow > base->fast))
-            info("ARL '%s' has %zu fast searches and %zu slow searches. Is the source really changing so fast?"
+            netdata_info("ARL '%s' has %zu fast searches and %zu slow searches. Is the source really changing so fast?"
                  , base->name, base->fast, base->slow);
 
         /*
         if(unlikely(base->iteration % 60 == 0)) {
-            info("ARL '%s' statistics: iteration %zu, expected %zu, wanted %zu, allocated %zu, fred %zu, relinkings %zu, found %zu, added %zu, fast %zu, slow %zu"
+            netdata_info("ARL '%s' statistics: iteration %zu, expected %zu, wanted %zu, allocated %zu, fred %zu, relinkings %zu, found %zu, added %zu, fast %zu, slow %zu"
                  , base->name
                  , base->iteration
                  , base->expected
@@ -242,7 +242,7 @@ int arl_find_or_create_and_relink(ARL_BASE *base, const char *s, const char *val
 
 #ifdef NETDATA_INTERNAL_CHECKS
     if(unlikely(base->iteration % 60 == 0 && e->flags & ARL_ENTRY_FLAG_FOUND))
-        info("ARL '%s': entry '%s' is already found. Did you forget to call arl_begin()?", base->name, s);
+        netdata_info("ARL '%s': entry '%s' is already found. Did you forget to call arl_begin()?", base->name, s);
 #endif
 
     e->flags |= ARL_ENTRY_FLAG_FOUND;
diff --git a/libnetdata/aral/aral.c b/libnetdata/aral/aral.c
index 60fe5e3..d3d64ba 100644
--- a/libnetdata/aral/aral.c
+++ b/libnetdata/aral/aral.c
@@ -192,7 +192,7 @@ static void aral_delete_leftover_files(const char *name, const char *path, const
             continue;
 
         snprintfz(full_path, FILENAME_MAX, "%s/%s", path, de->d_name);
-        info("ARAL: '%s' removing left-over file '%s'", name, full_path);
+        netdata_info("ARAL: '%s' removing left-over file '%s'", name, full_path);
         if(unlikely(unlink(full_path) == -1))
             error("ARAL: '%s' cannot delete file '%s'", name, full_path);
     }
@@ -1056,7 +1056,7 @@ int aral_stress_test(size_t threads, size_t elements, size_t seconds) {
         __atomic_add_fetch(&auc.errors, 1, __ATOMIC_RELAXED);
     }
 
-    info("ARAL: did %zu malloc, %zu free, "
+    netdata_info("ARAL: did %zu malloc, %zu free, "
          "using %zu threads, in %llu usecs",
          auc.ar->aral_lock.user_malloc_operations,
          auc.ar->aral_lock.user_free_operations,
diff --git a/libnetdata/clocks/clocks.c b/libnetdata/clocks/clocks.c
index 19c66f0..9af2010 100644
--- a/libnetdata/clocks/clocks.c
+++ b/libnetdata/clocks/clocks.c
@@ -433,11 +433,11 @@ inline collected_number uptime_msec(char *filename){
 
         if(delta <= 1000 && uptime_boottime != 0) {
             procfile_close(read_proc_uptime_ff);
-            info("Using now_boottime_usec() for uptime (dt is %lld ms)", delta);
+            netdata_info("Using now_boottime_usec() for uptime (dt is %lld ms)", delta);
             use_boottime = 1;
         }
         else if(uptime_proc != 0) {
-            info("Using /proc/uptime for uptime (dt is %lld ms)", delta);
+            netdata_info("Using /proc/uptime for uptime (dt is %lld ms)", delta);
             use_boottime = 0;
         }
         else {
diff --git a/libnetdata/ebpf/ebpf.c b/libnetdata/ebpf/ebpf.c
index b980d09..c07ea4f 100644
--- a/libnetdata/ebpf/ebpf.c
+++ b/libnetdata/ebpf/ebpf.c
@@ -183,7 +183,7 @@ static int kernel_is_rejected()
         if (read_file("/proc/version", version_string, VERSION_STRING_LEN)) {
             struct utsname uname_buf;
             if (!uname(&uname_buf)) {
-                info("Cannot check kernel version");
+                netdata_info("Cannot check kernel version");
                 return 0;
             }
             version_string_len =
@@ -230,7 +230,7 @@ static int kernel_is_rejected()
     while ((reject_string_len = getline(&reject_string, &buf_len, kernel_reject_list) - 1) > 0) {
         if (version_string_len >= reject_string_len) {
             if (!strncmp(version_string, reject_string, reject_string_len)) {
-                info("A buggy kernel is detected");
+                netdata_info("A buggy kernel is detected");
                 fclose(kernel_reject_list);
                 freez(reject_string);
                 return 1;
@@ -496,7 +496,7 @@ void ebpf_update_kernel_memory(ebpf_plugin_stats_t *report, ebpf_local_maps_t *m
                     report->memlock_kern += memsize;
                     report->hash_tables += 1;
 #ifdef NETDATA_DEV_MODE
-                    info("Hash table %u: %s (FD = %d) is consuming %lu bytes totalizing %lu bytes",
+                    netdata_info("Hash table %u: %s (FD = %d) is consuming %lu bytes totalizing %lu bytes",
                          report->hash_tables, map->name, map->map_fd, memsize, report->memlock_kern);
 #endif
                     break;
@@ -505,7 +505,7 @@ void ebpf_update_kernel_memory(ebpf_plugin_stats_t *report, ebpf_local_maps_t *m
                     report->memlock_kern -= memsize;
                     report->hash_tables -= 1;
 #ifdef NETDATA_DEV_MODE
-                    info("Hash table %s (FD = %d) was removed releasing %lu bytes, now we have %u tables loaded totalizing %lu bytes.",
+                    netdata_info("Hash table %s (FD = %d) was removed releasing %lu bytes, now we have %u tables loaded totalizing %lu bytes.",
                          map->name, map->map_fd, memsize, report->hash_tables, report->memlock_kern);
 #endif
                     break;
@@ -570,7 +570,7 @@ void ebpf_update_map_size(struct bpf_map *map, ebpf_local_maps_t *lmap, ebpf_mod
     if (lmap->user_input && lmap->user_input != lmap->internal_input) {
         define_size = lmap->internal_input;
 #ifdef NETDATA_INTERNAL_CHECKS
-        info("Changing map %s from size %u to %u ", map_name, lmap->internal_input, lmap->user_input);
+        netdata_info("Changing map %s from size %u to %u ", map_name, lmap->internal_input, lmap->user_input);
 #endif
     } else if (((lmap->type & apps_type) == apps_type) && (!em->apps_charts) && (!em->cgroup_charts)) {
         lmap->user_input = ND_EBPF_DEFAULT_MIN_PID;
@@ -878,7 +878,7 @@ struct bpf_link **ebpf_load_program(char *plugins_dir, ebpf_module_t *em, int kv
     size_t count_programs =  ebpf_count_programs(*obj);
 
 #ifdef NETDATA_INTERNAL_CHECKS
-    info("eBPF program %s loaded with success!", lpath);
+    netdata_info("eBPF program %s loaded with success!", lpath);
 #endif
 
     return ebpf_attach_programs(*obj, count_programs, em->names);
@@ -1107,7 +1107,7 @@ struct btf *ebpf_load_btf_file(char *path, char *filename)
     snprintfz(fullpath, PATH_MAX, "%s/%s", path, filename);
     struct btf *ret = ebpf_parse_btf_file(fullpath);
     if (!ret)
-        info("Your environment does not have BTF file %s/%s. The plugin will work with 'legacy' code.",
+        netdata_info("Your environment does not have BTF file %s/%s. The plugin will work with 'legacy' code.",
              path, filename);
 
     return ret;
@@ -1259,7 +1259,7 @@ void ebpf_update_module_using_config(ebpf_module_t *modules, netdata_ebpf_load_m
         modules->maps_per_core = CONFIG_BOOLEAN_NO;
 
 #ifdef NETDATA_DEV_MODE
-    info("The thread %s was configured with: mode = %s; update every = %d; apps = %s; cgroup = %s; ebpf type format = %s; ebpf co-re tracing = %s; collect pid = %s; maps per core = %s",
+    netdata_info("The thread %s was configured with: mode = %s; update every = %d; apps = %s; cgroup = %s; ebpf type format = %s; ebpf co-re tracing = %s; collect pid = %s; maps per core = %s",
          modules->thread_name,
          load_mode,
          modules->update_every,
diff --git a/libnetdata/json/json.c b/libnetdata/json/json.c
index 532b677..c37138c 100644
--- a/libnetdata/json/json.c
+++ b/libnetdata/json/json.c
@@ -124,7 +124,7 @@ int json_callback_print(JSON_ENTRY *e)
             buffer_strcat(wb,"NULL");
             break;
     }
-    info("JSON: %s", buffer_tostring(wb));
+    netdata_info("JSON: %s", buffer_tostring(wb));
     buffer_free(wb);
     return 0;
 }
@@ -323,7 +323,7 @@ size_t json_walk_array(char *js, jsmntok_t *t, size_t nest, size_t start, JSON_E
     for(i = 0; i < size ; i++) {
         ne.pos = i;
         if (strlen(e->name) > JSON_NAME_LEN  - 24 || strlen(e->fullname) > JSON_FULLNAME_LEN -24) {
-            info("JSON: JSON walk_array ignoring element with name:%s fullname:%s",e->name, e->fullname);
+            netdata_info("JSON: JSON walk_array ignoring element with name:%s fullname:%s",e->name, e->fullname);
             continue;
         }
         snprintfz(ne.name, JSON_NAME_LEN, "%s[%lu]", e->name, i);
diff --git a/libnetdata/libnetdata.c b/libnetdata/libnetdata.c
index 19b861e..6d08daf 100644
--- a/libnetdata/libnetdata.c
+++ b/libnetdata/libnetdata.c
@@ -1177,7 +1177,7 @@ void *netdata_mmap(const char *filename, size_t size, int flags, int ksm, bool r
         if(fd != -1 && fd_for_mmap == -1) {
             if (lseek(fd, 0, SEEK_SET) == 0) {
                 if (read(fd, mem, size) != (ssize_t) size)
-                    info("Cannot read from file '%s'", filename);
+                    netdata_info("Cannot read from file '%s'", filename);
             }
             else info("Cannot seek to beginning of file '%s'.", filename);
         }
@@ -1321,14 +1321,14 @@ int recursively_delete_dir(const char *path, const char *reason) {
             continue;
         }
 
-        info("Deleting %s file '%s'", reason?reason:"", fullpath);
+        netdata_info("Deleting %s file '%s'", reason?reason:"", fullpath);
         if(unlikely(unlink(fullpath) == -1))
             error("Cannot delete %s file '%s'", reason?reason:"", fullpath);
         else
             ret++;
     }
 
-    info("Deleting empty directory '%s'", path);
+    netdata_info("Deleting empty directory '%s'", path);
     if(unlikely(rmdir(path) == -1))
         error("Cannot delete empty directory '%s'", path);
     else
@@ -1399,7 +1399,7 @@ int verify_netdata_host_prefix() {
         goto failed;
 
     if(netdata_configured_host_prefix && *netdata_configured_host_prefix)
-        info("Using host prefix directory '%s'", netdata_configured_host_prefix);
+        netdata_info("Using host prefix directory '%s'", netdata_configured_host_prefix);
 
     return 0;
 
@@ -1999,7 +1999,7 @@ void timing_action(TIMING_ACTION action, TIMING_STEP step) {
                 );
             }
 
-            info("TIMINGS REPORT:\n%sTIMINGS REPORT:                        total # %10zu, t %11.2f ms",
+            netdata_info("TIMINGS REPORT:\n%sTIMINGS REPORT:                        total # %10zu, t %11.2f ms",
                  buffer_tostring(wb), total_reqs, (double)total_usec / USEC_PER_MS);
 
             memcpy(timings2, timings3, sizeof(timings2));
diff --git a/libnetdata/log/log.h b/libnetdata/log/log.h
index 3d9f092..c6941bd 100644
--- a/libnetdata/log/log.h
+++ b/libnetdata/log/log.h
@@ -118,7 +118,7 @@ typedef struct error_with_limit {
 #define internal_fatal(args...) debug_dummy()
 #endif
 
-#define info(args...)    info_int(0, __FILE__, __FUNCTION__, __LINE__, ##args)
+#define netdata_info(args...)    info_int(0, __FILE__, __FUNCTION__, __LINE__, ##args)
 #define collector_info(args...)    info_int(1, __FILE__, __FUNCTION__, __LINE__, ##args)
 #define infoerr(args...) error_int(0, "INFO", __FILE__, __FUNCTION__, __LINE__, ##args)
 #define error(args...)   error_int(0, "ERROR", __FILE__, __FUNCTION__, __LINE__, ##args)
diff --git a/libnetdata/popen/popen.c b/libnetdata/popen/popen.c
index 783c74a..2198b0e 100644
--- a/libnetdata/popen/popen.c
+++ b/libnetdata/popen/popen.c
@@ -406,11 +406,11 @@ int netdata_pclose(FILE *fp_child_input, FILE *fp_child_output, pid_t pid) {
 
             case CLD_KILLED:
                 if(info.si_status == SIGTERM) {
-                    info("child pid %d killed by SIGTERM", info.si_pid);
+                    netdata_info("child pid %d killed by SIGTERM", info.si_pid);
                     return(0);
                 }
                 else if(info.si_status == SIGPIPE) {
-                    info("child pid %d killed by SIGPIPE.", info.si_pid);
+                    netdata_info("child pid %d killed by SIGPIPE.", info.si_pid);
                     return(0);
                 }
                 else {
diff --git a/libnetdata/socket/security.c b/libnetdata/socket/security.c
index abae71c..682861f 100644
--- a/libnetdata/socket/security.c
+++ b/libnetdata/socket/security.c
@@ -585,7 +585,7 @@ void netdata_ssl_initialize_ctx(int selector) {
             if(!netdata_ssl_web_server_ctx) {
                 struct stat statbuf;
                 if (stat(netdata_ssl_security_key, &statbuf) || stat(netdata_ssl_security_cert, &statbuf))
-                    info("To use encryption it is necessary to set \"ssl certificate\" and \"ssl key\" in [web] !\n");
+                    netdata_info("To use encryption it is necessary to set \"ssl certificate\" and \"ssl key\" in [web] !\n");
                 else {
                     netdata_ssl_web_server_ctx = netdata_ssl_create_server_ctx(
                             SSL_MODE_ENABLE_PARTIAL_WRITE |
@@ -705,13 +705,13 @@ int ssl_security_location_for_context(SSL_CTX *ctx, char *file, char *path) {
     int load_custom = 1, load_default = 1;
     if (file || path) {
         if(!SSL_CTX_load_verify_locations(ctx, file, path)) {
-            info("Netdata can not verify custom CAfile or CApath for parent's SSL certificate, so it will use the default OpenSSL configuration to validate certificates!");
+            netdata_info("Netdata can not verify custom CAfile or CApath for parent's SSL certificate, so it will use the default OpenSSL configuration to validate certificates!");
             load_custom = 0;
         }
     }
 
     if(!SSL_CTX_set_default_verify_paths(ctx)) {
-        info("Can not verify default OpenSSL configuration to validate certificates!");
+        netdata_info("Can not verify default OpenSSL configuration to validate certificates!");
         load_default = 0;
     }
 
diff --git a/libnetdata/socket/socket.c b/libnetdata/socket/socket.c
index 7f0b81f..4c2a844 100644
--- a/libnetdata/socket/socket.c
+++ b/libnetdata/socket/socket.c
@@ -660,7 +660,7 @@ int listen_sockets_setup(LISTEN_SOCKETS *sockets) {
     if(sockets->failed) {
         size_t i;
         for(i = 0; i < sockets->opened ;i++)
-            info("LISTENER: Listen socket %s opened successfully.", sockets->fds_names[i]);
+            netdata_info("LISTENER: Listen socket %s opened successfully.", sockets->fds_names[i]);
     }
 
     return (int)sockets->opened;
@@ -810,7 +810,7 @@ int connect_to_this_ip46(int protocol, int socktype, const char *host, uint32_t
             errno = 0;
             if(connect(fd, ai->ai_addr, ai->ai_addrlen) < 0) {
                 if(errno == EALREADY || errno == EINPROGRESS) {
-                    info("Waiting for connection to ip %s port %s to be established", hostBfr, servBfr);
+                    netdata_info("Waiting for connection to ip %s port %s to be established", hostBfr, servBfr);
 
                     fd_set fds;
                     FD_ZERO(&fds);
@@ -818,7 +818,7 @@ int connect_to_this_ip46(int protocol, int socktype, const char *host, uint32_t
                     int rc = select (1, NULL, &fds, NULL, timeout);
 
                     if(rc > 0 && FD_ISSET(fd, &fds)) {
-                        info("connect() to ip %s port %s completed successfully", hostBfr, servBfr);
+                        netdata_info("connect() to ip %s port %s completed successfully", hostBfr, servBfr);
                     }
                     else if(rc == -1) {
                         error("Failed to connect to '%s', port '%s'. select() returned %d", hostBfr, servBfr, rc);
@@ -1518,7 +1518,7 @@ int poll_default_rcv_callback(POLLINFO *pi, short int *events) {
             }
         } else if (rc) {
             // data received
-            info("POLLFD: internal error: poll_default_rcv_callback() is discarding %zd bytes received on socket %d", rc, pi->fd);
+            netdata_info("POLLFD: internal error: poll_default_rcv_callback() is discarding %zd bytes received on socket %d", rc, pi->fd);
         }
     } while (rc != -1);
 
@@ -1528,7 +1528,7 @@ int poll_default_rcv_callback(POLLINFO *pi, short int *events) {
 int poll_default_snd_callback(POLLINFO *pi, short int *events) {
     *events &= ~POLLOUT;
 
-    info("POLLFD: internal error: poll_default_snd_callback(): nothing to send on socket %d", pi->fd);
+    netdata_info("POLLFD: internal error: poll_default_snd_callback(): nothing to send on socket %d", pi->fd);
     return 0;
 }
 
@@ -1758,7 +1758,7 @@ void poll_events(LISTEN_SOCKETS *sockets
         );
 
         pi->data = data;
-        info("POLLFD: LISTENER: listening on '%s'", (sockets->fds_names[i])?sockets->fds_names[i]:"UNKNOWN");
+        netdata_info("POLLFD: LISTENER: listening on '%s'", (sockets->fds_names[i])?sockets->fds_names[i]:"UNKNOWN");
     }
 
     int listen_sockets_active = 1;
@@ -1799,7 +1799,7 @@ void poll_events(LISTEN_SOCKETS *sockets
         // enable or disable the TCP listening sockets, based on the current number of sockets used and the limit set
         if((listen_sockets_active && (p.limit && p.used >= p.limit)) || (!listen_sockets_active && (!p.limit || p.used < p.limit))) {
             listen_sockets_active = !listen_sockets_active;
-            info("%s listening sockets (used TCP sockets %zu, max allowed for this worker %zu)", (listen_sockets_active)?"ENABLING":"DISABLING", p.used, p.limit);
+            netdata_info("%s listening sockets (used TCP sockets %zu, max allowed for this worker %zu)", (listen_sockets_active)?"ENABLING":"DISABLING", p.used, p.limit);
             for (i = 0; i <= p.max; i++) {
                 if(p.inf[i].flags & POLLINFO_FLAG_SERVER_SOCKET && p.inf[i].socktype == SOCK_STREAM) {
                     p.fds[i].events = (short int) ((listen_sockets_active) ? POLLIN : 0);
@@ -1947,7 +1947,7 @@ void poll_events(LISTEN_SOCKETS *sockets
 
                 if(likely(pi->flags & POLLINFO_FLAG_CLIENT_SOCKET)) {
                     if (unlikely(pi->send_count == 0 && p.complete_request_timeout > 0 && (now - pi->connected_t) >= p.complete_request_timeout)) {
-                        info("POLLFD: LISTENER: client slot %zu (fd %d) from %s port %s has not sent a complete request in %zu seconds - closing it. "
+                        netdata_info("POLLFD: LISTENER: client slot %zu (fd %d) from %s port %s has not sent a complete request in %zu seconds - closing it. "
                               , i
                               , pi->fd
                               , pi->client_ip ? pi->client_ip : "<undefined-ip>"
@@ -1957,7 +1957,7 @@ void poll_events(LISTEN_SOCKETS *sockets
                         poll_close_fd(pi);
                     }
                     else if(unlikely(pi->recv_count && p.idle_timeout > 0 && now - ((pi->last_received_t > pi->last_sent_t) ? pi->last_received_t : pi->last_sent_t) >= p.idle_timeout )) {
-                        info("POLLFD: LISTENER: client slot %zu (fd %d) from %s port %s is idle for more than %zu seconds - closing it. "
+                        netdata_info("POLLFD: LISTENER: client slot %zu (fd %d) from %s port %s is idle for more than %zu seconds - closing it. "
                               , i
                               , pi->fd
                               , pi->client_ip ? pi->client_ip : "<undefined-ip>"
diff --git a/libnetdata/storage_number/storage_number.c b/libnetdata/storage_number/storage_number.c
index ebae71d..9305dad 100644
--- a/libnetdata/storage_number/storage_number.c
+++ b/libnetdata/storage_number/storage_number.c
@@ -52,7 +52,7 @@ bool is_system_ieee754_double(void) {
 
         if(*ptr != tests[i].i && (tests[i].original == tests[i].d || (isnan(tests[i].original) && isnan(tests[i].d)))) {
             if(!logged)
-                info("IEEE754: test #%zu, value " NETDATA_DOUBLE_FORMAT_G " is represented in this system as %lX, but it was expected as %lX",
+                netdata_info("IEEE754: test #%zu, value " NETDATA_DOUBLE_FORMAT_G " is represented in this system as %lX, but it was expected as %lX",
                      i+1, tests[i].original, *ptr, tests[i].i);
             errors++;
         }
@@ -60,14 +60,14 @@ bool is_system_ieee754_double(void) {
 
     if(!errors && sizeof(NETDATA_DOUBLE) == sizeof(uint64_t)) {
         if(!logged)
-            info("IEEE754: system is using IEEE754 DOUBLE PRECISION values");
+            netdata_info("IEEE754: system is using IEEE754 DOUBLE PRECISION values");
 
         logged = true;
         return true;
     }
     else {
         if(!logged)
-            info("IEEE754: system is NOT compatible with IEEE754 DOUBLE PRECISION values");
+            netdata_info("IEEE754: system is NOT compatible with IEEE754 DOUBLE PRECISION values");
 
         logged = true;
         return false;
diff --git a/libnetdata/threads/threads.c b/libnetdata/threads/threads.c
index a4591d5..187a93a 100644
--- a/libnetdata/threads/threads.c
+++ b/libnetdata/threads/threads.c
@@ -152,7 +152,7 @@ void netdata_threads_init_after_fork(size_t stacksize) {
         if(i != 0)
             error("pthread_attr_setstacksize() to %zu bytes, failed with code %d.", stacksize, i);
         else
-            info("Set threads stack size to %zu bytes", stacksize);
+            netdata_info("Set threads stack size to %zu bytes", stacksize);
     }
     else
         error("Invalid pthread stacksize %zu", stacksize);
@@ -173,7 +173,7 @@ static void thread_cleanup(void *ptr) {
     }
 
     if(!(netdata_thread->options & NETDATA_THREAD_OPTION_DONT_LOG_CLEANUP))
-        info("thread with task id %d finished", gettid());
+        netdata_info("thread with task id %d finished", gettid());
 
     sender_thread_buffer_free();
     rrdset_thread_rda_free();
@@ -207,7 +207,7 @@ static void thread_set_name_np(NETDATA_THREAD *nt) {
         if (ret != 0)
             error("cannot set pthread name of %d to %s. ErrCode: %d", gettid(), threadname, ret);
         else
-            info("set name of thread %d to %s", gettid(), threadname);
+            netdata_info("set name of thread %d to %s", gettid(), threadname);
 
     }
 }
@@ -230,7 +230,7 @@ void uv_thread_set_name_np(uv_thread_t ut, const char* name) {
     thread_name_get(true);
 
     if (ret)
-        info("cannot set libuv thread name to %s. Err: %d", threadname, ret);
+        netdata_info("cannot set libuv thread name to %s. Err: %d", threadname, ret);
 }
 
 void os_thread_get_current_name_np(char threadname[NETDATA_THREAD_NAME_MAX + 1])
@@ -247,7 +247,7 @@ static void *netdata_thread_init(void *ptr) {
     netdata_thread = (NETDATA_THREAD *)ptr;
 
     if(!(netdata_thread->options & NETDATA_THREAD_OPTION_DONT_LOG_STARTUP))
-        info("thread created with task id %d", gettid());
+        netdata_info("thread created with task id %d", gettid());
 
     if(pthread_setcanceltype(PTHREAD_CANCEL_DEFERRED, NULL) != 0)
         error("cannot set pthread cancel type to DEFERRED.");
diff --git a/registry/registry_init.c b/registry/registry_init.c
index ba4250e..53b1931 100644
--- a/registry/registry_init.c
+++ b/registry/registry_init.c
@@ -11,7 +11,7 @@ int registry_init(void) {
         registry.enabled = config_get_boolean(CONFIG_SECTION_REGISTRY, "enabled", 0);
     }
     else {
-        info("Registry is disabled - use the central netdata");
+        netdata_info("Registry is disabled - use the central netdata");
         config_set_boolean(CONFIG_SECTION_REGISTRY, "enabled", 0);
         registry.enabled = 0;
     }
diff --git a/registry/registry_internals.c b/registry/registry_internals.c
index fe4d2da..8e9ee63 100644
--- a/registry/registry_internals.c
+++ b/registry/registry_internals.c
@@ -13,7 +13,7 @@ struct registry registry;
 int regenerate_guid(const char *guid, char *result) {
     uuid_t uuid;
     if(unlikely(uuid_parse(guid, uuid) == -1)) {
-        info("Registry: GUID '%s' is not a valid GUID.", guid);
+        netdata_info("Registry: GUID '%s' is not a valid GUID.", guid);
         return -1;
     }
     else {
@@ -21,7 +21,7 @@ int regenerate_guid(const char *guid, char *result) {
 
 #ifdef NETDATA_INTERNAL_CHECKS
         if(strcmp(guid, result) != 0)
-            info("GUID '%s' and re-generated GUID '%s' differ!", guid, result);
+            netdata_info("GUID '%s' and re-generated GUID '%s' differ!", guid, result);
 #endif /* NETDATA_INTERNAL_CHECKS */
     }
 
@@ -84,7 +84,7 @@ REGISTRY_PERSON_URL *registry_verify_request(char *person_guid, char *machine_gu
     char pbuf[GUID_LEN + 1], mbuf[GUID_LEN + 1];
 
     if(!person_guid || !*person_guid || !machine_guid || !*machine_guid || !url || !*url) {
-        info("Registry Request Verification: invalid request! person: '%s', machine '%s', url '%s'", person_guid?person_guid:"UNSET", machine_guid?machine_guid:"UNSET", url?url:"UNSET");
+        netdata_info("Registry Request Verification: invalid request! person: '%s', machine '%s', url '%s'", person_guid?person_guid:"UNSET", machine_guid?machine_guid:"UNSET", url?url:"UNSET");
         return NULL;
     }
 
@@ -93,14 +93,14 @@ REGISTRY_PERSON_URL *registry_verify_request(char *person_guid, char *machine_gu
 
     // make sure the person GUID is valid
     if(regenerate_guid(person_guid, pbuf) == -1) {
-        info("Registry Request Verification: invalid person GUID, person: '%s', machine '%s', url '%s'", person_guid, machine_guid, url);
+        netdata_info("Registry Request Verification: invalid person GUID, person: '%s', machine '%s', url '%s'", person_guid, machine_guid, url);
         return NULL;
     }
     person_guid = pbuf;
 
     // make sure the machine GUID is valid
     if(regenerate_guid(machine_guid, mbuf) == -1) {
-        info("Registry Request Verification: invalid machine GUID, person: '%s', machine '%s', url '%s'", person_guid, machine_guid, url);
+        netdata_info("Registry Request Verification: invalid machine GUID, person: '%s', machine '%s', url '%s'", person_guid, machine_guid, url);
         return NULL;
     }
     machine_guid = mbuf;
@@ -108,7 +108,7 @@ REGISTRY_PERSON_URL *registry_verify_request(char *person_guid, char *machine_gu
     // make sure the machine exists
     REGISTRY_MACHINE *m = registry_machine_find(machine_guid);
     if(!m) {
-        info("Registry Request Verification: machine not found, person: '%s', machine '%s', url '%s'", person_guid, machine_guid, url);
+        netdata_info("Registry Request Verification: machine not found, person: '%s', machine '%s', url '%s'", person_guid, machine_guid, url);
         return NULL;
     }
     if(mm) *mm = m;
@@ -116,14 +116,14 @@ REGISTRY_PERSON_URL *registry_verify_request(char *person_guid, char *machine_gu
     // make sure the person exist
     REGISTRY_PERSON *p = registry_person_find(person_guid);
     if(!p) {
-        info("Registry Request Verification: person not found, person: '%s', machine '%s', url '%s'", person_guid, machine_guid, url);
+        netdata_info("Registry Request Verification: person not found, person: '%s', machine '%s', url '%s'", person_guid, machine_guid, url);
         return NULL;
     }
     if(pp) *pp = p;
 
     REGISTRY_PERSON_URL *pu = registry_person_url_index_find(p, url);
     if(!pu) {
-        info("Registry Request Verification: URL not found for person, person: '%s', machine '%s', url '%s'", person_guid, machine_guid, url);
+        netdata_info("Registry Request Verification: URL not found for person, person: '%s', machine '%s', url '%s'", person_guid, machine_guid, url);
         return NULL;
     }
     //else if (pu->machine != m) {
@@ -178,7 +178,7 @@ REGISTRY_PERSON *registry_request_delete(char *person_guid, char *machine_guid,
     // make sure the user is not deleting the url it uses
     /*
     if(!strcmp(delete_url, pu->url->url)) {
-        info("Registry Delete Request: delete URL is the one currently accessed, person: '%s', machine '%s', url '%s', delete url '%s'"
+        netdata_info("Registry Delete Request: delete URL is the one currently accessed, person: '%s', machine '%s', url '%s', delete url '%s'"
              , p->guid, m->guid, pu->url->url, delete_url);
         return NULL;
     }
@@ -186,7 +186,7 @@ REGISTRY_PERSON *registry_request_delete(char *person_guid, char *machine_guid,
 
     REGISTRY_PERSON_URL *dpu = registry_person_url_index_find(p, delete_url);
     if(!dpu) {
-        info("Registry Delete Request: URL not found for person: '%s', machine '%s', url '%s', delete url '%s'", p->guid
+        netdata_info("Registry Delete Request: URL not found for person: '%s', machine '%s', url '%s', delete url '%s'", p->guid
              , m->guid, pu->url->url, delete_url);
         return NULL;
     }
@@ -230,7 +230,7 @@ REGISTRY_MACHINE *registry_request_machine(char *person_guid, char *machine_guid
 
     // make sure the machine GUID is valid
     if(regenerate_guid(request_machine, mbuf) == -1) {
-        info("Registry Machine URLs request: invalid machine GUID, person: '%s', machine '%s', url '%s', request machine '%s'", p->guid, m->guid, pu->url->url, request_machine);
+        netdata_info("Registry Machine URLs request: invalid machine GUID, person: '%s', machine '%s', url '%s', request machine '%s'", p->guid, m->guid, pu->url->url, request_machine);
         return NULL;
     }
     request_machine = mbuf;
@@ -238,7 +238,7 @@ REGISTRY_MACHINE *registry_request_machine(char *person_guid, char *machine_guid
     // make sure the machine exists
     m = registry_machine_find(request_machine);
     if(!m) {
-        info("Registry Machine URLs request: machine not found, person: '%s', machine '%s', url '%s', request machine '%s'", p->guid, machine_guid, pu->url->url, request_machine);
+        netdata_info("Registry Machine URLs request: machine not found, person: '%s', machine '%s', url '%s', request machine '%s'", p->guid, machine_guid, pu->url->url, request_machine);
         return NULL;
     }
 
diff --git a/registry/registry_machine.c b/registry/registry_machine.c
index 414cd16..8ccae18 100644
--- a/registry/registry_machine.c
+++ b/registry/registry_machine.c
@@ -67,7 +67,7 @@ REGISTRY_MACHINE *registry_machine_get(const char *machine_guid, time_t when) {
         // validate it is a GUID
         char buf[GUID_LEN + 1];
         if(unlikely(regenerate_guid(machine_guid, buf) == -1))
-            info("Registry: machine guid '%s' is not a valid guid. Ignoring it.", machine_guid);
+            netdata_info("Registry: machine guid '%s' is not a valid guid. Ignoring it.", machine_guid);
         else {
             machine_guid = buf;
             m = registry_machine_find(machine_guid);
diff --git a/registry/registry_person.c b/registry/registry_person.c
index 2f55e99..01d8229 100644
--- a/registry/registry_person.c
+++ b/registry/registry_person.c
@@ -153,7 +153,7 @@ REGISTRY_PERSON *registry_person_allocate(const char *person_guid, time_t when)
                 break;
             }
             else
-                info("Registry: generated person guid '%s' found in the registry. Retrying...", p->guid);
+                netdata_info("Registry: generated person guid '%s' found in the registry. Retrying...", p->guid);
         }
     }
     else
@@ -187,7 +187,7 @@ REGISTRY_PERSON *registry_person_get(const char *person_guid, time_t when) {
         char buf[GUID_LEN + 1];
         // validate it is a GUID
         if(unlikely(regenerate_guid(person_guid, buf) == -1))
-            info("Registry: person guid '%s' is not a valid guid. Ignoring it.", person_guid);
+            netdata_info("Registry: person guid '%s' is not a valid guid. Ignoring it.", person_guid);
         else {
             person_guid = buf;
             p = registry_person_find(person_guid);
diff --git a/spawn/spawn.c b/spawn/spawn.c
index f326f88..c59e6eb 100644
--- a/spawn/spawn.c
+++ b/spawn/spawn.c
@@ -235,7 +235,7 @@ void spawn_init(void)
     struct completion completion;
     int error;
 
-    info("Initializing spawn client.");
+    netdata_info("Initializing spawn client.");
 
     init_spawn_cmd_queue();
 
@@ -268,15 +268,15 @@ void spawn_init(void)
             char cmd[64];
             sprintf(cmd, "echo CONCURRENT_STRESS_TEST %d 1>&2", j * CONCURRENT_SPAWNS + i + 1);
             serial[i] = spawn_enq_cmd(cmd);
-            info("Queued command %s for spawning.", cmd);
+            netdata_info("Queued command %s for spawning.", cmd);
         }
         int exit_status;
         time_t exec_run_timestamp;
         for (int i = 0; i < CONCURRENT_SPAWNS; ++i) {
-            info("Started waiting for serial %llu exit status %d run timestamp %llu.", serial[i], exit_status,
+            netdata_info("Started waiting for serial %llu exit status %d run timestamp %llu.", serial[i], exit_status,
                  exec_run_timestamp);
             spawn_wait_cmd(serial[i], &exit_status, &exec_run_timestamp);
-            info("Finished waiting for serial %llu exit status %d run timestamp %llu.", serial[i], exit_status,
+            netdata_info("Finished waiting for serial %llu exit status %d run timestamp %llu.", serial[i], exit_status,
                  exec_run_timestamp);
         }
     }
diff --git a/spawn/spawn_client.c b/spawn/spawn_client.c
index 3e37e79..83450b7 100644
--- a/spawn/spawn_client.c
+++ b/spawn/spawn_client.c
@@ -19,7 +19,7 @@ static void after_pipe_write(uv_write_t* req, int status)
 {
     (void)status;
 #ifdef SPAWN_DEBUG
-    info("CLIENT %s called status=%d", __func__, status);
+    netdata_info("CLIENT %s called status=%d", __func__, status);
 #endif
     void **data = req->data;
     freez(data[0]);
@@ -59,7 +59,7 @@ static void client_parse_spawn_protocol(unsigned source_len, char *source)
             cmdinfo->pid = spawn_result->exec_pid;
             if (0 == cmdinfo->pid) { /* Failed to spawn */
 #ifdef SPAWN_DEBUG
-                info("CLIENT %s SPAWN_PROT_SPAWN_RESULT failed to spawn.", __func__);
+                netdata_info("CLIENT %s SPAWN_PROT_SPAWN_RESULT failed to spawn.", __func__);
 #endif
                 cmdinfo->flags |= SPAWN_CMD_FAILED_TO_SPAWN | SPAWN_CMD_DONE;
                 uv_cond_signal(&cmdinfo->cond);
@@ -67,7 +67,7 @@ static void client_parse_spawn_protocol(unsigned source_len, char *source)
                 cmdinfo->exec_run_timestamp = spawn_result->exec_run_timestamp;
                 cmdinfo->flags |= SPAWN_CMD_IN_PROGRESS;
 #ifdef SPAWN_DEBUG
-                info("CLIENT %s SPAWN_PROT_SPAWN_RESULT in progress.", __func__);
+                netdata_info("CLIENT %s SPAWN_PROT_SPAWN_RESULT in progress.", __func__);
 #endif
             }
             uv_mutex_unlock(&cmdinfo->mutex);
@@ -84,7 +84,7 @@ static void client_parse_spawn_protocol(unsigned source_len, char *source)
             uv_mutex_lock(&cmdinfo->mutex);
             cmdinfo->exit_status = exit_status->exec_exit_status;
 #ifdef SPAWN_DEBUG
-            info("CLIENT %s SPAWN_PROT_CMD_EXIT_STATUS %d.", __func__, exit_status->exec_exit_status);
+            netdata_info("CLIENT %s SPAWN_PROT_CMD_EXIT_STATUS %d.", __func__, exit_status->exec_exit_status);
 #endif
             cmdinfo->flags |= SPAWN_CMD_DONE;
             uv_cond_signal(&cmdinfo->cond);
@@ -102,9 +102,9 @@ static void client_parse_spawn_protocol(unsigned source_len, char *source)
 static void on_pipe_read(uv_stream_t* pipe, ssize_t nread, const uv_buf_t* buf)
 {
     if (0 == nread) {
-        info("%s: Zero bytes read from spawn pipe.", __func__);
+        netdata_info("%s: Zero bytes read from spawn pipe.", __func__);
     } else if (UV_EOF == nread) {
-        info("EOF found in spawn pipe.");
+        netdata_info("EOF found in spawn pipe.");
     } else if (nread < 0) {
         error("%s: %s", __func__, uv_strerror(nread));
     }
@@ -113,7 +113,7 @@ static void on_pipe_read(uv_stream_t* pipe, ssize_t nread, const uv_buf_t* buf)
         (void)uv_read_stop((uv_stream_t *)pipe);
     } else if (nread) {
 #ifdef SPAWN_DEBUG
-        info("CLIENT %s read %u", __func__, (unsigned)nread);
+        netdata_info("CLIENT %s read %u", __func__, (unsigned)nread);
 #endif
         client_parse_spawn_protocol(nread, buf->base);
     }
@@ -162,7 +162,7 @@ static void spawn_process_cmd(struct spawn_cmd_info *cmdinfo)
     writebuf[2] = uv_buf_init((char *)cmdinfo->command_to_run, write_ctx->payload.command_length);
 
 #ifdef SPAWN_DEBUG
-    info("CLIENT %s SPAWN_PROT_EXEC_CMD %u", __func__, (unsigned)cmdinfo->serial);
+    netdata_info("CLIENT %s SPAWN_PROT_EXEC_CMD %u", __func__, (unsigned)cmdinfo->serial);
 #endif
     ret = uv_write(&write_ctx->write_req, (uv_stream_t *)&spawn_channel, writebuf, 3, after_pipe_write);
     fatal_assert(ret == 0);
@@ -223,12 +223,12 @@ void spawn_client(void *arg)
         }
     }
     /* cleanup operations of the event loop */
-    info("Shutting down spawn client event loop.");
+    netdata_info("Shutting down spawn client event loop.");
     uv_close((uv_handle_t *)&spawn_channel, NULL);
     uv_close((uv_handle_t *)&spawn_async, NULL);
     uv_run(loop, UV_RUN_DEFAULT); /* flush all libuv handles */
 
-    info("Shutting down spawn client loop complete.");
+    netdata_info("Shutting down spawn client loop complete.");
     fatal_assert(0 == uv_loop_close(loop));
 
     return;
diff --git a/streaming/receiver.c b/streaming/receiver.c
index 709f15b..704e530 100644
--- a/streaming/receiver.c
+++ b/streaming/receiver.c
@@ -619,7 +619,7 @@ void rrdpush_receive_log_status(struct receiver_state *rpt, const char *msg, con
                           (rpt->hostname && *rpt->hostname) ? rpt->hostname : "-",
                           status);
 
-    info("STREAM '%s' [receive from [%s]:%s]: "
+    netdata_info("STREAM '%s' [receive from [%s]:%s]: "
           "%s. "
           "STATUS: %s%s%s%s"
           , rpt->hostname
@@ -763,7 +763,7 @@ static void rrdpush_receive(struct receiver_state *rpt)
     }
 
 #ifdef NETDATA_INTERNAL_CHECKS
-    info("STREAM '%s' [receive from [%s]:%s]: "
+    netdata_info("STREAM '%s' [receive from [%s]:%s]: "
          "client willing to stream metrics for host '%s' with machine_guid '%s': "
          "update every = %d, history = %ld, memory mode = %s, health %s,%s tags '%s'"
          , rpt->hostname
@@ -914,7 +914,7 @@ static void rrdpush_receiver_thread_cleanup(void *ptr) {
 
     rrdhost_clear_receiver(rpt);
 
-    info("STREAM '%s' [receive from [%s]:%s]: "
+    netdata_info("STREAM '%s' [receive from [%s]:%s]: "
          "receive thread ended (task id %d)"
     , rpt->hostname ? rpt->hostname : "-"
     , rpt->client_ip ? rpt->client_ip : "-", rpt->client_port ? rpt->client_port : "-"
@@ -933,7 +933,7 @@ void *rrdpush_receiver_thread(void *ptr) {
 
     struct receiver_state *rpt = (struct receiver_state *)ptr;
     rpt->tid = gettid();
-    info("STREAM %s [%s]:%s: receive thread created (task id %d)", rpt->hostname, rpt->client_ip, rpt->client_port, rpt->tid);
+    netdata_info("STREAM %s [%s]:%s: receive thread created (task id %d)", rpt->hostname, rpt->client_ip, rpt->client_port, rpt->tid);
 
     rrdpush_receive(rpt);
 
diff --git a/streaming/replication.c b/streaming/replication.c
index c6fafc3..1435b48 100644
--- a/streaming/replication.c
+++ b/streaming/replication.c
@@ -1606,7 +1606,7 @@ static void verify_all_hosts_charts_are_streaming_now(void) {
     dfe_done(host);
 
     size_t executed = __atomic_load_n(&replication_globals.atomic.executed, __ATOMIC_RELAXED);
-    info("REPLICATION SUMMARY: finished, executed %zu replication requests, %zu charts pending replication",
+    netdata_info("REPLICATION SUMMARY: finished, executed %zu replication requests, %zu charts pending replication",
          executed - replication_globals.main_thread.last_executed, errors);
     replication_globals.main_thread.last_executed = executed;
 }
diff --git a/streaming/rrdpush.c b/streaming/rrdpush.c
index c481871..d4bbfa9 100644
--- a/streaming/rrdpush.c
+++ b/streaming/rrdpush.c
@@ -57,12 +57,12 @@ static void load_stream_conf() {
     errno = 0;
     char *filename = strdupz_path_subpath(netdata_configured_user_config_dir, "stream.conf");
     if(!appconfig_load(&stream_config, filename, 0, NULL)) {
-        info("CONFIG: cannot load user config '%s'. Will try stock config.", filename);
+        netdata_info("CONFIG: cannot load user config '%s'. Will try stock config.", filename);
         freez(filename);
 
         filename = strdupz_path_subpath(netdata_configured_stock_config_dir, "stream.conf");
         if(!appconfig_load(&stream_config, filename, 0, NULL))
-            info("CONFIG: cannot load stock config '%s'. Running with internal defaults.", filename);
+            netdata_info("CONFIG: cannot load stock config '%s'. Running with internal defaults.", filename);
     }
     freez(filename);
 }
@@ -139,7 +139,7 @@ int rrdpush_init() {
     netdata_ssl_validate_certificate_sender = !appconfig_get_boolean(&stream_config, CONFIG_SECTION_STREAM, "ssl skip certificate verification", !netdata_ssl_validate_certificate);
 
     if(!netdata_ssl_validate_certificate_sender)
-        info("SSL: streaming senders will skip SSL certificates verification.");
+        netdata_info("SSL: streaming senders will skip SSL certificates verification.");
 
     netdata_ssl_ca_path = appconfig_get(&stream_config, CONFIG_SECTION_STREAM, "CApath", NULL);
     netdata_ssl_ca_file = appconfig_get(&stream_config, CONFIG_SECTION_STREAM, "CAfile", NULL);
@@ -468,7 +468,7 @@ RRDSET_STREAM_BUFFER rrdset_push_metric_initialize(RRDSET *st, time_t wall_clock
         return (RRDSET_STREAM_BUFFER) { .wb = NULL, };
     }
     else if(unlikely(host_flags & RRDHOST_FLAG_RRDPUSH_SENDER_LOGGED_STATUS)) {
-        info("STREAM %s [send]: sending metrics to parent...", rrdhost_hostname(host));
+        netdata_info("STREAM %s [send]: sending metrics to parent...", rrdhost_hostname(host));
         rrdhost_flag_clear(host, RRDHOST_FLAG_RRDPUSH_SENDER_LOGGED_STATUS);
     }
 
@@ -555,7 +555,7 @@ int connect_to_one_of_destinations(
         if(d->postpone_reconnection_until > now)
             continue;
 
-        info(
+        netdata_info(
             "STREAM %s: connecting to '%s' (default port: %d)...",
             rrdhost_hostname(host),
             string2str(d->destination),
@@ -611,7 +611,7 @@ bool destinations_init_add_one(char *entry, void *data) {
     DOUBLE_LINKED_LIST_APPEND_ITEM_UNSAFE(t->list, d, prev, next);
 
     t->count++;
-    info("STREAM: added streaming destination No %d: '%s' to host '%s'", t->count, string2str(d->destination), rrdhost_hostname(t->host));
+    netdata_info("STREAM: added streaming destination No %d: '%s' to host '%s'", t->count, string2str(d->destination), rrdhost_hostname(t->host));
 
     return false; // we return false, so that we will get all defined destinations
 }
@@ -849,7 +849,7 @@ int rrdpush_receiver_thread_spawn(struct web_client *w, char *decoded_query_stri
                 rpt->capabilities = convert_stream_version_to_capabilities(1);
 
             if (unlikely(rrdhost_set_system_info_variable(rpt->system_info, name, value))) {
-                info("STREAM '%s' [receive from [%s]:%s]: "
+                netdata_info("STREAM '%s' [receive from [%s]:%s]: "
                      "request has parameter '%s' = '%s', which is not used."
                      , (rpt->hostname && *rpt->hostname) ? rpt->hostname : "-"
                      , rpt->client_ip, rpt->client_port
@@ -1122,7 +1122,7 @@ int rrdpush_receiver_thread_spawn(struct web_client *w, char *decoded_query_stri
             // we can proceed with this connection
             receiver_stale = false;
 
-            info("STREAM '%s' [receive from [%s]:%s]: "
+            netdata_info("STREAM '%s' [receive from [%s]:%s]: "
                  "stopped previous stale receiver to accept this one."
                  , rpt->hostname
                  , rpt->client_ip, rpt->client_port
@@ -1259,7 +1259,7 @@ void log_receiver_capabilities(struct receiver_state *rpt) {
     BUFFER *wb = buffer_create(100, NULL);
     stream_capabilities_to_string(wb, rpt->capabilities);
 
-    info("STREAM %s [receive from [%s]:%s]: established link with negotiated capabilities: %s",
+    netdata_info("STREAM %s [receive from [%s]:%s]: established link with negotiated capabilities: %s",
          rrdhost_hostname(rpt->host), rpt->client_ip, rpt->client_port, buffer_tostring(wb));
 
     buffer_free(wb);
@@ -1269,7 +1269,7 @@ void log_sender_capabilities(struct sender_state *s) {
     BUFFER *wb = buffer_create(100, NULL);
     stream_capabilities_to_string(wb, s->capabilities);
 
-    info("STREAM %s [send to %s]: established link with negotiated capabilities: %s",
+    netdata_info("STREAM %s [send to %s]: established link with negotiated capabilities: %s",
          rrdhost_hostname(s->host), s->connected_to, buffer_tostring(wb));
 
     buffer_free(wb);
diff --git a/streaming/sender.c b/streaming/sender.c
index 6e58d9a..6fae768 100644
--- a/streaming/sender.c
+++ b/streaming/sender.c
@@ -111,7 +111,7 @@ void sender_commit(struct sender_state *s, BUFFER *wb, STREAM_TRAFFIC_TYPE type)
 //    fclose(fp);
 
     if(unlikely(s->buffer->max_size < (src_len + 1) * SENDER_BUFFER_ADAPT_TO_TIMES_MAX_SIZE)) {
-        info("STREAM %s [send to %s]: max buffer size of %zu is too small for a data message of size %zu. Increasing the max buffer size to %d times the max data message size.",
+        netdata_info("STREAM %s [send to %s]: max buffer size of %zu is too small for a data message of size %zu. Increasing the max buffer size to %d times the max data message size.",
               rrdhost_hostname(s->host), s->connected_to, s->buffer->max_size, buffer_strlen(wb) + 1, SENDER_BUFFER_ADAPT_TO_TIMES_MAX_SIZE);
 
         s->buffer->max_size = (src_len + 1) * SENDER_BUFFER_ADAPT_TO_TIMES_MAX_SIZE;
@@ -1280,7 +1280,7 @@ static void rrdpush_sender_thread_cleanup_callback(void *ptr) {
     RRDHOST *host = s->host;
 
     netdata_mutex_lock(&host->sender->mutex);
-    info("STREAM %s [send]: sending thread exits %s",
+    netdata_info("STREAM %s [send]: sending thread exits %s",
          rrdhost_hostname(host),
          host->sender->exit.reason ? host->sender->exit.reason : "");
 
@@ -1366,7 +1366,7 @@ void *rrdpush_sender_thread(void *ptr) {
 
     rrdpush_initialize_ssl_ctx(s->host);
 
-    info("STREAM %s [send]: thread created (task id %d)", rrdhost_hostname(s->host), gettid());
+    netdata_info("STREAM %s [send]: thread created (task id %d)", rrdhost_hostname(s->host), gettid());
 
     s->timeout = (int)appconfig_get_number(
         &stream_config, CONFIG_SECTION_STREAM, "timeout seconds", 600);
@@ -1438,7 +1438,7 @@ void *rrdpush_sender_thread(void *ptr) {
             s->replication.oldest_request_after_t = 0;
 
             rrdhost_flag_set(s->host, RRDHOST_FLAG_RRDPUSH_SENDER_READY_4_METRICS);
-            info("STREAM %s [send to %s]: enabling metrics streaming...", rrdhost_hostname(s->host), s->connected_to);
+            netdata_info("STREAM %s [send to %s]: enabling metrics streaming...", rrdhost_hostname(s->host), s->connected_to);
 
             continue;
         }
diff --git a/web/api/health/health_cmdapi.c b/web/api/health/health_cmdapi.c
index 7c4869b..ac1729e 100644
--- a/web/api/health/health_cmdapi.c
+++ b/web/api/health/health_cmdapi.c
@@ -96,7 +96,7 @@ void health_silencers2file(BUFFER *wb) {
     if(fd) {
         size_t written = (size_t)fprintf(fd, "%s", wb->buffer) ;
         if (written == wb->len ) {
-            info("Silencer changes written to %s", silencers_filename);
+            netdata_info("Silencer changes written to %s", silencers_filename);
         }
         fclose(fd);
         return;
diff --git a/web/api/queries/query.c b/web/api/queries/query.c
index a0347f6..9ba7a25 100644
--- a/web/api/queries/query.c
+++ b/web/api/queries/query.c
@@ -2158,7 +2158,7 @@ bool rrdr_relative_window_to_absolute(time_t *after, time_t *before, time_t *now
 #define query_debug_log_init() BUFFER *debug_log = buffer_create(1000)
 #define query_debug_log(args...) buffer_sprintf(debug_log, ##args)
 #define query_debug_log_fin() { \
-        info("QUERY: '%s', after:%ld, before:%ld, duration:%ld, points:%zu, res:%ld - wanted => after:%ld, before:%ld, points:%zu, group:%zu, granularity:%ld, resgroup:%ld, resdiv:" NETDATA_DOUBLE_FORMAT_AUTO " %s", qt->id, after_requested, before_requested, before_requested - after_requested, points_requested, resampling_time_requested, after_wanted, before_wanted, points_wanted, group, query_granularity, resampling_group, resampling_divisor, buffer_tostring(debug_log)); \
+        netdata_info("QUERY: '%s', after:%ld, before:%ld, duration:%ld, points:%zu, res:%ld - wanted => after:%ld, before:%ld, points:%zu, group:%zu, granularity:%ld, resgroup:%ld, resdiv:" NETDATA_DOUBLE_FORMAT_AUTO " %s", qt->id, after_requested, before_requested, before_requested - after_requested, points_requested, resampling_time_requested, after_wanted, before_wanted, points_wanted, group, query_granularity, resampling_group, resampling_divisor, buffer_tostring(debug_log)); \
         buffer_free(debug_log); \
         debug_log = NULL; \
     }
diff --git a/web/api/queries/weights.c b/web/api/queries/weights.c
index 0830a96..17e5f35 100644
--- a/web/api/queries/weights.c
+++ b/web/api/queries/weights.c
@@ -1447,7 +1447,7 @@ static void rrdset_metric_correlations_volume(
     merge_query_value_to_stats(&highlight_countif, stats, 1);
 
     if(!netdata_double_isnumber(highlight_countif.value)) {
-        info("WEIGHTS: highlighted countif query failed, but highlighted average worked - strange...");
+        netdata_info("WEIGHTS: highlighted countif query failed, but highlighted average worked - strange...");
         return;
     }
 
diff --git a/web/api/tests/valid_urls.c b/web/api/tests/valid_urls.c
index 8a2a87f..9d7eea8 100644
--- a/web/api/tests/valid_urls.c
+++ b/web/api/tests/valid_urls.c
@@ -46,7 +46,7 @@ void repr(char *result, int result_size, char const *buf, int size)
 
 ssize_t send(int sockfd, const void *buf, size_t len, int flags)
 {
-    info("Mocking send: %zu bytes\n", len);
+    netdata_info("Mocking send: %zu bytes\n", len);
     (void)sockfd;
     (void)buf;
     (void)flags;
diff --git a/web/api/tests/web_api.c b/web/api/tests/web_api.c
index 93e6454..f3da27c 100644
--- a/web/api/tests/web_api.c
+++ b/web/api/tests/web_api.c
@@ -46,7 +46,7 @@ void repr(char *result, int result_size, char const *buf, int size)
 
 ssize_t send(int sockfd, const void *buf, size_t len, int flags)
 {
-    info("Mocking send: %zu bytes\n", len);
+    netdata_info("Mocking send: %zu bytes\n", len);
     (void)sockfd;
     (void)buf;
     (void)flags;
@@ -85,7 +85,7 @@ int __wrap_web_client_api_request_v1(RRDHOST *host, struct web_client *w, char *
 {
     char url_repr[160];
     repr(url_repr, sizeof(url_repr), url, strlen(url));
-    info("web_client_api_request_v1(url=\"%s\")\n", url_repr);
+    netdata_info("web_client_api_request_v1(url=\"%s\")\n", url_repr);
     check_expected_ptr(host);
     check_expected_ptr(w);
     check_expected_ptr(url_repr);
@@ -302,7 +302,7 @@ static void api_info(void **state)
 
     char buffer_repr[1024];
     repr(buffer_repr, sizeof(buffer_repr), def->instance->response.data->buffer,def->prefix_len);
-    info("Buffer contains: %s [first %zu]", buffer_repr,def->prefix_len);
+    netdata_info("Buffer contains: %s [first %zu]", buffer_repr,def->prefix_len);
     if (def->prefix_len == def->full_len) {
         expect_value(__wrap_web_client_api_request_v1, host, localhost);
         expect_value(__wrap_web_client_api_request_v1, w, def->instance);
diff --git a/web/api/web_api_v1.c b/web/api/web_api_v1.c
index 6373296..366de2a 100644
--- a/web/api/web_api_v1.c
+++ b/web/api/web_api_v1.c
@@ -166,7 +166,7 @@ char *get_mgmt_api_key(void) {
     return guid;
 
 temp_key:
-    info("You can still continue to use the alarm management API using the authorization token %s during this Netdata session only.", guid);
+    netdata_info("You can still continue to use the alarm management API using the authorization token %s during this Netdata session only.", guid);
     return guid;
 }
 
diff --git a/web/rtc/webrtc.c b/web/rtc/webrtc.c
index ba16865..e6699e7 100644
--- a/web/rtc/webrtc.c
+++ b/web/rtc/webrtc.c
@@ -25,7 +25,7 @@ static void webrtc_log(rtcLogLevel level, const char *message) {
             break;
 
         case RTC_LOG_INFO:
-            info("WEBRTC: %s", message);
+            netdata_info("WEBRTC: %s", message);
             break;
 
         default:
diff --git a/web/server/static/static-threaded.c b/web/server/static/static-threaded.c
index 4cb3dcd..acd6d65 100644
--- a/web/server/static/static-threaded.c
+++ b/web/server/static/static-threaded.c
@@ -394,7 +394,7 @@ cleanup:
 static void socket_listen_main_static_threaded_worker_cleanup(void *ptr) {
     worker_private = (struct web_server_static_threaded_worker *)ptr;
 
-    info("stopped after %zu connects, %zu disconnects (max concurrent %zu), %zu receptions and %zu sends",
+    netdata_info("stopped after %zu connects, %zu disconnects (max concurrent %zu), %zu receptions and %zu sends",
             worker_private->connected,
             worker_private->disconnected,
             worker_private->max_concurrent,
@@ -485,10 +485,10 @@ static void socket_listen_main_static_threaded_cleanup(void *ptr) {
 //    if(found)
 //        error("%d static web threads are taking too long to finish. Giving up.", found);
 
-    info("closing all web server sockets...");
+    netdata_info("closing all web server sockets...");
     listen_sockets_close(&api_sockets);
 
-    info("all static web threads stopped.");
+    netdata_info("all static web threads stopped.");
     static_thread->enabled = NETDATA_MAIN_THREAD_EXITED;
 }
 
@@ -502,7 +502,7 @@ void *socket_listen_main_static_threaded(void *ptr) {
     netdata_ssl_validate_certificate = !config_get_boolean(CONFIG_SECTION_WEB, "ssl skip certificate verification", !netdata_ssl_validate_certificate);
 
     if(!netdata_ssl_validate_certificate_sender)
-        info("SSL: web server will skip SSL certificates verification.");
+        netdata_info("SSL: web server will skip SSL certificates verification.");
 
 #ifdef ENABLE_HTTPS
     netdata_ssl_initialize_ctx(NETDATA_SSL_WEB_SERVER_CTX);
@@ -514,7 +514,7 @@ void *socket_listen_main_static_threaded(void *ptr) {
     int def_thread_count = MIN(get_netdata_cpus(), 6);
 
     if (!strcmp(config_get(CONFIG_SECTION_WEB, "mode", ""),"single-threaded")) {
-                info("Running web server with one thread, because mode is single-threaded");
+                netdata_info("Running web server with one thread, because mode is single-threaded");
                 config_set(CONFIG_SECTION_WEB, "mode", "static-threaded");
                 def_thread_count = 1;
     }
@@ -526,7 +526,7 @@ void *socket_listen_main_static_threaded(void *ptr) {
     // See https://github.com/netdata/netdata/issues/11081#issuecomment-831998240 for more details
     if (OPENSSL_VERSION_NUMBER < OPENSSL_VERSION_110) {
         static_threaded_workers_count = 1;
-        info("You are running an OpenSSL older than 1.1.0, web server will not enable multithreading.");
+        netdata_info("You are running an OpenSSL older than 1.1.0, web server will not enable multithreading.");
     }
 #endif
 
@@ -546,7 +546,7 @@ void *socket_listen_main_static_threaded(void *ptr) {
         char tag[50 + 1];
         snprintfz(tag, 50, "WEB[%d]", i+1);
 
-        info("starting worker %d", i+1);
+        netdata_info("starting worker %d", i+1);
         netdata_thread_create(&static_workers_private_data[i].thread, tag, NETDATA_THREAD_OPTION_DEFAULT,
                               socket_listen_main_static_threaded_worker, (void *)&static_workers_private_data[i]);
     }
diff --git a/web/server/web_client.c b/web/server/web_client.c
index 5dcff0b..63a974a 100644
--- a/web/server/web_client.c
+++ b/web/server/web_client.c
@@ -891,7 +891,7 @@ static inline HTTP_VALIDATION http_request_validate(struct web_client *w) {
         is_it_valid = url_is_request_complete(s, &s[last_pos], w->header_parse_last_size, &w->post_payload, &w->post_payload_size);
         if(!is_it_valid) {
             if(w->header_parse_tries > HTTP_REQ_MAX_HEADER_FETCH_TRIES) {
-                info("Disabling slow client after %zu attempts to read the request (%zu bytes received)", w->header_parse_tries, buffer_strlen(w->response.data));
+                netdata_info("Disabling slow client after %zu attempts to read the request (%zu bytes received)", w->header_parse_tries, buffer_strlen(w->response.data));
                 w->header_parse_tries = 0;
                 w->header_parse_last_size = 0;
                 web_client_disable_wait_receive(w);
